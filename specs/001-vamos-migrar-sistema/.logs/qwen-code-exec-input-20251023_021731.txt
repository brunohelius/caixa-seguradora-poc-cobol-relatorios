=== INPUT PROMPT FOR QWEN-CODE-EXEC ===
Timestamp: 20251023_021731
Length: 518054 chars
================================================================================

Execute implementation for task T010 following the /implement workflow template.

**CRITICAL: CONSOLIDATED TASK PLAN (PRIMARY GUIDANCE)**
You MUST read and follow the consolidated task plan file at:
/Users/brunosouza/Development/Caixa Seguradora/POC Cobol/specs/001-vamos-migrar-sistema/.task-plans/task-T010.md

This file contains:
1. SPECIFICATION (WHAT & WHY) - Task purpose, requirements, success criteria
2. TECHNICAL PLANNING (HOW) - Artifact analysis, technical approach, patterns
3. IMPLEMENTATION STEPS (EXECUTABLE STEPS) - Detailed steps, subtasks, verification

Read this file NOW before implementing. This is your COMPLETE implementation guide.

**LEGACY PLAN (for reference only - use consolidated task file above):**
ADAPTIVE_PLANNING_MODE: Task complexity is TRIVIAL (0.19). Execute directly following task description.

**ARTIFACT CONTEXT (from design artifacts):**


### PLAN.MD (Tech Stack & Architecture)

# Implementation Plan: COBOL RG1866B to .NET 9 React Migration

**Branch**: `001-vamos-migrar-sistema` | **Date**: October 22, 2025 | **Spec**: [spec.md](spec.md)
**Input**: Feature specification from `/specs/001-vamos-migrar-sistema/spec.md`

## Summary

Migrate legacy COBOL batch program RG1866B (SUSEP Circular 360 Premium Reporting System) to modern full-stack application with .NET 9 backend and React frontend. The system generates regulated insurance premium reports by processing policy data, premiums, endorsements, and cossurance information from 26+ database tables. Key technical challenge is ensuring byte-for-byte output compatibility with legacy system while modernizing architecture. Implementation uses SQLite for development with mocked DB2 data structure, Clean Architecture for backend, and Caixa Seguradora-branded responsive UI.

## Technical Context

**Language/Version**:
- Backend: C# with .NET 9 SDK
- Frontend: TypeScript with React 18+
- Database: SQLite 3.x (development), DB2 compatibility layer

**Primary Dependencies**:
- Backend: ASP.NET Core Web API 9.0, Entity Framework Core 9.0, Serilog (logging), AutoMapper (DTO mapping), Swashbuckle (Swagger/OpenAPI), xUnit (testing)
- Frontend: React 18+, React Router 6+ (navigation), Axios (HTTP client), Recharts or Chart.js (visualizations), TailwindCSS (styling), Vite (build tool)
- Shared: SQLite driver (Microsoft.Data.Sqlite), Newtonsoft.Json or System.Text.Json

**Storage**: SQLite database with schema mirroring 26+ DB2 views/tables (V0PREMIOS, V0APOLICE, V0ENDOSSO, V0PRODUTO, V0CLIENTE, V0TOMADOR, V0ENDERECOS, V0AGENCIAS, V0PRODUTOR, V0COBERAPOL, V0FATURAS, V0HISTOPARC, V0APOLCOSCED, GE399, etc.)

**Testing**:
- Backend: xUnit (unit tests), FluentAssertions (assertions), Moq (mocking), Microsoft.AspNetCore.Mvc.Testing (integration tests)
- Frontend: Vitest or Jest (unit tests), React Testing Library (component tests), Playwright or Cypress (E2E tests)
- Migration validation: Custom comparison framework for COBOL vs .NET output validation

**Target Platform**:
- Backend: Linux/Windows/macOS server (containerized via Docker)
- Frontend: Modern browsers (Chrome 120+, Firefox 120+, Edge 120+, Safari 17+)
- Deployment: Docker Compose for development, Kubernetes-ready for production

**Project Type**: Web application (separate backend API + frontend SPA)

**Performance Goals**:
- Report generation: Process 10,000+ premium records in under 5 minutes
- API response: <2 seconds for dashboard load, <500ms for standard queries
- Concurrent users: Support 10+ simultaneous report generation without 20%+ degradation
- Database queries: Cursor-based processing for large datasets to prevent memory overflow

**Constraints**:
- **Byte-level compatibility**: Output files (PREMIT.TXT, PREMCED.TXT) must match COBOL output exactly for regulatory compliance
- **Decimal precision**: Financial calculations must use C# decimal type (not float/double) to match COBOL arithmetic exactly
- **Fixed-width formatting**: Custom formatters required to replicate COBOL space/zero padding
- **Transaction boundaries**: Must replicate COBOL COMMIT/ROLLBACK semantics precisely
- **Language**: All user-facing content in Portuguese (Brazilian)
- **Branding**: Must follow Caixa Seguradora corporate style guide
- **Legacy coexistence**: Must run in parallel with COBOL system during validation period

**Scale/Scope**:
- **Code migration**: ~5,000 lines COBOL → estimated 15,000+ lines C#/TypeScript
- **Data structures**: 687 COBOL data items → C# models
- **Business logic**: 63 COBOL sections, 65 paragraphs → C# services/repositories
- **Database**: 26+ views/tables, 4 cursor operations
- **External modules**: 3 COBOL modules (RE0001S, GE0009S, GE0010S) → C# services or APIs
- **User stories**: 5 prioritized stories (dashboard, report generation, querying, batch jobs, data management)
- **Functional requirements**: 30 requirements covering report generation, database integration, business logic, UI, data management, testing

## Constitution Check

*GATE: Must pass before Phase 0 research. Re-check after Phase 1 design.*

**Note**: Constitution defined at `.specify/memory/constitution.md`; principles below summarize the ratified mandates and must remain aligned with that document.

### Proposed Principles for This Migration

Given the nature of this project (legacy migration with regulatory compliance requirements), proposing these architectural principles:

**I. Functional Parity First (NON-NEGOTIABLE)**
- Every COBOL section must have documented C# equivalent with traceability
- All business calculations must produce identical results (zero deviation)
- Output files must match byte-for-byte for regulatory compliance
- No new features added during migration phase (scope protection)

**II. Clean Architecture Mandatory**
- Domain models independent of infrastructure
- Repository pattern for database access (enables future DB2 → production DB migration)
- Service layer encapsulates business logic
- API controllers handle HTTP concerns only
- Dependency injection for testability

**III. Test-Driven Migration (NON-NEGOTIABLE)**
- Side-by-side comparison tests required for all business logic
- Unit tests for all calculation services (90%+ coverage target)
- Integration tests for database operations
- E2E tests for complete report generation workflow
- Validation: 100 production samples must show 100% output equivalence

**IV. Data Type Precision**
- C# decimal type mandatory for all financial calculations
- Custom type converters for COBOL PIC → C# type mappings
- Rounding mode configuration matching COBOL arithmetic
- String padding/formatting replicates COBOL fixed-width behavior

**V. Observability & Traceability**
- Comprehensive logging (similar to COBOL DISPLAY statements)
- Audit trail for all report generation operations
- Performance metrics for comparison with COBOL baseline
- Structured logging (JSON) for troubleshooting

**Constitution Status**: ✅ PASS (principles codified in `.specify/memory/constitution.md`, amendments require governance workflow)

## Project Structure

### Documentation (this feature)

```text
specs/001-vamos-migrar-sistema/
├── spec.md              # Feature specification (created)
├── plan.md              # This file (/speckit.plan command output)
├── research.md          # Phase 0 output (next step)
├── data-model.md        # Phase 1 output
├── quickstart.md        # Phase 1 output
├── contracts/           # Phase 1 output (API contracts)
│   ├── openapi.yaml    # OpenAPI 3.0 specification
│   └── schemas/        # JSON schemas for data models
├── checklists/          # Quality validation checklists
│   └── requirements.md  # Specification quality checklist (created)
└── tasks.md             # Phase 2 output (/speckit.tasks command - created)
```

### Source Code (repository root)

```text
# Web application structure (backend + frontend)

backend/
├── src/
│   ├── CaixaSeguradora.Api/              # ASP.NET Core Web API
│   │   ├── Controllers/                   # API controllers
│   │   │   ├── ReportsController.cs      # Report generation endpoints
│   │   │   ├── DashboardController.cs    # Dashboard metrics
│   │   │   ├── QueryController.cs        # Data query endpoints
│   │   │   └── DataManagementController.cs # Mock data management
│   │   ├── Program.cs                     # Application entry point
│   │   ├── appsettings.json              # Configuration
│   │   └── Middleware/                    # Custom middleware
│   │
│   ├── CaixaSeguradora.Core/             # Domain layer (Clean Architecture)
│   │   ├── Entities/                      # Domain entities
│   │   │   ├── Premium.cs                # Premium record
│   │   │   ├── Policy.cs                 # Insurance policy
│   │   │   ├── Endorsement.cs            # Policy endorsement
│   │   │   ├── Product.cs                # Insurance product
│   │   │   ├── Client.cs                 # Policyholder
│   │   │   ├── Coverage.cs               # Coverage details
│   │   │   ├── Invoice.cs                # Billing invoice
│   │   │   └── CossuredPolicy.cs         # Cossurance arrangement
│   │   ├── Interfaces/                    # Repository & service contracts
│   │   │   ├── IReportService.cs
│   │   │   ├── IPremiumRepository.cs
│   │   │   ├── IPolicyRepository.cs
│   │   │   └── ICalculationService.cs
│   │   ├── Services/                      # Domain services
│   │   │   ├── PremiumCalculationService.cs   # Business calculations
│   │   │   ├── CossuranceService.cs           # Cossurance logic
│   │   │   └── ValidationService.cs           # Business rules validation
│   │   ├── DTOs/                          # Data transfer objects
│   │   └── Exceptions/                    # Domain exceptions
│   │
│   ├── CaixaSeguradora.Infrastructure/    # Infrastructure layer
│   │   ├── Data/                          # Database context & repositories
│   │   │   ├── ApplicationDbContext.cs   # EF Core DbContext
│   │   │   ├── Repositories/
│   │   │   │   ├── PremiumRepository.cs
│   │   │   │   ├── PolicyRepository.cs
│   │   │   │   └── BaseRepository.cs
│   │   │   └── Configurations/            # EF entity configurations
│   │   ├── Services/                      # External service implementations
│   │   │   ├── FileGenerationService.cs  # PREMIT/PREMCED file generation
│   │   │   ├── FixedWidthFormatter.cs    # COBOL-compatible formatting
│   │   │   └── ExternalModuleService.cs  # Mock for GE0009S, GE0010S, RE0001S
│   │   ├── Migrations/                    # EF Core migrations
│   │   └── MockData/                      # SQLite data seeding
│   │
│   ├── CaixaSeguradora.Tests/             # Test projects
│   │   ├── UnitTests/                     # Unit tests
│   │   │   ├── Services/
│   │   │   └── Calculations/
│   │   ├── IntegrationTests/              # Integration tests
│   │   │   ├── Api/
│   │   │   └── Database/
│   │   └── ComparisonTests/               # COBOL vs .NET validation
│   │       ├── OutputComparison.cs
│   │       └── TestDataSets/
│   │
│   └── CaixaSeguradora.sln                # Solution file
│
frontend/
├── src/
│   ├── components/                        # Reusable React components
│   │   ├── common/                        # Generic components
│   │   │   ├── Header.tsx                # Caixa Seguradora header
│   │   │   ├── Footer.tsx
│   │   │   ├── LoadingSpinner.tsx
│   │   │   └── ErrorMessage.tsx
│   │   ├── dashboard/                     # Dashboard components
│   │   │   ├── MigrationMetrics.tsx
│   │   │   ├── ComplexityChart.tsx
│   │   │   ├── FunctionPointsCard.tsx
│   │   │   └── DatabaseDependencies.tsx
│   │   ├── reports/                       # Report generation components
│   │   │   ├── ReportForm.tsx
│   │   │   ├── ProgressIndicator.tsx
│   │   │   └── ResultsDownload.tsx
│   │   └── query/                         # Query builder components
│   │       ├── QueryBuilder.tsx
│   │       ├── ResultsTable.tsx
│   │       └── ChartVisualization.tsx
│   │
│   ├── pages/                             # Page components (routes)
│   │   ├── DashboardPage.tsx             # Landing page (P1)
│   │   ├── ReportGenerationPage.tsx      # Report generation (P2)
│   │   ├── QueryPage.tsx                 # Data querying (P3)
│   │   ├── BatchJobsPage.tsx             # Job monitoring (P4)
│   │   └── DataManagementPage.tsx        # Mock data management (P4)
│   │
│   ├── services/                          # API integration layer
│   │   ├── apiClient.ts                  # Axios configuration
│   │   ├── reportService.ts              # Report generation API calls
│   │   ├── dashboardService.ts           # Dashboard data API calls
│   │   └── queryService.ts               # Query execution API calls
│   │
│   ├── models/                            # TypeScript interfaces
│   │   ├── Premium.ts
│   │   ├── Policy.ts
│   │   ├── Report.ts
│   │   └── DashboardMetrics.ts
│   │
│   ├── hooks/                             # Custom React hooks
│   │   ├── useReportGeneration.ts
│   │   ├── useDashboardData.ts
│   │   └── useQuery.ts
│   │
│   ├── utils/                             # Utility functions
│   │   ├── formatters.ts                 # Data formatting
│   │   ├── validators.ts                 # Input validation
│   │   └── chartHelpers.ts               # Chart configuration
│   │
│   ├── styles/                            # Global styles
│   │   ├── globals.css                   # Tailwind imports + globals
│   │   ├── caixa-theme.css              # Caixa Seguradora branding
│   │   └── variables.css                 # CSS custom properties
│   │
│   ├── App.tsx                            # Root component
│   ├── main.tsx                           # Entry point
│   └── router.tsx                         # React Router configuration
│
├── tests/                                 # Frontend tests
│   ├── unit/                              # Component unit tests
│   ├── integration/                       # Integration tests
│   └── e2e/                               # End-to-end tests (Playwright)
│
├── public/                                # Static assets
│   ├── favicon.ico
│   └── assets/
│       ├── logo-caixa.png
│       └── images/
│
├── package.json                           # NPM dependencies
├── vite.config.ts                         # Vite configuration
├── tsconfig.json                          # TypeScript configuration
└── tailwind.config.js                     # Tailwind CSS configuration

docker/
├── Dockerfile.backend                     # Backend container
├── Dockerfile.frontend                    # Frontend container
└── docker-compose.yml                     # Development environment

docs/
├── parser/                                # COBOL analysis (existing)
│   ├── FINAL-ANALYSIS-REPORT.md
│   ├── INDEX.md
│   └── detailed-structure.txt
├── migration/                             # Migration documentation
│   ├── data-dictionary.md                # COBOL → C# type mappings
│   ├── business-rules.md                 # Extracted business logic
│   ├── comparison-results.md             # Validation test results
│   └── deployment-guide.md               # Deployment instructions
└── api/                                   # API documentation
    └── README.md                          # API usage guide

database/
├── schema/                                # SQLite schema
│   ├── create-tables.sql                 # DDL for all 26+ tables
│   └── indexes.sql                       # Performance indexes
├── mock-data/                             # Test data
│   ├── load-data.sql                     # Data loading scripts
│   └── csv/                              # CSV files for bulk import
│       ├── v0premios.csv
│       ├── v0apolice.csv
│       └── [other tables].csv
└── migrations/                            # Schema version control
```

**Structure Decision**: Web application with separate backend and frontend projects. Backend uses Clean Architecture (Api → Core → Infrastructure) for maintainability and testability. Frontend uses component-based architecture with React Router for navigation. Docker Compose orchestrates both services for development. This structure supports the migration strategy: clear separation allows parallel development of backend logic migration and frontend UI creation, facilitates independent testing of business logic vs. UI, and enables future scaling (e.g., deploying backend to production DB2 while keeping frontend unchanged).

## Complexity Tracking

> **Fill ONLY if Constitution Check has violations that must be justified**

**Note**: No constitution violations - this is a greenfield migration project establishing its own architectural patterns. Complexity is inherent to the legacy system being migrated:

| Complexity Source | Why Needed | Simpler Alternative Rejected Because |
|-------------------|------------|-------------------------------------|
| Clean Architecture (3 layers) | Separation of concerns for 687 data items, 63 sections of business logic | Direct coupling would make testing impossible; regulatory compliance requires isolated business logic for validation |
| Repository Pattern | Abstract database access for future DB2 → production DB migration | Direct EF Core usage would hardcode SQLite specifics; need flexibility for production database transition |
| Custom Formatters | COBOL fixed-width format with space/zero padding | Standard .NET formatters don't replicate COBOL behavior; regulatory compliance requires byte-for-byte matching |
| SQLite Mock + Production DB Layer | Development environment without mainframe access | Mocking all 26+ tables inline would be unmaintainable; need realistic database structure for accurate testing |
| Dual Frontend/Backend | React SPA + REST API | Monolithic Razor Pages insufficient for modern UX; dashboard with charts requires rich client-side interaction |

---

## Phase 0: Research & Technical Decisions

**Status**: In Progress

### Research Areas

Based on Technical Context analysis, the following areas require research and decision documentation:

#### R1: COBOL to C# Type Mapping Strategy
**Question**: What is the precise mapping for all COBOL PIC types to C# types ensuring arithmetic precision?
**Priority**: Critical (affects all 687 data items)
**Focus Areas**:
- PIC 9(n)V9(m) → C# decimal with exact scale/precision
- PIC X(n) → C# string with fixed-length handling
- PIC S9(n) COMP-3 → C# integer types
- Date formats (YYYYMMDD, DDMMYYYY) → C# DateTime
- Rounding mode configuration for Math.Round

#### R2: Fixed-Width File Generation
**Question**: How to replicate COBOL WRITE with fixed-width records, space padding, zero padding?
**Priority**: Critical (regulatory compliance)
**Focus Areas**:
- Custom formatter implementation patterns
- String padding: PadRight for spaces, PadLeft with '0' for numbers
- Binary comparison techniques for validation
- Performance optimization for large files (streaming writes)

#### R3: Cursor-Based Processing Pattern
**Question**: How to implement COBOL cursor behavior (DECLARE, OPEN, FETCH, CLOSE) in EF Core?
**Priority**: High (performance for large datasets)
**Focus Areas**:
- EF Core AsNoTracking with streaming
- IAsyncEnumerable<T> for async streaming
- Pagination strategies
- Memory management for millions of records

#### R4: External Module Integration
**Question**: How to integrate or mock COBOL modules RE0001S, GE0009S, GE0010S?
**Priority**: Medium (required for complete business logic)
**Focus Areas**:
- Parameter marshalling from COBOL LINKAGE SECTION
- Service interface design for mockability
- Potential reverse-engineering approaches if source unavailable
- Testing strategies for external dependencies

#### R5: Transaction Boundary Replication
**Question**: How to replicate COBOL COMMIT/ROLLBACK semantics in EF Core?
**Priority**: High (data integrity)
**Focus Areas**:
- EF Core transaction scopes
- SaveChanges behavior and transaction boundaries
- Error handling and rollback patterns
- Distributed transaction considerations (if multiple databases)

#### R6: Caixa Seguradora Branding Implementation
**Question**: How to extract and implement corporate branding from website?
**Priority**: Medium (user experience)
**Focus Areas**:
- Color palette extraction (primary, secondary, accent colors)
- Typography stack (fonts, sizes, weights)
- Component library approach (custom vs. Tailwind + shadcn/ui)
- Logo and asset licensing/usage

#### R7: SQLite to DB2 Compatibility Layer
**Question**: What are the limitations and workarounds for SQLite mimicking DB2?
**Priority**: High (data access foundation)
**Focus Areas**:
- SQL dialect differences (date functions, string functions)
- Stored procedure alternatives (in-code logic)
- Cursor behavior differences
- Concurrency control (locking vs. optimistic concurrency)
- Type system differences (DECIMAL precision)

#### R8: Performance Baseline Establishment
**Question**: How to measure and compare COBOL vs .NET performance?
**Priority**: Medium (success criteria validation)
**Focus Areas**:
- Profiling tools for C# (.NET diagnostic tools)
- Benchmark framework selection
- Metrics collection (execution time, memory usage, I/O operations)
- Reporting and comparison visualization

### Research Deliverable

All research findings will be documented in `research.md` with the following structure for each area:

```markdown
### [R#]: [Research Area Name]

**Decision**: [What was chosen]

**Rationale**: [Why this approach was selected]

**Alternatives Considered**:
1. [Alternative 1] - Rejected because [reason]
2. [Alternative 2] - Rejected because [reason]

**Implementation Notes**: [Key considerations, gotchas, best practices]

**References**: [Links to documentation, blog posts, Stack Overflow, etc.]
```

---

## Phase 1: Design & Contracts (After Research Complete)

**Status**: ✅ Complete (October 22, 2025)

### Phase 1.1: Data Model Design

**Output**: `data-model.md` with comprehensive entity definitions

**Scope**: Map all key entities from feature spec to C# models with:
- Entity name and purpose
- Properties with C# types (informed by R1 research)
- Relationships (foreign keys, navigation properties)
- Validation rules (from functional requirements)
- EF Core configuration (fluent API, indexes, constraints)

**Key Entities to Define** (from spec):
1. Premium Record (V0PREMIOS)
2. Policy (V0APOLICE)
3. Endorsement (V0ENDOSSO)
4. Product (V0PRODUTO, V0PRODUTOSVG)
5. Client (V0CLIENTE, V0TOMADOR)
6. Address (V0ENDERECOS)
7. Agency (V0AGENCIAS)
8. Producer (V0PRODUTOR)
9. Coverage (V0COBERAPOL)
10. Invoice (V0FATURAS)
11. Installment (V0HISTOPARC)
12. Cossured Policy (V0APOLCOSCED)
13. Cossurance Calculation (GE399)
14. System Configuration (V0SISTEMA)
15. Report Definition (V0RELATORIOS)

### Phase 1.2: API Contracts

**Output**: `/contracts/openapi.yaml` and `/contracts/schemas/`

**Scope**: Generate OpenAPI 3.0 specification for all API endpoints based on functional requirements:

**Endpoints to Define**:

```yaml
# Dashboard APIs (User Story 1 - P1)
GET /api/dashboard/metrics           # System overview metrics
GET /api/dashboard/complexity        # Processing complexity stats
GET /api/dashboard/function-points   # Function points estimation
GET /api/dashboard/database-deps     # Database dependencies

# Report Generation APIs (User Story 2 - P2)
POST /api/reports/generate           # Generate PREMIT/PREMCED reports
  Request: { systemId, startDate, endDate, reportType, mode }
  Response: { jobId, status, message }
GET /api/reports/{jobId}/status      # Check generation status
GET /api/reports/{jobId}/download    # Download generated files
GET /api/reports/history             # List past report generations

# Query APIs (User Story 3 - P3)
POST /api/query/execute              # Execute ad-hoc query
  Request: { filters, columns, aggregations, sorting }
  Response: { data, summary, pagination }
GET /api/query/saved                 # List saved queries
POST /api/query/export               # Export query results (CSV/Excel/PDF)

# Batch Job APIs (User Story 4 - P4)
POST /api/jobs/schedule              # Schedule batch report job
GET /api/jobs                        # List scheduled jobs
GET /api/jobs/{jobId}                # Get job details
PUT /api/jobs/{jobId}                # Update job configuration
DELETE /api/jobs/{jobId}             # Delete scheduled job
GET /api/jobs/{jobId}/history        # Job execution history

# Data Management APIs (User Story 5 - P4)
GET /api/data/schema                 # Get SQLite schema info
POST /api/data/load                  # Load mock data from CSV/JSON
POST /api/data/validate              # Validate data integrity
DELETE /api/data/reset               # Clear and reset database
GET /api/data/comparison             # Get COBOL vs .NET comparison results
```

**Schema Definitions**: JSON schemas for all request/response DTOs will be generated in `/contracts/schemas/` directory.

### Phase 1.3: Quickstart Guide

**Output**: `quickstart.md` with developer onboarding instructions

**Contents**:
- Prerequisites (SDKs, tools, versions)
- Repository clone and setup
- Database initialization (SQLite schema creation, mock data loading)
- Backend build and run instructions
- Frontend build and run instructions
- Docker Compose quick start
- Running tests
- API documentation access (Swagger UI)
- Troubleshooting common setup issues

### Phase 1.4: Agent Context Update

After completing design artifacts, will run:
```bash
.specify/scripts/bash/update-agent-context.sh claude
```

This will update `.claude/context.md` with:
- Technology stack from this plan
- Project structure references
- Key architectural decisions from research.md
- Links to data-model.md and contracts/

---

## Phase 2: Task Breakdown (Separate Command)

**Status**: Not started (requires `/speckit.tasks` command)

This phase is executed by a separate command (`/speckit.tasks`) and will generate `tasks.md` with:
- Dependency-ordered implementation tasks
- Assignments to user stories (P1-P4)
- Effort estimates
- Acceptance criteria references
- Technology-specific implementation details

---

## Notes

### Critical Success Factors

1. **Research Quality**: Phase 0 research must thoroughly address all 8 research areas. Incomplete research on type mapping or formatting could cause regulatory non-compliance.

2. **Data Model Accuracy**: Entity definitions in Phase 1.1 must precisely map all 687 COBOL data items. Missing fields or incorrect types will cause calculation discrepancies.

3. **API Contract Completeness**: All 30 functional requirements must map to API endpoints. Missing endpoints will block frontend implementation.

4. **Test Strategy**: Comparison tests (COBOL vs .NET) are non-negotiable. Without these, no confidence in migration accuracy.

### Risk Mitigation

**Risk**: COBOL business logic misinterpretation
**Mitigation**: Document every COBOL section with pseudocode in business-rules.md; validate with SMEs

**Risk**: Decimal precision errors in calculations
**Mitigation**: R1 research must include unit tests comparing decimal operations; use decimal type exclusively

**Risk**: Performance regression vs COBOL
**Mitigation**: R8 establishes baseline; continuous benchmarking during implementation

**Risk**: External module unavailability (RE0001S, GE0009S, GE0010S)
**Mitigation**: R4 research includes mocking strategy; document assumptions for each module

### Completion Summary

**Phase 0: Research & Technical Decisions** - ✅ Complete
- `research.md` created with comprehensive research for all 8 areas (R1-R8)
- Type mapping strategy defined (COBOL PIC → C# types)
- Fixed-width file generation approach established
- Cursor processing mapped to IAsyncEnumerable<T>
- External module integration strategy documented
- Transaction boundary replication designed
- Caixa Seguradora branding guidelines extracted
- Database compatibility layer architected
- Performance baseline methodology established

**Phase 1: Design & Contracts** - ✅ Complete
- **Phase 1.1**: `data-model.md` created with 15 comprehensive entity definitions
  - All COBOL views/tables mapped to C# entities
  - Complete EF Core configurations with fluent API
  - Validation rules documented for each entity
  - Navigation properties and relationships defined
  - Traceability matrix linking entities to COBOL sections
- **Phase 1.2**: `contracts/openapi.yaml` created with complete API specification
  - 28 RESTful endpoints across 9 categories
  - Request/response schemas for all operations
  - OpenAPI 3.0.3 compliant specification
  - Comprehensive API documentation in `contracts/schemas/README.md`
  - Examples and usage patterns documented
- **Phase 1.3**: `quickstart.md` created with developer onboarding guide
  - Prerequisites and environment setup instructions
  - Step-by-step getting started guide
  - Development workflow and best practices
  - Testing instructions for backend and frontend
  - Database management with EF Core migrations
  - Troubleshooting common issues
  - Quick reference commands

### Next Steps

1. ✅ Complete Technical Context
2. ✅ Pass Constitution Check (greenfield project)
3. ✅ **Complete**: Generate `research.md` (Phase 0)
4. ✅ **Complete**: Generate `data-model.md` (Phase 1.1)
5. ✅ **Complete**: Generate API contracts (Phase 1.2)
6. ✅ **Complete**: Generate `quickstart.md` (Phase 1.3)
7. 🔄 **In Progress**: Update agent context (Phase 1.4)
8. ⏳ **Pending**: Execute `/speckit.tasks` for task breakdown (Phase 2)

---

**Plan Version**: 1.1 | **Created**: October 22, 2025 | **Updated**: October 22, 2025 | **Status**: Phase 1 Complete, Ready for Phase 2



### SPEC.MD (User Stories & Acceptance)

# Feature Specification: COBOL RG1866B to .NET 9 React Migration

**Feature Branch**: `001-vamos-migrar-sistema`
**Created**: October 22, 2025
**Status**: Draft
**Legacy System**: COBOL RG1866B - SUSEP Circular 360 Premium Reporting System

## Executive Summary

Migrate the legacy COBOL batch processing program RG1866B (SUSEP Circular 360 Premium Reports) to a modern full-stack application using .NET 9 backend with React frontend. The system generates regulated insurance premium reports for Brazilian insurance regulator (SUSEP), processing policy data, premiums, endorsements, and cossurance information from 26+ database tables.

### Current State
- **Legacy System**: COBOL batch program RG1866B (~5,000 lines)
- **Database**: IBM DB2 with 26+ views/tables
- **Processing**: Batch processing with 4 cursors
- **Output**: 2 text files (PREMIT.TXT, PREMCED.TXT)
- **External Dependencies**: 3 COBOL modules (RE0001S, GE0009S, GE0010S)
- **Data Structures**: 687 data items, 63 sections, 65 paragraphs

### Target State
- **Backend**: .NET 9 Web API with C#
- **Frontend**: React application with dashboard
- **Database**: SQLite local database with mocked DB2 data structure
- **Architecture**: Clean Architecture with RESTful APIs
- **UI/UX**: Caixa Seguradora branding and styling
- **Deployment**: Containerized solution

## User Scenarios & Testing

### User Story 1 - View Migration Dashboard (Priority: P1)

Users need to understand the scope and complexity of the migration project, view current system metrics, and track migration progress through an interactive dashboard.

**Why this priority**: Provides immediate value by visualizing the migration scope, establishing baseline metrics, and creating transparency for stakeholders. Can be developed independently without backend logic migration.

**Independent Test**: Can be fully tested by launching the React application, navigating to the dashboard, and verifying all metrics display correctly with mock data. Delivers value by documenting system complexity and providing project visibility.

**Acceptance Scenarios**:

1. **Given** a user accesses the application, **When** they land on the homepage, **Then** they see a comprehensive dashboard showing system overview (program name, lines of code, creation date), data structure metrics (687 data items, table breakdown), processing complexity (63 sections, 65 paragraphs, 4 cursors), database dependencies (26+ tables with access patterns), and external module integrations (3 modules)

2. **Given** the dashboard is displayed, **When** user views the Function Points section, **Then** they see estimated function points for migration, breakdown by component (backend, frontend, database, integration), complexity ratings (High/Medium/Low), and effort estimates

3. **Given** user is on the dashboard, **When** they interact with visualizations, **Then** they can view interactive charts showing data distribution, drill down into specific sections/paragraphs, see database table relationships, and navigate to detailed analysis reports

---

### User Story 2 - Generate Premium Reports (Interactive) (Priority: P2)

Users need to generate SUSEP Circular 360 premium reports on-demand through a web interface, replacing the batch COBOL process with an interactive workflow that allows parameter selection and real-time execution.

**Why this priority**: Core business functionality that delivers immediate operational value by replacing the batch process with interactive capabilities. Represents the primary use case of the legacy system.

**Independent Test**: Can be tested by configuring report parameters (date range, system ID, report type), executing the generation process, and verifying output files match legacy COBOL output format byte-for-byte.

**Acceptance Scenarios**:

1. **Given** user is logged into the system, **When** they navigate to Report Generation, **Then** they see a form with date range selectors (start date, end date), system selection dropdown, report type selection (PREMIT, PREMCED, or Both), and processing mode (weekly cumulative, monthly)

2. **Given** user has filled the report parameters, **When** they click "Generate Report", **Then** system validates all required parameters, displays processing progress indicator, executes premium calculation logic identical to COBOL, accesses required database tables (V0PREMIOS, V0APOLICE, etc.), and generates output files in correct format

3. **Given** report generation completes successfully, **When** user views results, **Then** they can download PREMIT.TXT file, download PREMCED.TXT file, view generation summary (records processed, execution time), and see any warnings or validation messages

4. **Given** report generation encounters errors, **When** processing fails, **Then** system displays clear error message in Portuguese, logs detailed error information for support, maintains data integrity (no partial writes), and allows user to retry with corrected parameters

---

### User Story 3 - Query and Visualize Premium Data (Priority: P3)

Users need to query premium data interactively, view results in tables and charts, and export data for analysis, providing modern data exploration capabilities not available in the legacy batch system.

**Why this priority**: Adds modern capabilities beyond legacy functionality, enabling better business insights. Builds on core report generation but is not critical for initial operational parity.

**Independent Test**: Can be tested by executing various queries against mocked database, verifying results display correctly in tables and charts, and validating export functionality produces accurate files.

**Acceptance Scenarios**:

1. **Given** user is on the Query screen, **When** they build a query, **Then** they can filter by policy number, product, date range, select specific columns to display, sort results by any column, and apply aggregations (sum, average, count)

2. **Given** query results are displayed, **When** user views the data, **Then** they see paginated table with responsive design, summary statistics at the top, visual charts (bar, line, pie) based on data, and export buttons (CSV, Excel, PDF)

3. **Given** user wants to analyze trends, **When** they create visualizations, **Then** system generates charts from query results, allows customization (chart type, colors, labels), updates charts in real-time as filters change, and saves favorite queries for future use

---

### User Story 4 - Monitor Batch Processing Jobs (Priority: P4)

Users need to schedule and monitor batch report generation jobs, view execution history, and receive notifications about job completion or failures, providing operational visibility for automated processing.

**Why this priority**: Addresses operational requirements for scheduled processing but is not critical for initial MVP. Can be added once interactive generation is stable.

**Independent Test**: Can be tested by creating scheduled jobs, monitoring their execution status, and verifying notification delivery without impacting other system functionality.

**Acceptance Scenarios**:

1. **Given** user wants to automate reports, **When** they create a scheduled job, **Then** they can define job name and description, set recurrence pattern (daily, weekly, monthly), specify report parameters, and configure notification recipients

2. **Given** batch jobs are scheduled, **When** user views job monitor, **Then** they see list of all scheduled jobs, current execution status (Running, Completed, Failed), last execution time and duration, and next scheduled execution time

3. **Given** a batch job completes, **When** results are ready, **Then** system sends email notification to configured recipients, stores output files in designated location, updates job history with execution details, and triggers any configured downstream processes

---

### User Story 5 - Manage Database Mock Data (Priority: P4)

Developers and testers need to manage mock SQLite database data that replicates DB2 structure, load test datasets, and validate data integrity for thorough testing of migration logic.

**Why this priority**: Critical for testing but not user-facing functionality. Required for comprehensive validation but can use minimal datasets initially.

**Independent Test**: Can be tested by loading mock data files, verifying schema matches DB2, querying data, and confirming calculations produce expected results.

**Acceptance Scenarios**:

1. **Given** developer needs test data, **When** they access data management interface, **Then** they can view current SQLite schema, load mock data from CSV/JSON files, validate data against DB2 schema rules, and clear and reset test database

2. **Given** tester wants realistic data, **When** they load production-like dataset, **Then** system validates all foreign key relationships, checks data type compatibility, reports any data quality issues, and confirms record counts match source

3. **Given** migration testing is ongoing, **When** comparing outputs, **Then** developers can run side-by-side comparisons (COBOL vs .NET), generate diff reports highlighting discrepancies, export comparison results for analysis, and flag any business logic deviations

---

### Edge Cases

- **What happens when database query returns zero records?** System displays "No data found for selected parameters" message and allows user to adjust filters without error.

- **How does system handle cursor operations with large datasets?** Implements pagination and streaming results for cursors processing millions of records to prevent memory overflow, matching COBOL's cursor-based processing.

- **What if external module calls (GE0009S, GE0010S) are unavailable?** System displays descriptive error, logs the failure for diagnostics, and allows retry. Admin can configure module endpoints and fallback behavior.

- **How are concurrent users handled during report generation?** System queues requests, provides estimated wait time, and processes reports asynchronously to prevent database locking conflicts.

- **What happens with malformed date inputs?** System validates dates before processing, provides clear error messages in Portuguese ("Data inválida"), and highlights the problematic field.

- **How are DB2-specific data types handled in SQLite?** Mapping layer converts DB2 types (DECIMAL with scale, CHAR fixed-length) to SQLite equivalents, preserving precision and padding rules.

- **What if output file generation fails midway?** Transaction-based file writing ensures atomic operations - either complete file is written or nothing, with rollback capability.

- **How are COBOL numeric computations (PIC 9V99) replicated exactly?** Uses decimal types with exact precision matching, includes rounding mode configuration to replicate COBOL arithmetic behavior.

- **What happens when report parameters conflict (end date before start date)?** Validation layer catches logical errors before processing, returns specific error code and user-friendly message.

- **How is legacy fixed-width file format maintained?** Custom formatter applies padding (spaces for strings, zeros for numbers) matching COBOL WRITE statements exactly, validated by byte comparison.

## Requirements

### Functional Requirements

#### Core Report Generation
- **FR-001**: System MUST generate PREMIT.TXT file with identical layout and content to legacy COBOL output, including all columns, fixed-width formatting, and data precision
- **FR-002**: System MUST generate PREMCED.TXT file for cossurance/ceded premium data with exact legacy format compatibility
- **FR-003**: System MUST process premium records using same business logic as COBOL sections R0500-R5500, ensuring calculation parity
- **FR-004**: System MUST support date range parameters for report generation (initial date, final date) matching legacy WHERE clause logic
- **FR-005**: System MUST validate all input parameters before processing and return descriptive errors in Portuguese

#### Database Integration
- **FR-006**: System MUST connect to SQLite database with schema matching 26+ DB2 views/tables used by legacy COBOL
- **FR-007**: System MUST implement cursor-like processing for large datasets (V0PREMIOS, V0ENDERECOS, V0APOLCOSCED, GE399)
- **FR-008**: System MUST maintain transactional integrity for multi-step operations matching COBOL COMMIT/ROLLBACK behavior
- **FR-009**: System MUST handle all SQL error conditions (duplicate keys, not found, etc.) with equivalent error handling to COBOL SQLCODE checks
- **FR-010**: System MUST support read-only access to all database views without modifying existing data

#### Business Logic Migration
- **FR-011**: System MUST replicate all 687 COBOL data items as C# models with equivalent data types and precision
- **FR-012**: System MUST implement all calculation logic from COBOL sections (premium calculations, accumulations, cossurance)
- **FR-013**: System MUST call equivalent functionality for external modules RE0001S, GE0009S, GE0010S through internal services or APIs
- **FR-014**: System MUST apply all business validation rules encoded in COBOL IF statements (date validations, ramo-specific logic, cancellation checks)
- **FR-015**: System MUST handle endorsement processing (V0ENDOSSO) including cancelled endorsements with same logic as COBOL

#### User Interface
- **FR-016**: System MUST provide dashboard as landing page showing system analysis metrics (sections, data items, tables, complexity)
- **FR-017**: System MUST display function points estimation for migration with breakdown by component
- **FR-018**: System MUST provide report generation interface with parameter selection (dates, systems, report types)
- **FR-019**: System MUST show processing progress indicator during long-running operations
- **FR-020**: System MUST display all error messages and labels in Portuguese (Brazilian)
- **FR-021**: System MUST apply Caixa Seguradora branding (colors, logos, typography) following corporate guidelines from website
- **FR-022**: System MUST be responsive and work on desktop, tablet, and mobile viewports

#### Data Management
- **FR-023**: System MUST provide capability to load mock DB2 data into SQLite from CSV or JSON files
- **FR-024**: System MUST validate mock data schema compatibility with DB2 structure
- **FR-025**: System MUST support export of generated reports in multiple formats (TXT original format, CSV, Excel)
- **FR-026**: System MUST maintain data type precision when converting COBOL PIC formats to C# types (e.g., PIC 9(9)V99 to decimal(11,2))

#### Testing & Validation
- **FR-027**: System MUST provide side-by-side comparison capability between COBOL output and .NET output for validation
- **FR-028**: System MUST log all operations with sufficient detail for debugging and audit (similar to COBOL DISPLAY statements)
- **FR-029**: System MUST generate test reports with sample data to validate business logic migration
- **FR-030**: System MUST include automated unit tests for all critical calculation logic

### Non-Functional Requirements

#### Performance & Scalability
- **NFR-001**: System MUST process 10,000+ premium records in under 5 minutes, matching or improving legacy COBOL throughput.
- **NFR-002**: System MUST deliver API responses under 2 seconds for dashboard endpoints and under 500 ms for standard query endpoints.
- **NFR-003**: System MUST sustain at least 10 concurrent report generations with no more than 20% degradation in processing time.

#### Reliability & Data Integrity
- **NFR-004**: System MUST enforce read-only database access for legacy-mirrored views and block unintended write operations.
- **NFR-005**: System MUST guarantee transactional safeguards so partial failures rollback state consistently across services.

#### Observability & Auditability
- **NFR-006**: System MUST emit structured JSON logs enriched with correlation identifiers and COBOL section references.
- **NFR-007**: System MUST persist audit trails for report requests, parameters, comparison outcomes, and user actions subject to regulatory review.

#### Localization & Compliance
- **NFR-008**: System MUST present all UI text, error messages, and generated user-facing documentation in Brazilian Portuguese.
- **NFR-009**: System MUST maintain byte-level PREMIT/PREMCED compatibility that satisfies SUSEP Circular 360 validation.

#### Deployment & Operations
- **NFR-010**: System MUST build and run inside Docker containers, keeping environment parity between development, validation, and production stages.
- **NFR-011**: System MUST externalize secrets and environment configuration, ensuring sensitive values never reside in source control.

### Key Entities

#### Premium Data
- **Premium Record**: Represents a premium emission record from V0PREMIOS view, including policy number, product code, premium amount, emission date, effective date, status, and calculation components
- **Policy**: Insurance policy master data from V0APOLICE, including policy number, client ID, product, start/end dates, status, and agency information
- **Endorsement**: Policy modification from V0ENDOSSO, including endorsement number, type, date, premium impact, and cancellation status
- **Product**: Insurance product definition from V0PRODUTO/V0PRODUTOSVG, including product code, name, line of business (ramo), SUSEP code, and calculation rules

#### Party & Location
- **Client**: Policyholder or insured party from V0CLIENTE/V0TOMADOR, including client ID, name, document number (CPF/CNPJ), type (person/company)
- **Address**: Location data from V0ENDERECOS, including address components, city, state (UF), postal code, and address type
- **Agency**: Sales agency from V0AGENCIAS, including agency code, name, region, and channel information
- **Producer**: Insurance broker/producer from V0PRODUTOR, including producer code, name, commission rates, and affiliation

#### Coverage & Billing
- **Coverage**: Insurance coverage details from V0COBERAPOL, including coverage code, insured amount (IS), premium calculation basis, rates, and limits
- **Invoice**: Billing information from V0FATURAS, including invoice number, installment details, due dates, payment status, and amounts
- **Installment**: Premium installment from V0HISTOPARC, including parcel number, due date, payment date, amount, and status

#### Cossurance & Reinsurance
- **Cossured Policy**: Cossurance arrangement from V0APOLCOSCED, including ceding/acquiring company, percentage share, and premium distribution
- **Cossurance Calculation**: Cossurance computation data from GE399 table, including quota percentages, retained premium, and ceded amounts
- **Reinsurance Data**: Reinsurance calculations processed through external module RE0001S, including treaty information, retention limits, and ceded premium

## Success Criteria

### Measurable Outcomes

#### Functional Accuracy
- **SC-001**: Generated PREMIT.TXT and PREMCED.TXT files match legacy COBOL output byte-for-byte for identical input datasets (100% accuracy target)
- **SC-002**: All business calculations (premium, cossurance, accumulations) produce identical results to COBOL with zero deviation
- **SC-003**: System processes complete test dataset and generates valid output files in under 5 minutes for datasets with 10,000+ premium records

#### User Experience
- **SC-004**: Users can generate reports through web interface in 30 seconds or less from parameter selection to download (excluding processing time)
- **SC-005**: Dashboard loads and displays all migration metrics within 2 seconds on standard internet connection
- **SC-006**: 95% of report generation requests complete successfully on first attempt without user intervention
- **SC-007**: Error messages provide sufficient clarity that users can self-correct 80% of parameter errors without support

#### Technical Quality
- **SC-008**: System maintains 100% database transaction integrity with zero data corruption during concurrent operations
- **SC-009**: All critical business logic has automated unit test coverage achieving 90%+ code coverage
- **SC-010**: System handles 10 concurrent report generation requests without performance degradation exceeding 20%
- **SC-011**: SQLite mock database supports all 26+ tables with referential integrity constraints matching DB2 structure

#### Migration Validation
- **SC-012**: Side-by-side comparison tests with 100 production samples show 100% output equivalence between COBOL and .NET
- **SC-013**: All 63 COBOL sections have documented equivalent functionality in C# codebase with traceability matrix
- **SC-014**: All 687 COBOL data items have mapped C# models with validated type conversions
- **SC-015**: Performance testing shows .NET system processes equivalent workload within 120% of COBOL execution time (allowing 20% overhead for modernization benefits)

#### Operational Readiness
- **SC-016**: System includes comprehensive logging capturing all operations for 30-day troubleshooting and audit period
- **SC-017**: Documentation covers 100% of migrated business rules with examples and test cases
- **SC-018**: Development team successfully trains 5 business users who can independently generate reports and interpret results
- **SC-019**: System deployed successfully in containerized environment with zero-downtime deployment capability

## Out of Scope

The following items are explicitly excluded from this migration:

### Legacy Systems Not Included
- Migration of external COBOL modules RE0001S, GE0009S, GE0010S (will be called through adapters or mocked)
- Migration of other COBOL programs in the REGISTROS GERAIS system beyond RG1866B
- Integration with production DB2 mainframe database (using SQLite mock only)
- Migration of JCL job scheduling infrastructure

### Advanced Features
- Real-time premium calculation engine (beyond report generation)
- Online policy issuance or endorsement processing
- Integration with external SUSEP submission systems
- Multi-language support (Portuguese Brazilian only)
- Mobile native applications (responsive web only)

### Infrastructure
- Production hosting environment setup
- High availability / disaster recovery infrastructure
- Production security hardening and penetration testing
- Production monitoring and alerting setup

### Data Migration
- Historical data migration from DB2 to production database
- Data cleansing or transformation beyond mock data loading
- Archive strategies for old reports

## Assumptions

### Technical Assumptions
1. **Parser Accuracy**: ProLeap COBOL parser output accurately represents program structure, though business logic will be validated against source code
2. **SQLite Capability**: SQLite database can adequately replicate DB2 functionality for development and testing, including complex joins and cursor operations
3. **External Module Behavior**: External COBOL modules (RE0001S, GE0009S, GE0010S) can be adequately mocked or replaced with equivalent C# implementations
4. **Development Environment**: Team has access to .NET 9 SDK, Node.js 20+, and standard development tools
5. **Browser Compatibility**: Modern browsers (Chrome 120+, Firefox 120+, Edge 120+, Safari 17+) will be supported

### Business Assumptions
1. **Report Format Stability**: SUSEP Circular 360 report layouts remain stable during migration period
2. **Business Rules Documentation**: COBOL comments and header documentation accurately describe business intent
3. **Test Data Availability**: Sufficient representative test data can be obtained or generated for validation
4. **User Availability**: Subject matter experts will be available for business logic clarification during migration
5. **Timeline Flexibility**: Migration can proceed iteratively with user story prioritization allowing early feedback

## Dependencies

### External Dependencies
- **COBOL Source Code**: Complete, readable RG1866B.cbl source file (available)
- **DB2 Schema Documentation**: Database schema definitions for all 26+ tables/views
- **External Module Interfaces**: Interface contracts for RE0001S, GE0009S, GE0010S modules
- **Sample Data**: Representative datasets from production for testing and validation
- **Business Logic Documentation**: Any existing documentation of business rules and calculations
- **Caixa Seguradora Branding**: Corporate style guide, logos, color palette from website

### Technical Dependencies
- **.NET 9 SDK**: Backend framework for API development
- **React 18+**: Frontend framework for user interface
- **SQLite**: Local development database
- **Entity Framework Core**: ORM for database access
- **Serilog**: Logging framework
- **xUnit or MSTest**: Unit testing framework

## Constraints

### Technical Constraints
- **Legacy Compatibility**: Output files must maintain byte-level compatibility with legacy format for regulatory compliance
- **Precision Requirements**: Financial calculations must maintain exact decimal precision matching COBOL arithmetic
- **Database Limitations**: SQLite used for development has limitations vs. production DB2 (no stored procedures, limited concurrency)
- **Browser Requirements**: Must work in standard browsers without plugins or special configurations

### Regulatory Constraints
- **SUSEP Compliance**: Report format and content must comply with SUSEP Circular 360 regulations
- **Data Accuracy**: Insurance premium calculations must be auditable and match regulatory requirements
- **Report Retention**: Generated reports must be stored for regulatory retention period (defined by SUSEP)

### Business Constraints
- **Zero Downtime Requirement**: Migration must not disrupt ongoing report generation capabilities
- **Parallel Operation**: New system must run in parallel with legacy for validation period
- **User Acceptance**: Business users must approve migration before legacy decommission

## Migration Strategy

### Phase 1: Foundation (Weeks 1-2)
**Goal**: Establish project structure and baseline understanding

**Activities**:
1. Analyze parser output and COBOL source code comprehensively
2. Create detailed data dictionary mapping all 687 data items to C# types
3. Extract and document all business rules from COBOL IF/PERFORM logic
4. Set up .NET 9 Web API project structure with Clean Architecture
5. Initialize React project with Caixa Seguradora branding
6. Create SQLite database schema matching 26+ DB2 tables
7. Implement dashboard (User Story 1) with migration metrics

**Deliverables**:
- Data dictionary (COBOL to C# type mappings)
- Business rules documentation
- Project scaffolding (backend + frontend)
- Dashboard showing system complexity

### Phase 2: Core Backend (Weeks 3-5)
**Goal**: Implement backend services with business logic

**Activities**:
1. Create C# entity models for all key database tables
2. Implement repository pattern with Entity Framework Core
3. Migrate premium processing logic (sections R0500-R0700)
4. Implement policy and product data access (sections R0720-R0990)
5. Create calculation services for premium accumulation (R1300)
6. Implement cossurance processing logic (sections R3000-R5500)
7. Develop API endpoints for report generation
8. Unit test all business logic with known test cases

**Deliverables**:
- Backend API with core business logic
- Unit tests for calculations
- API documentation (Swagger)

### Phase 3: Report Generation (Weeks 6-7)
**Goal**: Implement end-to-end report generation

**Activities**:
1. Implement file generation services (PREMIT, PREMCED)
2. Create fixed-width file formatters matching COBOL output
3. Implement cursor-like batch processing for large datasets
4. Develop transaction management for data integrity
5. Create React report generation UI (User Story 2)
6. Implement error handling and validation
7. Load representative test data into SQLite
8. Execute side-by-side comparison tests

**Deliverables**:
- Working report generation (interactive)
- Test results comparing COBOL vs .NET output
- Report generation UI

### Phase 4: Validation & Enhancement (Weeks 8-9)
**Goal**: Validate accuracy and add value-added features

**Activities**:
1. Run comprehensive validation with 100+ test scenarios
2. Implement query and visualization features (User Story 3)
3. Add batch job monitoring (User Story 4)
4. Create data management utilities (User Story 5)
5. Conduct user acceptance testing
6. Performance optimization
7. Documentation completion

**Deliverables**:
- Validation report (COBOL parity achieved)
- Enhanced UI features
- Complete user and technical documentation

## References

### Documentation
- **Parser Analysis**: `/docs/parser/FINAL-ANALYSIS-REPORT.md` - Complete COBOL program structure analysis
- **Detailed Structure**: `/docs/parser/detailed-structure.txt` - Section and paragraph breakdown
- **Parser Index**: `/docs/parser/INDEX.md` - Navigation guide to all parser documentation

### Legacy System
- **COBOL Source**: `/RG1866B.cbl` - Original COBOL program source code
- **Program ID**: RG1866B - REGISTROS GERAIS system
- **Function**: SUSEP Circular 360 - Premium emission reports (PREMIT.TXT, PREMCED.TXT)
- **Created**: May 21, 2014 by Wellington F R C Veras

### External Resources
- **SUSEP Circular 360**: Brazilian insurance regulator reporting requirements
- **Caixa Seguradora Website**: https://www.caixaseguradora.com.br/ - Corporate branding reference
- **Dashboard Reference**: https://sicoob-sge3-jv1x.vercel.app/dashboard - UI inspiration

## Notes

### Critical Implementation Considerations

1. **Decimal Precision**: COBOL PIC fields use exact decimal precision. C# decimal type MUST be used (not double/float) for all financial calculations to avoid rounding errors that would cause regulatory non-compliance.

2. **Fixed-Width Formatting**: COBOL writes fixed-width records with space-padding for strings and zero-padding for numbers. Custom formatters required to replicate exact byte layout.

3. **Cursor Processing**: COBOL uses 4 database cursors for sequential processing. .NET implementation should use streaming/pagination to handle large datasets without loading all into memory.

4. **Date Handling**: COBOL date validations are complex (comparing proposal date vs. effective date by ramo). All date logic must be carefully migrated with timezone considerations.

5. **External Module Calls**: COBOL calls RE0001S, GE0009S, GE0010S with specific parameter structures. These must be mocked initially or replaced with equivalent C# services.

6. **Transaction Semantics**: COBOL has explicit COMMIT points. .NET must replicate same transactional boundaries to maintain data integrity.

### Known Limitations

1. **SQLite vs. DB2**: SQLite lacks some DB2 features (no stored procedures, limited concurrency, different date functions). Production deployment would require migration to SQL Server, PostgreSQL, or actual DB2.

2. **Parser Limitations**: While ProLeap parser successfully extracted structure, some complex COBOL idioms may require manual interpretation from source code.

3. **External Module Availability**: If external COBOL modules source code is unavailable, their functionality must be reverse-engineered from call parameters and expected behaviors.



### DATA-MODEL.MD (Entities & Relationships)

# Data Model Design: COBOL RG1866B to .NET 9 Migration

**Feature Branch**: `001-vamos-migrar-sistema`
**Created**: October 22, 2025
**Status**: Phase 1.1 - Data Model Design
**Version**: 1.0

## Overview

This document defines the C# entity models for the SUSEP Circular 360 Premium Reporting System migration. All entities map to DB2 views/tables used by the legacy COBOL RG1866B program and follow Clean Architecture principles with precise type mappings to preserve COBOL data semantics.

## Design Principles

### Type Mapping Strategy
- **Financial Fields**: Use C# `decimal` type exclusively (never `float`/`double`) to match COBOL packed decimal precision
- **Fixed-Length Strings**: Preserve COBOL `PIC X(n)` semantics with `[MaxLength(n)]` attributes
- **Date Fields**: Use `DateTime` with explicit format handling for COBOL date representations (YYYYMMDD, DDMMYYYY)
- **COBOL Metadata**: Apply `[CobolField]` custom attributes to preserve PIC clause information for validation and file generation

### Entity Framework Configuration
- **Fluent API**: Configure complex relationships, indexes, and constraints
- **No Tracking**: Read-only queries use `AsNoTracking()` for performance
- **View Mapping**: Use `ToView()` for DB2 views, `ToTable()` for tables
- **Concurrency**: Not required (read-only operations)

### Relationship Patterns
- **Navigation Properties**: Defined for foreign key relationships
- **Lazy Loading**: Disabled (use explicit `Include()` for performance control)
- **Cascade Delete**: Not applicable (read-only system)

---

## Core Domain Entities

### 1. Premium Record (V0PREMIOS)

**Purpose**: Represents premium emission records - the core entity for report generation, aggregating policy, product, and financial data.

**COBOL Source**: `V0PREMIOS` view, processed via cursor at section R0500-00-DECLARE-V0PREMIOS

#### Properties

```csharp
public class PremiumRecord
{
    // Primary Key
    [Key]
    public long PremiumId { get; set; }

    // Business Identifiers
    [CobolField(PicClause = "9(9)", Length = 9, FieldType = CobolFieldType.Numeric)]
    public int CompanyCode { get; set; }  // V0PREM-COD-EMP (COMP)

    [CobolField(PicClause = "9(4)", Length = 4)]
    public int ReferenceYear { get; set; }  // V0PREM-ANO-REFER

    [CobolField(PicClause = "9(4)", Length = 4)]
    public int ReferenceMonth { get; set; }  // V0PREM-MES-REFER

    [CobolField(PicClause = "9(4)", Length = 4)]
    public int ReferenceDay { get; set; }  // V0PREM-DIA-REFER

    [CobolField(PicClause = "X(1)", Length = 1)]
    [MaxLength(1)]
    public string MovementType { get; set; }  // V0PREM-TIPO-MOVT ('E', 'C', 'R', etc.)

    [CobolField(PicClause = "9(13)", Length = 13, FieldType = CobolFieldType.PackedDecimal)]
    public long PolicyNumber { get; set; }  // V0PREM-NUM-APOL (COMP-3)

    [CobolField(PicClause = "9(9)", Length = 9)]
    public int EndorsementNumber { get; set; }  // V0PREM-NRENDOS

    [CobolField(PicClause = "9(4)", Length = 4)]
    public int InstallmentNumber { get; set; }  // V0PREM-NRPARCEL

    [CobolField(PicClause = "9(4)", Length = 4)]
    public int OccurrenceNumber { get; set; }  // V0PREM-NUM-OCORR

    [CobolField(PicClause = "9(4)", Length = 4)]
    public int HistoricalOccurrence { get; set; }  // V0PREM-OCORHIST

    // Product Classification
    [CobolField(PicClause = "9(4)", Length = 4)]
    public int LineOfBusiness { get; set; }  // V0PREM-RAMOFR (Ramo)

    [CobolField(PicClause = "9(4)", Length = 4)]
    public int ProductModality { get; set; }  // V0PREM-MODALIFR

    [CobolField(PicClause = "9(4)", Length = 4)]
    public int OperationType { get; set; }  // V0PREM-OPERACAO

    [CobolField(PicClause = "9(4)", Length = 4)]
    public int BusinessOperationType { get; set; }  // V0PREM-TIPO-OPER

    [CobolField(PicClause = "9(9)", Length = 9)]
    public int ClientCode { get; set; }  // V0PREM-CODCLIEN

    // Currency & Exchange
    [CobolField(PicClause = "9(6)V9(9)", Length = 16, DecimalPlaces = 9, FieldType = CobolFieldType.PackedDecimal)]
    [Column(TypeName = "decimal(15,9)")]
    public decimal ExchangeRate { get; set; }  // V0PREM-VALOR-COT

    // Premium Components - Installment (Item)
    [CobolField(PicClause = "9(10)V9(5)", Length = 16, DecimalPlaces = 5, FieldType = CobolFieldType.PackedDecimal)]
    [Column(TypeName = "decimal(15,5)")]
    public decimal InsuredAmountItem { get; set; }  // V0PREM-IMP-SEG-IT

    [CobolField(PicClause = "9(10)V9(5)", Length = 16, DecimalPlaces = 5, FieldType = CobolFieldType.PackedDecimal)]
    [Column(TypeName = "decimal(15,5)")]
    public decimal BasePremiumItem { get; set; }  // V0PREM-VLPRMBAS-IT

    [CobolField(PicClause = "9(10)V9(5)", Length = 16, DecimalPlaces = 5, FieldType = CobolFieldType.PackedDecimal)]
    [Column(TypeName = "decimal(15,5)")]
    public decimal FixedPremiumItem { get; set; }  // V0PREM-VLPREFIX-IT

    [CobolField(PicClause = "9(10)V9(5)", Length = 16, DecimalPlaces = 5, FieldType = CobolFieldType.PackedDecimal)]
    [Column(TypeName = "decimal(15,5)")]
    public decimal TariffPremiumItem { get; set; }  // V0PREM-VLPRMTAR-IT

    [CobolField(PicClause = "9(10)V9(5)", Length = 16, DecimalPlaces = 5, FieldType = CobolFieldType.PackedDecimal)]
    [Column(TypeName = "decimal(15,5)")]
    public decimal DiscountItem { get; set; }  // V0PREM-VLDESCON-IT

    [CobolField(PicClause = "9(10)V9(5)", Length = 16, DecimalPlaces = 5, FieldType = CobolFieldType.PackedDecimal)]
    [Column(TypeName = "decimal(15,5)")]
    public decimal NetPremiumItem { get; set; }  // V0PREM-VLPRMLIQ-IT

    [CobolField(PicClause = "9(10)V9(5)", Length = 16, DecimalPlaces = 5, FieldType = CobolFieldType.PackedDecimal)]
    [Column(TypeName = "decimal(15,5)")]
    public decimal AdditionalFractionalItem { get; set; }  // V0PREM-VLADIFRA-IT

    [CobolField(PicClause = "9(10)V9(5)", Length = 16, DecimalPlaces = 5, FieldType = CobolFieldType.PackedDecimal)]
    [Column(TypeName = "decimal(15,5)")]
    public decimal IssuanceCostItem { get; set; }  // V0PREM-VLCUSEMI-IT

    [CobolField(PicClause = "9(10)V9(5)", Length = 16, DecimalPlaces = 5, FieldType = CobolFieldType.PackedDecimal)]
    [Column(TypeName = "decimal(15,5)")]
    public decimal IofItem { get; set; }  // V0PREM-VLIOCC-IT

    [CobolField(PicClause = "9(10)V9(5)", Length = 16, DecimalPlaces = 5, FieldType = CobolFieldType.PackedDecimal)]
    [Column(TypeName = "decimal(15,5)")]
    public decimal TotalPremiumItem { get; set; }  // V0PREM-VLPRMTOT-IT

    [CobolField(PicClause = "9(10)V9(5)", Length = 16, DecimalPlaces = 5, FieldType = CobolFieldType.PackedDecimal)]
    [Column(TypeName = "decimal(15,5)")]
    public decimal CommissionItem { get; set; }  // V0PREM-VLCOMIS-IT

    [CobolField(PicClause = "9(10)V9(5)", Length = 16, DecimalPlaces = 5, FieldType = CobolFieldType.PackedDecimal)]
    [Column(TypeName = "decimal(15,5)")]
    public decimal AdministrationFeeItem { get; set; }  // V0PREM-VLADMN-IT

    [CobolField(PicClause = "9(10)V9(5)", Length = 16, DecimalPlaces = 5, FieldType = CobolFieldType.PackedDecimal)]
    [Column(TypeName = "decimal(15,5)")]
    public decimal AgencyCommissionItem { get; set; }  // V0PREM-VLAGENC-IT

    [CobolField(PicClause = "9(10)V9(5)", Length = 16, DecimalPlaces = 5, FieldType = CobolFieldType.PackedDecimal)]
    [Column(TypeName = "decimal(15,5)")]
    public decimal PreferentialCommissionItem { get; set; }  // V0PREM-VLPREFCM-IT

    // Premium Components - Net (Liquido)
    [CobolField(PicClause = "9(10)V9(5)", Length = 16, DecimalPlaces = 5, FieldType = CobolFieldType.PackedDecimal)]
    [Column(TypeName = "decimal(15,5)")]
    public decimal InsuredAmountNet { get; set; }  // V0PREM-IMP-SEG-IL

    [CobolField(PicClause = "9(10)V9(5)", Length = 16, DecimalPlaces = 5, FieldType = CobolFieldType.PackedDecimal)]
    [Column(TypeName = "decimal(15,5)")]
    public decimal BasePremiumNet { get; set; }  // V0PREM-VLPRMBAS-IL

    [CobolField(PicClause = "9(10)V9(5)", Length = 16, DecimalPlaces = 5, FieldType = CobolFieldType.PackedDecimal)]
    [Column(TypeName = "decimal(15,5)")]
    public decimal FixedPremiumNet { get; set; }  // V0PREM-VLPREFIX-IL

    [CobolField(PicClause = "9(10)V9(5)", Length = 16, DecimalPlaces = 5, FieldType = CobolFieldType.PackedDecimal)]
    [Column(TypeName = "decimal(15,5)")]
    public decimal TariffPremiumNet { get; set; }  // V0PREM-VLPRMTAR-IL

    [CobolField(PicClause = "9(10)V9(5)", Length = 16, DecimalPlaces = 5, FieldType = CobolFieldType.PackedDecimal)]
    [Column(TypeName = "decimal(15,5)")]
    public decimal DiscountNet { get; set; }  // V0PREM-VLDESCON-IL

    [CobolField(PicClause = "9(10)V9(5)", Length = 16, DecimalPlaces = 5, FieldType = CobolFieldType.PackedDecimal)]
    [Column(TypeName = "decimal(15,5)")]
    public decimal NetPremiumNet { get; set; }  // V0PREM-VLPRMLIQ-IL

    [CobolField(PicClause = "9(10)V9(5)", Length = 16, DecimalPlaces = 5, FieldType = CobolFieldType.PackedDecimal)]
    [Column(TypeName = "decimal(15,5)")]
    public decimal AdditionalFractionalNet { get; set; }  // V0PREM-VLADIFRA-IL

    [CobolField(PicClause = "9(10)V9(5)", Length = 16, DecimalPlaces = 5, FieldType = CobolFieldType.PackedDecimal)]
    [Column(TypeName = "decimal(15,5)")]
    public decimal IssuanceCostNet { get; set; }  // V0PREM-VLCUSEMI-IL

    [CobolField(PicClause = "9(10)V9(5)", Length = 16, DecimalPlaces = 5, FieldType = CobolFieldType.PackedDecimal)]
    [Column(TypeName = "decimal(15,5)")]
    public decimal IofNet { get; set; }  // V0PREM-VLIOCC-IL

    [CobolField(PicClause = "9(10)V9(5)", Length = 16, DecimalPlaces = 5, FieldType = CobolFieldType.PackedDecimal)]
    [Column(TypeName = "decimal(15,5)")]
    public decimal TotalPremiumNet { get; set; }  // V0PREM-VLPRMTOT-IL

    [CobolField(PicClause = "9(10)V9(5)", Length = 16, DecimalPlaces = 5, FieldType = CobolFieldType.PackedDecimal)]
    [Column(TypeName = "decimal(15,5)")]
    public decimal CommissionNet { get; set; }  // V0PREM-VLCOMIS-IL

    [CobolField(PicClause = "9(10)V9(5)", Length = 16, DecimalPlaces = 5, FieldType = CobolFieldType.PackedDecimal)]
    [Column(TypeName = "decimal(15,5)")]
    public decimal AdministrationFeeNet { get; set; }  // V0PREM-VLADMN-IL

    [CobolField(PicClause = "9(10)V9(5)", Length = 16, DecimalPlaces = 5, FieldType = CobolFieldType.PackedDecimal)]
    [Column(TypeName = "decimal(15,5)")]
    public decimal AgencyCommissionNet { get; set; }  // V0PREM-VLAGENC-IL

    [CobolField(PicClause = "9(10)V9(5)", Length = 16, DecimalPlaces = 5, FieldType = CobolFieldType.PackedDecimal)]
    [Column(TypeName = "decimal(15,5)")]
    public decimal PreferentialCommissionNet { get; set; }  // V0PREM-VLPREFCM-IL

    // Premium Components - Cossurance (Cosseguro)
    [CobolField(PicClause = "9(10)V9(5)", Length = 16, DecimalPlaces = 5, FieldType = CobolFieldType.PackedDecimal)]
    [Column(TypeName = "decimal(15,5)")]
    public decimal InsuredAmountCossurance { get; set; }  // V0PREM-IMP-SEG-IC

    [CobolField(PicClause = "9(10)V9(5)", Length = 16, DecimalPlaces = 5, FieldType = CobolFieldType.PackedDecimal)]
    [Column(TypeName = "decimal(15,5)")]
    public decimal BasePremiumCossurance { get; set; }  // V0PREM-VLPRMBAS-IC

    [CobolField(PicClause = "9(10)V9(5)", Length = 16, DecimalPlaces = 5, FieldType = CobolFieldType.PackedDecimal)]
    [Column(TypeName = "decimal(15,5)")]
    public decimal FixedPremiumCossurance { get; set; }  // V0PREM-VLPREFIX-IC

    [CobolField(PicClause = "9(10)V9(5)", Length = 16, DecimalPlaces = 5, FieldType = CobolFieldType.PackedDecimal)]
    [Column(TypeName = "decimal(15,5)")]
    public decimal TariffPremiumCossurance { get; set; }  // V0PREM-VLPRMTAR-IC

    [CobolField(PicClause = "9(10)V9(5)", Length = 16, DecimalPlaces = 5, FieldType = CobolFieldType.PackedDecimal)]
    [Column(TypeName = "decimal(15,5)")]
    public decimal DiscountCossurance { get; set; }  // V0PREM-VLDESCON-IC

    [CobolField(PicClause = "9(10)V9(5)", Length = 16, DecimalPlaces = 5, FieldType = CobolFieldType.PackedDecimal)]
    [Column(TypeName = "decimal(15,5)")]
    public decimal NetPremiumCossurance { get; set; }  // V0PREM-VLPRMLIQ-IC

    [CobolField(PicClause = "9(10)V9(5)", Length = 16, DecimalPlaces = 5, FieldType = CobolFieldType.PackedDecimal)]
    [Column(TypeName = "decimal(15,5)")]
    public decimal AdditionalFractionalCossurance { get; set; }  // V0PREM-VLADIFRA-IC

    [CobolField(PicClause = "9(10)V9(5)", Length = 16, DecimalPlaces = 5, FieldType = CobolFieldType.PackedDecimal)]
    [Column(TypeName = "decimal(15,5)")]
    public decimal CommissionCossurance { get; set; }  // V0PREM-VLCOMIS-IC

    [CobolField(PicClause = "9(10)V9(5)", Length = 16, DecimalPlaces = 5, FieldType = CobolFieldType.PackedDecimal)]
    [Column(TypeName = "decimal(15,5)")]
    public decimal AdministrationFeeCossurance { get; set; }  // V0PREM-VLADMN-IC

    [CobolField(PicClause = "9(10)V9(5)", Length = 16, DecimalPlaces = 5, FieldType = CobolFieldType.PackedDecimal)]
    [Column(TypeName = "decimal(15,5)")]
    public decimal AgencyCommissionCossurance { get; set; }  // V0PREM-VLAGENC-IC

    [CobolField(PicClause = "9(10)V9(5)", Length = 16, DecimalPlaces = 5, FieldType = CobolFieldType.PackedDecimal)]
    [Column(TypeName = "decimal(15,5)")]
    public decimal PreferentialCommissionCossurance { get; set; }  // V0PREM-VLPREFCM-IC

    // Premium Components - Reinsurance
    [CobolField(PicClause = "9(10)V9(5)", Length = 16, DecimalPlaces = 5, FieldType = CobolFieldType.PackedDecimal)]
    [Column(TypeName = "decimal(15,5)")]
    public decimal InsuredAmountReinsurance { get; set; }  // V0PREM-IMP-SEG-IR

    [CobolField(PicClause = "9(10)V9(5)", Length = 16, DecimalPlaces = 5, FieldType = CobolFieldType.PackedDecimal)]
    [Column(TypeName = "decimal(15,5)")]
    public decimal TariffPremiumReinsurance { get; set; }  // V0PREM-VLPRMTAR-IR

    [CobolField(PicClause = "9(10)V9(5)", Length = 16, DecimalPlaces = 5, FieldType = CobolFieldType.PackedDecimal)]
    [Column(TypeName = "decimal(15,5)")]
    public decimal DiscountReinsurance { get; set; }  // V0PREM-VLDESCON-IR

    [CobolField(PicClause = "9(10)V9(5)", Length = 16, DecimalPlaces = 5, FieldType = CobolFieldType.PackedDecimal)]
    [Column(TypeName = "decimal(15,5)")]
    public decimal NetPremiumReinsurance { get; set; }  // V0PREM-VLPRMLIQ-IR

    [CobolField(PicClause = "9(10)V9(5)", Length = 16, DecimalPlaces = 5, FieldType = CobolFieldType.PackedDecimal)]
    [Column(TypeName = "decimal(15,5)")]
    public decimal AdditionalFractionalReinsurance { get; set; }  // V0PREM-VLADIFRA-IR

    [CobolField(PicClause = "9(10)V9(5)", Length = 16, DecimalPlaces = 5, FieldType = CobolFieldType.PackedDecimal)]
    [Column(TypeName = "decimal(15,5)")]
    public decimal CommissionReinsurance { get; set; }  // V0PREM-VLCOMIS-IR

    // Premium Totals
    [CobolField(PicClause = "9(13)V99", Length = 15, DecimalPlaces = 2, FieldType = CobolFieldType.PackedDecimal)]
    [Column(TypeName = "decimal(15,2)")]
    public decimal InsuredAmountTotal { get; set; }  // V0PREM-IMP-SEG-T

    [CobolField(PicClause = "9(13)V99", Length = 15, DecimalPlaces = 2, FieldType = CobolFieldType.PackedDecimal)]
    [Column(TypeName = "decimal(15,2)")]
    public decimal BasePremiumTotal { get; set; }  // V0PREM-VLPRMBAS-T

    [CobolField(PicClause = "9(13)V99", Length = 15, DecimalPlaces = 2, FieldType = CobolFieldType.PackedDecimal)]
    [Column(TypeName = "decimal(15,2)")]
    public decimal FixedPremiumTotal { get; set; }  // V0PREM-VLPREFIX-T

    [CobolField(PicClause = "9(13)V99", Length = 15, DecimalPlaces = 2, FieldType = CobolFieldType.PackedDecimal)]
    [Column(TypeName = "decimal(15,2)")]
    public decimal TariffPremiumTotal { get; set; }  // V0PREM-VLPRMTAR-T

    [CobolField(PicClause = "9(13)V99", Length = 15, DecimalPlaces = 2, FieldType = CobolFieldType.PackedDecimal)]
    [Column(TypeName = "decimal(15,2)")]
    public decimal DiscountTotal { get; set; }  // V0PREM-VLDESCON-T

    [CobolField(PicClause = "9(13)V99", Length = 15, DecimalPlaces = 2, FieldType = CobolFieldType.PackedDecimal)]
    [Column(TypeName = "decimal(15,2)")]
    public decimal NetPremiumTotal { get; set; }  // V0PREM-VLPRMLIQ-T

    [CobolField(PicClause = "9(13)V99", Length = 15, DecimalPlaces = 2, FieldType = CobolFieldType.PackedDecimal)]
    [Column(TypeName = "decimal(15,2)")]
    public decimal AdditionalFractionalTotal { get; set; }  // V0PREM-VLADIFRA-T

    [CobolField(PicClause = "9(13)V99", Length = 15, DecimalPlaces = 2, FieldType = CobolFieldType.PackedDecimal)]
    [Column(TypeName = "decimal(15,2)")]
    public decimal IssuanceCostTotal { get; set; }  // V0PREM-VLCUSEMI-T

    [CobolField(PicClause = "9(13)V99", Length = 15, DecimalPlaces = 2, FieldType = CobolFieldType.PackedDecimal)]
    [Column(TypeName = "decimal(15,2)")]
    public decimal IofTotal { get; set; }  // V0PREM-VLIOCC-T

    [CobolField(PicClause = "9(13)V99", Length = 15, DecimalPlaces = 2, FieldType = CobolFieldType.PackedDecimal)]
    [Column(TypeName = "decimal(15,2)")]
    public decimal TotalPremiumTotal { get; set; }  // V0PREM-VLPRMTOT-T

    [CobolField(PicClause = "9(13)V99", Length = 15, DecimalPlaces = 2, FieldType = CobolFieldType.PackedDecimal)]
    [Column(TypeName = "decimal(15,2)")]
    public decimal CommissionTotal { get; set; }  // V0PREM-VLCOMIS-T

    [CobolField(PicClause = "9(13)V99", Length = 15, DecimalPlaces = 2, FieldType = CobolFieldType.PackedDecimal)]
    [Column(TypeName = "decimal(15,2)")]
    public decimal AdministrationFeeTotal { get; set; }  // V0PREM-VLADMN-T

    [CobolField(PicClause = "9(13)V99", Length = 15, DecimalPlaces = 2, FieldType = CobolFieldType.PackedDecimal)]
    [Column(TypeName = "decimal(15,2)")]
    public decimal AgencyCommissionTotal { get; set; }  // V0PREM-VLAGENC-T

    [CobolField(PicClause = "9(13)V99", Length = 15, DecimalPlaces = 2, FieldType = CobolFieldType.PackedDecimal)]
    [Column(TypeName = "decimal(15,2)")]
    public decimal PreferentialCommissionTotal { get; set; }  // V0PREM-VLPREFCM-T

    // Net Local Currency Totals
    [CobolField(PicClause = "9(13)V99", Length = 15, DecimalPlaces = 2, FieldType = CobolFieldType.PackedDecimal)]
    [Column(TypeName = "decimal(15,2)")]
    public decimal InsuredAmountLocalTotal { get; set; }  // V0PREM-IMP-SEG-L

    [CobolField(PicClause = "9(13)V99", Length = 15, DecimalPlaces = 2, FieldType = CobolFieldType.PackedDecimal)]
    [Column(TypeName = "decimal(15,2)")]
    public decimal BasePremiumLocalTotal { get; set; }  // V0PREM-VLPRMBAS-L

    [CobolField(PicClause = "9(13)V99", Length = 15, DecimalPlaces = 2, FieldType = CobolFieldType.PackedDecimal)]
    [Column(TypeName = "decimal(15,2)")]
    public decimal FixedPremiumLocalTotal { get; set; }  // V0PREM-VLPREFIX-L

    // Navigation Properties
    public Policy Policy { get; set; }
    public Product Product { get; set; }
    public Client Client { get; set; }
    public Endorsement Endorsement { get; set; }
}
```

#### Validation Rules
1. `PolicyNumber` must exist in `Policy` entity
2. `EndorsementNumber` > 0 indicates endorsement-related premium
3. `ReferenceYear` must be >= 2000
4. `ReferenceMonth` must be 1-12
5. `ReferenceDay` must be 1-31
6. `MovementType` must be in `['E', 'C', 'R', 'S', 'A']` (Emission, Cancellation, Reversal, Supplement, Adjustment)
7. All financial totals must equal sum of corresponding item/net/cossurance/reinsurance components

#### EF Core Configuration

```csharp
public class PremiumRecordConfiguration : IEntityTypeConfiguration<PremiumRecord>
{
    public void Configure(EntityTypeBuilder<PremiumRecord> builder)
    {
        builder.ToView("V0PREMIOS");
        builder.HasKey(p => p.PremiumId);

        // Indexes for cursor processing (COBOL WHERE clause equivalents)
        builder.HasIndex(p => new { p.CompanyCode, p.ReferenceYear, p.ReferenceMonth, p.ReferenceDay })
            .HasDatabaseName("IX_V0PREMIOS_DateRange");

        builder.HasIndex(p => p.PolicyNumber)
            .HasDatabaseName("IX_V0PREMIOS_PolicyNumber");

        // Relationships
        builder.HasOne(p => p.Policy)
            .WithMany()
            .HasForeignKey(p => p.PolicyNumber)
            .OnDelete(DeleteBehavior.Restrict);

        builder.HasOne(p => p.Client)
            .WithMany()
            .HasForeignKey(p => p.ClientCode)
            .OnDelete(DeleteBehavior.Restrict);
    }
}
```

---

### 2. Policy (V0APOLICE)

**Purpose**: Insurance policy master data containing contract information, effective dates, and status.

**COBOL Source**: `V0APOLICE` view, accessed at sections R0980-00-SELECT-V0APOLICE, R0990-00-SELECT-EF-APOLICE

#### Properties

```csharp
public class Policy
{
    [Key]
    [CobolField(PicClause = "9(13)", Length = 13, FieldType = CobolFieldType.PackedDecimal)]
    public long PolicyNumber { get; set; }  // NUM_APOLICE

    [CobolField(PicClause = "9(9)", Length = 9)]
    public int CompanyCode { get; set; }  // COD_EMP

    [CobolField(PicClause = "9(4)", Length = 4)]
    public int ProductCode { get; set; }  // COD_PROD

    [CobolField(PicClause = "9(9)", Length = 9)]
    public int ClientCode { get; set; }  // COD_CLIEN (Policyholder)

    [CobolField(PicClause = "X(10)", Length = 10)]
    [MaxLength(10)]
    public string EffectiveDate { get; set; }  // DT_INIVIG (YYYY-MM-DD)

    public DateTime EffectiveDateParsed => DateTime.ParseExact(EffectiveDate, "yyyy-MM-dd", CultureInfo.InvariantCulture);

    [CobolField(PicClause = "X(10)", Length = 10)]
    [MaxLength(10)]
    public string ExpirationDate { get; set; }  // DT_FIMVIG

    public DateTime ExpirationDateParsed => DateTime.ParseExact(ExpirationDate, "yyyy-MM-dd", CultureInfo.InvariantCulture);

    [CobolField(PicClause = "X(10)", Length = 10)]
    [MaxLength(10)]
    public string IssuanceDate { get; set; }  // DT_EMIS

    public DateTime IssuanceDateParsed => DateTime.ParseExact(IssuanceDate, "yyyy-MM-dd", CultureInfo.InvariantCulture);

    [CobolField(PicClause = "X(10)", Length = 10)]
    [MaxLength(10)]
    public string ProposalDate { get; set; }  // DT_PROPT

    [CobolField(PicClause = "X(1)", Length = 1)]
    [MaxLength(1)]
    public string PolicyStatus { get; set; }  // IND_SITUACAO ('A'=Active, 'C'=Cancelled, etc.)

    [CobolField(PicClause = "9(4)", Length = 4)]
    public int AgencyCode { get; set; }  // COD_AGENC

    [CobolField(PicClause = "9(9)", Length = 9)]
    public int ProducerCode { get; set; }  // COD_PRODU

    [CobolField(PicClause = "9(13)", Length = 13)]
    public long ProposalNumber { get; set; }  // NUM_PROPT

    [CobolField(PicClause = "9(4)", Length = 4)]
    public int LineOfBusiness { get; set; }  // RAMO_SUSEP

    [CobolField(PicClause = "9(13)V99", Length = 15, DecimalPlaces = 2, FieldType = CobolFieldType.PackedDecimal)]
    [Column(TypeName = "decimal(15,2)")]
    public decimal InsuredAmount { get; set; }  // IMP_SEG

    [CobolField(PicClause = "9(13)V99", Length = 15, DecimalPlaces = 2, FieldType = CobolFieldType.PackedDecimal)]
    [Column(TypeName = "decimal(15,2)")]
    public decimal TotalPremium { get; set; }  // VL_PRM_TOT

    [CobolField(PicClause = "9(4)", Length = 4)]
    public int RenewalType { get; set; }  // TIP_RENOV

    // Navigation Properties
    public Product Product { get; set; }
    public Client Policyholder { get; set; }
    public Agency Agency { get; set; }
    public Producer Producer { get; set; }
    public ICollection<Endorsement> Endorsements { get; set; }
    public ICollection<Coverage> Coverages { get; set; }
}
```

#### Validation Rules
1. `EffectiveDate` must be <= `ExpirationDate`
2. `IssuanceDate` should be <= `EffectiveDate` (with exceptions for specific products)
3. `PolicyStatus` must be in `['A', 'C', 'S', 'E']` (Active, Cancelled, Suspended, Expired)
4. `PolicyNumber` must be unique per `CompanyCode`

#### EF Core Configuration

```csharp
public class PolicyConfiguration : IEntityTypeConfiguration<Policy>
{
    public void Configure(EntityTypeBuilder<Policy> builder)
    {
        builder.ToView("V0APOLICE");
        builder.HasKey(p => p.PolicyNumber);

        builder.HasIndex(p => new { p.CompanyCode, p.ProductCode })
            .HasDatabaseName("IX_V0APOLICE_Product");

        builder.HasIndex(p => p.ClientCode)
            .HasDatabaseName("IX_V0APOLICE_Client");

        builder.HasOne(p => p.Product)
            .WithMany()
            .HasForeignKey(p => p.ProductCode)
            .OnDelete(DeleteBehavior.Restrict);

        builder.HasOne(p => p.Policyholder)
            .WithMany()
            .HasForeignKey(p => p.ClientCode)
            .OnDelete(DeleteBehavior.Restrict);

        builder.HasOne(p => p.Agency)
            .WithMany()
            .HasForeignKey(p => p.AgencyCode)
            .OnDelete(DeleteBehavior.Restrict);

        builder.HasOne(p => p.Producer)
            .WithMany()
            .HasForeignKey(p => p.ProducerCode)
            .OnDelete(DeleteBehavior.Restrict);
    }
}
```

---

### 3. Endorsement (V0ENDOSSO)

**Purpose**: Policy modifications (endorsements) that alter coverage, premium, or other policy terms.

**COBOL Source**: `V0ENDOSSO` view, accessed at sections R0760-00-SELECT-V0ENDOSSO, R0780-00-SELECT-ENDOS-CANCLM

#### Properties

```csharp
public class Endorsement
{
    [Key]
    public long EndorsementId { get; set; }

    [CobolField(PicClause = "9(13)", Length = 13, FieldType = CobolFieldType.PackedDecimal)]
    public long PolicyNumber { get; set; }  // NUM_APOLICE

    [CobolField(PicClause = "9(9)", Length = 9)]
    public int EndorsementNumber { get; set; }  // NUM_ENDOS

    [CobolField(PicClause = "X(10)", Length = 10)]
    [MaxLength(10)]
    public string EndorsementDate { get; set; }  // DT_ENDOS

    public DateTime EndorsementDateParsed => DateTime.ParseExact(EndorsementDate, "yyyy-MM-dd", CultureInfo.InvariantCulture);

    [CobolField(PicClause = "9(4)", Length = 4)]
    public int EndorsementType { get; set; }  // TIP_ENDOS

    [CobolField(PicClause = "X(1)", Length = 1)]
    [MaxLength(1)]
    public string EndorsementStatus { get; set; }  // IND_SITUACAO

    [CobolField(PicClause = "X(1)", Length = 1)]
    [MaxLength(1)]
    public string CancellationFlag { get; set; }  // IND_CANCELM ('S'/'N')

    [CobolField(PicClause = "X(10)", Length = 10)]
    [MaxLength(10)]
    public string CancellationDate { get; set; }  // DT_CANCELM

    [CobolField(PicClause = "9(13)V99", Length = 15, DecimalPlaces = 2, FieldType = CobolFieldType.PackedDecimal)]
    [Column(TypeName = "decimal(15,2)")]
    public decimal PremiumImpact { get; set; }  // VL_PRM_ENDOS (can be negative for cancellations)

    [CobolField(PicClause = "9(13)V99", Length = 15, DecimalPlaces = 2, FieldType = CobolFieldType.PackedDecimal)]
    [Column(TypeName = "decimal(15,2)")]
    public decimal InsuredAmountChange { get; set; }  // IMP_SEG_ENDOS

    [CobolField(PicClause = "9(4)", Length = 4)]
    public int CancellationReason { get; set; }  // COD_MOTIVO_CANCEL

    [CobolField(PicClause = "X(200)", Length = 200)]
    [MaxLength(200)]
    public string EndorsementDescription { get; set; }  // DES_ENDOS

    // Navigation Properties
    public Policy Policy { get; set; }
}
```

#### Validation Rules
1. `PolicyNumber` must exist in `Policy` entity
2. `EndorsementNumber` must be > 0
3. `CancellationFlag` must be 'S' or 'N'
4. If `CancellationFlag` = 'S', `CancellationDate` must not be null
5. `EndorsementDate` must be >= Policy `EffectiveDate`

#### EF Core Configuration

```csharp
public class EndorsementConfiguration : IEntityTypeConfiguration<Endorsement>
{
    public void Configure(EntityTypeBuilder<Endorsement> builder)
    {
        builder.ToView("V0ENDOSSO");
        builder.HasKey(e => e.EndorsementId);

        builder.HasIndex(e => new { e.PolicyNumber, e.EndorsementNumber })
            .IsUnique()
            .HasDatabaseName("IX_V0ENDOSSO_PolicyEndorsement");

        builder.HasIndex(e => e.CancellationFlag)
            .HasDatabaseName("IX_V0ENDOSSO_Cancellation");

        builder.HasOne(e => e.Policy)
            .WithMany(p => p.Endorsements)
            .HasForeignKey(e => e.PolicyNumber)
            .OnDelete(DeleteBehavior.Restrict);
    }
}
```

---

### 4. Product (V0PRODUTO, V0PRODUTOSVG)

**Purpose**: Insurance product definitions including SUSEP codes, line of business classification, and product metadata.

**COBOL Source**: `V0PRODUTO` view (R0740-00-SELECT-V0PRODUTO), `V0PRODUTOSVG` view (R1020-00-SELECT-V0PRODUTOSVG)

#### Properties

```csharp
public class Product
{
    [Key]
    [CobolField(PicClause = "9(4)", Length = 4)]
    public int ProductCode { get; set; }  // COD_PROD

    [CobolField(PicClause = "9(9)", Length = 9)]
    public int CompanyCode { get; set; }  // COD_EMP

    [CobolField(PicClause = "X(100)", Length = 100)]
    [MaxLength(100)]
    public string ProductName { get; set; }  // NOM_PROD

    [CobolField(PicClause = "9(4)", Length = 4)]
    public int LineOfBusiness { get; set; }  // RAMO_SUSEP

    [CobolField(PicClause = "9(4)", Length = 4)]
    public int LineOfBusinessGroup { get; set; }  // GRUPO_RAMO_SUSEP

    [CobolField(PicClause = "X(20)", Length = 20)]
    [MaxLength(20)]
    public string SusepProcessNumber { get; set; }  // NUM_PROC_SUSEP

    [CobolField(PicClause = "X(1)", Length = 1)]
    [MaxLength(1)]
    public string ProductType { get; set; }  // TIP_PROD ('A'=Auto, 'V'=Vida, 'R'=Residencial, etc.)

    [CobolField(PicClause = "X(1)", Length = 1)]
    [MaxLength(1)]
    public string ProductStatus { get; set; }  // IND_SITUACAO ('A'=Active, 'I'=Inactive)

    [CobolField(PicClause = "9(4)", Length = 4)]
    public int ProductModality { get; set; }  // MODALIFR

    [CobolField(PicClause = "X(1)", Length = 1)]
    [MaxLength(1)]
    public string IsLifeInsurance { get; set; }  // IND_VIDA_GRUPO ('S'/'N')

    // Navigation Properties
    public ICollection<Policy> Policies { get; set; }
}
```

#### Validation Rules
1. `ProductCode` must be unique per `CompanyCode`
2. `LineOfBusiness` must be valid SUSEP code (e.g., 0118 = Auto, 0969 = Vida Individual)
3. `ProductStatus` must be in `['A', 'I', 'S']` (Active, Inactive, Suspended)
4. `SusepProcessNumber` format must match SUSEP standards (e.g., "15414.900XXX/XXXX-XX")

#### EF Core Configuration

```csharp
public class ProductConfiguration : IEntityTypeConfiguration<Product>
{
    public void Configure(EntityTypeBuilder<Product> builder)
    {
        builder.ToView("V0PRODUTO");
        builder.HasKey(p => p.ProductCode);

        builder.HasIndex(p => new { p.CompanyCode, p.LineOfBusiness })
            .HasDatabaseName("IX_V0PRODUTO_LineOfBusiness");

        builder.HasIndex(p => p.ProductStatus)
            .HasDatabaseName("IX_V0PRODUTO_Status");
    }
}
```

---

### 5. Client (V0CLIENTE, V0TOMADOR)

**Purpose**: Customer/party information for policyholders, insured parties, and beneficiaries.

**COBOL Source**: `V0CLIENTE` view (R0960-00-SELECT-V0CLIENTE), `V0TOMADOR` view (R1140-00-SELECT-V0TOMADOR)

#### Properties

```csharp
public class Client
{
    [Key]
    [CobolField(PicClause = "9(9)", Length = 9)]
    public int ClientCode { get; set; }  // COD_CLIEN

    [CobolField(PicClause = "9(9)", Length = 9)]
    public int CompanyCode { get; set; }  // COD_EMP

    [CobolField(PicClause = "X(100)", Length = 100)]
    [MaxLength(100)]
    public string ClientName { get; set; }  // NOM_CLIEN

    [CobolField(PicClause = "X(1)", Length = 1)]
    [MaxLength(1)]
    public string ClientType { get; set; }  // TIP_PESSOA ('F'=Fisica/Person, 'J'=Juridica/Company)

    [CobolField(PicClause = "X(14)", Length = 14)]
    [MaxLength(14)]
    public string DocumentNumber { get; set; }  // NUM_CPF_CNPJ (CPF or CNPJ)

    [CobolField(PicClause = "X(20)", Length = 20)]
    [MaxLength(20)]
    public string IdentityDocument { get; set; }  // NUM_RG_IE

    [CobolField(PicClause = "X(10)", Length = 10)]
    [MaxLength(10)]
    public string BirthDate { get; set; }  // DT_NASC (YYYY-MM-DD)

    public DateTime? BirthDateParsed => string.IsNullOrWhiteSpace(BirthDate)
        ? null
        : DateTime.ParseExact(BirthDate, "yyyy-MM-dd", CultureInfo.InvariantCulture);

    [CobolField(PicClause = "X(1)", Length = 1)]
    [MaxLength(1)]
    public string Gender { get; set; }  // IND_SEXO ('M', 'F')

    [CobolField(PicClause = "X(50)", Length = 50)]
    [MaxLength(50)]
    public string Email { get; set; }  // DES_EMAIL

    [CobolField(PicClause = "X(20)", Length = 20)]
    [MaxLength(20)]
    public string PhoneNumber { get; set; }  // NUM_FONE

    [CobolField(PicClause = "X(1)", Length = 1)]
    [MaxLength(1)]
    public string ClientStatus { get; set; }  // IND_SITUACAO ('A'=Active, 'I'=Inactive)

    // Navigation Properties
    public ICollection<Address> Addresses { get; set; }
}
```

#### Validation Rules
1. `ClientCode` must be unique per `CompanyCode`
2. `ClientType` must be 'F' or 'J'
3. If `ClientType` = 'F', `DocumentNumber` must be valid CPF (11 digits)
4. If `ClientType` = 'J', `DocumentNumber` must be valid CNPJ (14 digits)
5. `Email` must match email format regex if not null
6. `Gender` must be in `['M', 'F', 'O']` (Male, Female, Other)

#### EF Core Configuration

```csharp
public class ClientConfiguration : IEntityTypeConfiguration<Client>
{
    public void Configure(EntityTypeBuilder<Client> builder)
    {
        builder.ToView("V0CLIENTE");
        builder.HasKey(c => c.ClientCode);

        builder.HasIndex(c => c.DocumentNumber)
            .IsUnique()
            .HasDatabaseName("IX_V0CLIENTE_DocumentNumber");

        builder.HasIndex(c => c.ClientType)
            .HasDatabaseName("IX_V0CLIENTE_Type");
    }
}
```

---

### 6. Address (V0ENDERECOS)

**Purpose**: Address information for clients, agencies, and other parties. COBOL uses cursor processing for multiple addresses per client.

**COBOL Source**: `V0ENDERECOS` view, cursor declared at R1230-00-DECLARE-V0ENDERECOS, fetched at R1240-00-FETCH-V0ENDERECOS

#### Properties

```csharp
public class Address
{
    [Key]
    public long AddressId { get; set; }

    [CobolField(PicClause = "9(9)", Length = 9)]
    public int ClientCode { get; set; }  // COD_CLIEN

    [CobolField(PicClause = "9(4)", Length = 4)]
    public int AddressSequence { get; set; }  // SEQ_ENDER

    [CobolField(PicClause = "X(1)", Length = 1)]
    [MaxLength(1)]
    public string AddressType { get; set; }  // TIP_ENDER ('R'=Residential, 'C'=Commercial, etc.)

    [CobolField(PicClause = "X(100)", Length = 100)]
    [MaxLength(100)]
    public string StreetAddress { get; set; }  // DES_LOGRADOURO

    [CobolField(PicClause = "X(10)", Length = 10)]
    [MaxLength(10)]
    public string Number { get; set; }  // NUM_LOGRA

    [CobolField(PicClause = "X(50)", Length = 50)]
    [MaxLength(50)]
    public string Complement { get; set; }  // DES_COMPL

    [CobolField(PicClause = "X(50)", Length = 50)]
    [MaxLength(50)]
    public string Neighborhood { get; set; }  // DES_BAIRRO

    [CobolField(PicClause = "X(50)", Length = 50)]
    [MaxLength(50)]
    public string City { get; set; }  // NOM_MUNIC

    [CobolField(PicClause = "X(2)", Length = 2)]
    [MaxLength(2)]
    public string State { get; set; }  // COD_UF (e.g., 'SP', 'RJ')

    [CobolField(PicClause = "X(8)", Length = 8)]
    [MaxLength(8)]
    public string PostalCode { get; set; }  // NUM_CEP (Brazilian CEP format XXXXX-XXX)

    [CobolField(PicClause = "9(4)", Length = 4)]
    public int CountryCode { get; set; }  // COD_PAIS (default 1058 = Brazil)

    // Navigation Properties
    public Client Client { get; set; }
}
```

#### Validation Rules
1. `ClientCode` must exist in `Client` entity
2. `AddressSequence` must be > 0
3. Combination of `ClientCode` + `AddressSequence` must be unique
4. `State` must be valid Brazilian UF code (e.g., 'SP', 'RJ', 'MG')
5. `PostalCode` must match Brazilian CEP format (NNNNN-NNN)
6. `AddressType` must be in `['R', 'C', 'P', 'O']` (Residential, Commercial, Postal, Other)

#### EF Core Configuration

```csharp
public class AddressConfiguration : IEntityTypeConfiguration<Address>
{
    public void Configure(EntityTypeBuilder<Address> builder)
    {
        builder.ToView("V0ENDERECOS");
        builder.HasKey(a => a.AddressId);

        builder.HasIndex(a => new { a.ClientCode, a.AddressSequence })
            .IsUnique()
            .HasDatabaseName("IX_V0ENDERECOS_ClientSequence");

        builder.HasIndex(a => a.State)
            .HasDatabaseName("IX_V0ENDERECOS_State");

        builder.HasOne(a => a.Client)
            .WithMany(c => c.Addresses)
            .HasForeignKey(a => a.ClientCode)
            .OnDelete(DeleteBehavior.Restrict);
    }
}
```

---

### 7. Agency (V0AGENCIAS)

**Purpose**: Sales agency/branch information for distribution channel tracking.

**COBOL Source**: `V0AGENCIAS` view, accessed at R1180-00-SELECT-V0AGENCIAS

#### Properties

```csharp
public class Agency
{
    [Key]
    [CobolField(PicClause = "9(4)", Length = 4)]
    public int AgencyCode { get; set; }  // COD_AGENC

    [CobolField(PicClause = "9(9)", Length = 9)]
    public int CompanyCode { get; set; }  // COD_EMP

    [CobolField(PicClause = "X(100)", Length = 100)]
    [MaxLength(100)]
    public string AgencyName { get; set; }  // NOM_AGENC

    [CobolField(PicClause = "9(4)", Length = 4)]
    public int RegionCode { get; set; }  // COD_REGIAO

    [CobolField(PicClause = "X(2)", Length = 2)]
    [MaxLength(2)]
    public string State { get; set; }  // COD_UF

    [CobolField(PicClause = "X(1)", Length = 1)]
    [MaxLength(1)]
    public string ChannelType { get; set; }  // TIP_CANAL ('A'=Agency, 'C'=Call Center, 'W'=Web, etc.)

    [CobolField(PicClause = "X(1)", Length = 1)]
    [MaxLength(1)]
    public string AgencyStatus { get; set; }  // IND_SITUACAO ('A'=Active, 'I'=Inactive)

    // Navigation Properties
    public ICollection<Policy> Policies { get; set; }
}
```

#### Validation Rules
1. `AgencyCode` must be unique per `CompanyCode`
2. `State` must be valid Brazilian UF code
3. `ChannelType` must be in `['A', 'C', 'W', 'P']` (Agency, Call Center, Web, Partner)
4. `AgencyStatus` must be in `['A', 'I']`

#### EF Core Configuration

```csharp
public class AgencyConfiguration : IEntityTypeConfiguration<Agency>
{
    public void Configure(EntityTypeBuilder<Agency> builder)
    {
        builder.ToView("V0AGENCIAS");
        builder.HasKey(a => a.AgencyCode);

        builder.HasIndex(a => new { a.CompanyCode, a.RegionCode })
            .HasDatabaseName("IX_V0AGENCIAS_Region");
    }
}
```

---

### 8. Producer (V0PRODUTOR)

**Purpose**: Insurance broker/producer information for commission tracking and distribution management.

**COBOL Source**: `V0PRODUTOR` view, accessed at R1200-00-SELECT-V0PRODUTOR

#### Properties

```csharp
public class Producer
{
    [Key]
    [CobolField(PicClause = "9(9)", Length = 9)]
    public int ProducerCode { get; set; }  // COD_PRODU

    [CobolField(PicClause = "9(9)", Length = 9)]
    public int CompanyCode { get; set; }  // COD_EMP

    [CobolField(PicClause = "X(100)", Length = 100)]
    [MaxLength(100)]
    public string ProducerName { get; set; }  // NOM_PRODU

    [CobolField(PicClause = "X(14)", Length = 14)]
    [MaxLength(14)]
    public string DocumentNumber { get; set; }  // NUM_CPF_CNPJ

    [CobolField(PicClause = "X(20)", Length = 20)]
    [MaxLength(20)]
    public string SusepRegistration { get; set; }  // NUM_REG_SUSEP

    [CobolField(PicClause = "9(4)V99", Length = 6, DecimalPlaces = 2, FieldType = CobolFieldType.PackedDecimal)]
    [Column(TypeName = "decimal(6,2)")]
    public decimal CommissionRate { get; set; }  // PCT_COMIS (percentage)

    [CobolField(PicClause = "X(1)", Length = 1)]
    [MaxLength(1)]
    public string ProducerType { get; set; }  // TIP_PRODU ('C'=Corretor, 'A'=Agenciador, 'I'=Indicador)

    [CobolField(PicClause = "X(1)", Length = 1)]
    [MaxLength(1)]
    public string ProducerStatus { get; set; }  // IND_SITUACAO ('A'=Active, 'I'=Inactive)

    // Navigation Properties
    public ICollection<Policy> Policies { get; set; }
}
```

#### Validation Rules
1. `ProducerCode` must be unique per `CompanyCode`
2. `DocumentNumber` must be valid CPF or CNPJ
3. `SusepRegistration` format must match SUSEP broker registration standards
4. `CommissionRate` must be between 0.00 and 100.00
5. `ProducerType` must be in `['C', 'A', 'I']` (Corretor, Agenciador, Indicador)

#### EF Core Configuration

```csharp
public class ProducerConfiguration : IEntityTypeConfiguration<Producer>
{
    public void Configure(EntityTypeBuilder<Producer> builder)
    {
        builder.ToView("V0PRODUTOR");
        builder.HasKey(p => p.ProducerCode);

        builder.HasIndex(p => p.SusepRegistration)
            .IsUnique()
            .HasDatabaseName("IX_V0PRODUTOR_SusepReg");
    }
}
```

---

### 9. Coverage (V0COBERAPOL)

**Purpose**: Policy coverage details including insured amounts, rates, and coverage-specific premiums.

**COBOL Source**: `V0COBERAPOL` view, accessed at sections R0850-00-SELECT-V0COBERAPOL, R1250-00-SELECT-V0COBERAPOL

#### Properties

```csharp
public class Coverage
{
    [Key]
    public long CoverageId { get; set; }

    [CobolField(PicClause = "9(13)", Length = 13, FieldType = CobolFieldType.PackedDecimal)]
    public long PolicyNumber { get; set; }  // NUM_APOLICE

    [CobolField(PicClause = "9(4)", Length = 4)]
    public int CoverageCode { get; set; }  // COD_COBER

    [CobolField(PicClause = "X(100)", Length = 100)]
    [MaxLength(100)]
    public string CoverageName { get; set; }  // NOM_COBER

    [CobolField(PicClause = "9(13)V99", Length = 15, DecimalPlaces = 2, FieldType = CobolFieldType.PackedDecimal)]
    [Column(TypeName = "decimal(15,2)")]
    public decimal InsuredAmount { get; set; }  // IMP_SEG

    [CobolField(PicClause = "9(4)V9999", Length = 8, DecimalPlaces = 4, FieldType = CobolFieldType.PackedDecimal)]
    [Column(TypeName = "decimal(8,4)")]
    public decimal Rate { get; set; }  // PCT_TAXA (per thousand or percentage)

    [CobolField(PicClause = "9(13)V99", Length = 15, DecimalPlaces = 2, FieldType = CobolFieldType.PackedDecimal)]
    [Column(TypeName = "decimal(15,2)")]
    public decimal TariffPremium { get; set; }  // VL_PRM_TAR

    [CobolField(PicClause = "X(1)", Length = 1)]
    [MaxLength(1)]
    public string CoverageType { get; set; }  // TIP_COBER ('B'=Basica, 'A'=Adicional)

    [CobolField(PicClause = "X(1)", Length = 1)]
    [MaxLength(1)]
    public string IsMandatory { get; set; }  // IND_OBRIGAT ('S'/'N')

    // Navigation Properties
    public Policy Policy { get; set; }
}
```

#### Validation Rules
1. `PolicyNumber` must exist in `Policy` entity
2. `InsuredAmount` must be > 0 for active coverages
3. `Rate` must be >= 0
4. `CoverageType` must be in `['B', 'A']` (Basica, Adicional)
5. `IsMandatory` must be 'S' or 'N'

#### EF Core Configuration

```csharp
public class CoverageConfiguration : IEntityTypeConfiguration<Coverage>
{
    public void Configure(EntityTypeBuilder<Coverage> builder)
    {
        builder.ToView("V0COBERAPOL");
        builder.HasKey(c => c.CoverageId);

        builder.HasIndex(c => new { c.PolicyNumber, c.CoverageCode })
            .IsUnique()
            .HasDatabaseName("IX_V0COBERAPOL_PolicyCoverage");

        builder.HasOne(c => c.Policy)
            .WithMany(p => p.Coverages)
            .HasForeignKey(c => c.PolicyNumber)
            .OnDelete(DeleteBehavior.Restrict);
    }
}
```

---

### 10. Invoice (V0FATURAS)

**Purpose**: Billing invoice information for premium collection tracking.

**COBOL Source**: `V0FATURAS` view, accessed at R1060-00-SELECT-V0FATURAS

#### Properties

```csharp
public class Invoice
{
    [Key]
    [CobolField(PicClause = "9(13)", Length = 13)]
    public long InvoiceNumber { get; set; }  // NUM_FATURA

    [CobolField(PicClause = "9(13)", Length = 13, FieldType = CobolFieldType.PackedDecimal)]
    public long PolicyNumber { get; set; }  // NUM_APOLICE

    [CobolField(PicClause = "9(9)", Length = 9)]
    public int EndorsementNumber { get; set; }  // NUM_ENDOS

    [CobolField(PicClause = "X(10)", Length = 10)]
    [MaxLength(10)]
    public string InvoiceDate { get; set; }  // DT_FATURA

    public DateTime InvoiceDateParsed => DateTime.ParseExact(InvoiceDate, "yyyy-MM-dd", CultureInfo.InvariantCulture);

    [CobolField(PicClause = "X(10)", Length = 10)]
    [MaxLength(10)]
    public string DueDate { get; set; }  // DT_VENCTO

    public DateTime DueDateParsed => DateTime.ParseExact(DueDate, "yyyy-MM-dd", CultureInfo.InvariantCulture);

    [CobolField(PicClause = "9(13)V99", Length = 15, DecimalPlaces = 2, FieldType = CobolFieldType.PackedDecimal)]
    [Column(TypeName = "decimal(15,2)")]
    public decimal InvoiceAmount { get; set; }  // VL_FATURA

    [CobolField(PicClause = "9(4)", Length = 4)]
    public int NumberOfInstallments { get; set; }  // QTD_PARCELAS

    [CobolField(PicClause = "X(1)", Length = 1)]
    [MaxLength(1)]
    public string PaymentStatus { get; set; }  // IND_SITUACAO ('A'=Aguardando, 'P'=Pago, 'V'=Vencido)

    // Navigation Properties
    public Policy Policy { get; set; }
    public ICollection<Installment> Installments { get; set; }
}
```

#### Validation Rules
1. `PolicyNumber` must exist in `Policy` entity
2. `DueDate` must be >= `InvoiceDate`
3. `InvoiceAmount` must be > 0
4. `NumberOfInstallments` must be >= 1
5. `PaymentStatus` must be in `['A', 'P', 'V', 'C']` (Aguardando, Pago, Vencido, Cancelado)

#### EF Core Configuration

```csharp
public class InvoiceConfiguration : IEntityTypeConfiguration<Invoice>
{
    public void Configure(EntityTypeBuilder<Invoice> builder)
    {
        builder.ToView("V0FATURAS");
        builder.HasKey(i => i.InvoiceNumber);

        builder.HasIndex(i => new { i.PolicyNumber, i.EndorsementNumber })
            .HasDatabaseName("IX_V0FATURAS_PolicyEndorsement");

        builder.HasOne(i => i.Policy)
            .WithMany()
            .HasForeignKey(i => i.PolicyNumber)
            .OnDelete(DeleteBehavior.Restrict);
    }
}
```

---

### 11. Installment (V0HISTOPARC)

**Purpose**: Premium installment payment history for tracking collection status.

**COBOL Source**: `V0HISTOPARC` view, accessed at R0800-00-SELECT-V0HISTOPARC

#### Properties

```csharp
public class Installment
{
    [Key]
    public long InstallmentId { get; set; }

    [CobolField(PicClause = "9(13)", Length = 13)]
    public long InvoiceNumber { get; set; }  // NUM_FATURA

    [CobolField(PicClause = "9(4)", Length = 4)]
    public int InstallmentNumber { get; set; }  // NUM_PARCELA

    [CobolField(PicClause = "X(10)", Length = 10)]
    [MaxLength(10)]
    public string DueDate { get; set; }  // DT_VENCTO

    public DateTime DueDateParsed => DateTime.ParseExact(DueDate, "yyyy-MM-dd", CultureInfo.InvariantCulture);

    [CobolField(PicClause = "X(10)", Length = 10)]
    [MaxLength(10)]
    public string PaymentDate { get; set; }  // DT_PAGTO

    public DateTime? PaymentDateParsed => string.IsNullOrWhiteSpace(PaymentDate)
        ? null
        : DateTime.ParseExact(PaymentDate, "yyyy-MM-dd", CultureInfo.InvariantCulture);

    [CobolField(PicClause = "9(13)V99", Length = 15, DecimalPlaces = 2, FieldType = CobolFieldType.PackedDecimal)]
    [Column(TypeName = "decimal(15,2)")]
    public decimal InstallmentAmount { get; set; }  // VL_PARCELA

    [CobolField(PicClause = "9(13)V99", Length = 15, DecimalPlaces = 2, FieldType = CobolFieldType.PackedDecimal)]
    [Column(TypeName = "decimal(15,2)")]
    public decimal AmountPaid { get; set; }  // VL_PAGO

    [CobolField(PicClause = "X(1)", Length = 1)]
    [MaxLength(1)]
    public string PaymentStatus { get; set; }  // IND_SITUACAO ('P'=Pago, 'A'=Aguardando, 'V'=Vencido)

    // Navigation Properties
    public Invoice Invoice { get; set; }
}
```

#### Validation Rules
1. `InvoiceNumber` must exist in `Invoice` entity
2. `InstallmentNumber` must be > 0 and <= `Invoice.NumberOfInstallments`
3. If `PaymentStatus` = 'P', `PaymentDate` must not be null
4. `AmountPaid` must be <= `InstallmentAmount`
5. `PaymentStatus` must be in `['P', 'A', 'V', 'C']`

#### EF Core Configuration

```csharp
public class InstallmentConfiguration : IEntityTypeConfiguration<Installment>
{
    public void Configure(EntityTypeBuilder<Installment> builder)
    {
        builder.ToView("V0HISTOPARC");
        builder.HasKey(i => i.InstallmentId);

        builder.HasIndex(i => new { i.InvoiceNumber, i.InstallmentNumber })
            .IsUnique()
            .HasDatabaseName("IX_V0HISTOPARC_InvoiceInstallment");

        builder.HasOne(i => i.Invoice)
            .WithMany(inv => inv.Installments)
            .HasForeignKey(i => i.InvoiceNumber)
            .OnDelete(DeleteBehavior.Restrict);
    }
}
```

---

### 12. CossuredPolicy (V0APOLCOSCED)

**Purpose**: Cossurance and ceded reinsurance policy arrangements where risk is shared among multiple insurers.

**COBOL Source**: `V0APOLCOSCED` view, cursor declared at R4900-00-DECLARE-V0APOLCOSCED, fetched at R5000-00-FETCH-V0APOLCOSCED

#### Properties

```csharp
public class CossuredPolicy
{
    [Key]
    public long CossuranceId { get; set; }

    [CobolField(PicClause = "9(13)", Length = 13, FieldType = CobolFieldType.PackedDecimal)]
    public long PolicyNumber { get; set; }  // NUM_APOLICE

    [CobolField(PicClause = "9(4)", Length = 4)]
    public int CossuranceCode { get; set; }  // COD_COSSG

    [CobolField(PicClause = "X(1)", Length = 1)]
    [MaxLength(1)]
    public string CossuranceType { get; set; }  // TIP_COSSG ('C'=Cosseguro, 'R'=Resseguro, 'E'=Retrocessao)

    [CobolField(PicClause = "9(9)", Length = 9)]
    public int CedingCompanyCode { get; set; }  // COD_CIA_CEDENTE

    [CobolField(PicClause = "9(9)", Length = 9)]
    public int AcquiringCompanyCode { get; set; }  // COD_CIA_CESSIONARIA

    [CobolField(PicClause = "9(4)V9(9)", Length = 14, DecimalPlaces = 9, FieldType = CobolFieldType.PackedDecimal)]
    [Column(TypeName = "decimal(13,9)")]
    public decimal PercentageShare { get; set; }  // PCT_PARTICIPACAO (0.000000001 to 1.000000000)

    [CobolField(PicClause = "9(13)V99", Length = 15, DecimalPlaces = 2, FieldType = CobolFieldType.PackedDecimal)]
    [Column(TypeName = "decimal(15,2)")]
    public decimal CededInsuredAmount { get; set; }  // IMP_SEG_CEDIDO

    [CobolField(PicClause = "9(13)V99", Length = 15, DecimalPlaces = 2, FieldType = CobolFieldType.PackedDecimal)]
    [Column(TypeName = "decimal(15,2)")]
    public decimal CededPremium { get; set; }  // VL_PRM_CEDIDO

    [CobolField(PicClause = "X(1)", Length = 1)]
    [MaxLength(1)]
    public string IsLeader { get; set; }  // IND_LIDER ('S'/'N' - for cossurance)

    // Navigation Properties
    public Policy Policy { get; set; }
}
```

#### Validation Rules
1. `PolicyNumber` must exist in `Policy` entity
2. `CossuranceType` must be in `['C', 'R', 'E']` (Cosseguro, Resseguro, Retrocessao)
3. `PercentageShare` must be > 0 and <= 1.0
4. `CededPremium` must be >= 0
5. `IsLeader` must be 'S' or 'N'

#### EF Core Configuration

```csharp
public class CossuredPolicyConfiguration : IEntityTypeConfiguration<CossuredPolicy>
{
    public void Configure(EntityTypeBuilder<CossuredPolicy> builder)
    {
        builder.ToView("V0APOLCOSCED");
        builder.HasKey(c => c.CossuranceId);

        builder.HasIndex(c => new { c.PolicyNumber, c.CossuranceCode })
            .HasDatabaseName("IX_V0APOLCOSCED_PolicyCossurance");

        builder.HasIndex(c => c.CossuranceType)
            .HasDatabaseName("IX_V0APOLCOSCED_Type");

        builder.HasOne(c => c.Policy)
            .WithMany()
            .HasForeignKey(c => c.PolicyNumber)
            .OnDelete(DeleteBehavior.Restrict);
    }
}
```

---

### 13. CossuranceCalculation (GE399)

**Purpose**: Detailed cossurance calculation data for quota distribution among cossurers.

**COBOL Source**: `GE399` table, cursor declared at R5300-00-DECLARE-GE399, fetched at R5400-00-FETCH-GE399

#### Properties

```csharp
public class CossuranceCalculation
{
    [Key]
    public long CalculationId { get; set; }

    [CobolField(PicClause = "9(13)", Length = 13, FieldType = CobolFieldType.PackedDecimal)]
    public long PolicyNumber { get; set; }  // NUM_APOLICE

    [CobolField(PicClause = "9(4)", Length = 4)]
    public int CossuranceCode { get; set; }  // COD_COSSG

    [CobolField(PicClause = "9(4)V9(9)", Length = 14, DecimalPlaces = 9, FieldType = CobolFieldType.PackedDecimal)]
    [Column(TypeName = "decimal(13,9)")]
    public decimal QuotaPercentage { get; set; }  // PCT_QUOTA

    [CobolField(PicClause = "9(13)V99", Length = 15, DecimalPlaces = 2, FieldType = CobolFieldType.PackedDecimal)]
    [Column(TypeName = "decimal(15,2)")]
    public decimal RetainedPremium { get; set; }  // VL_PRM_RETIDO

    [CobolField(PicClause = "9(13)V99", Length = 15, DecimalPlaces = 2, FieldType = CobolFieldType.PackedDecimal)]
    [Column(TypeName = "decimal(15,2)")]
    public decimal CededPremium { get; set; }  // VL_PRM_CEDIDO

    [CobolField(PicClause = "9(13)V99", Length = 15, DecimalPlaces = 2, FieldType = CobolFieldType.PackedDecimal)]
    [Column(TypeName = "decimal(15,2)")]
    public decimal CededCommission { get; set; }  // VL_COMIS_CEDIDA

    // Navigation Properties
    public Policy Policy { get; set; }
}
```

#### Validation Rules
1. `PolicyNumber` must exist in `Policy` entity
2. `QuotaPercentage` must be > 0 and <= 1.0
3. `RetainedPremium` + `CededPremium` should equal total premium (within tolerance)
4. All financial values must be >= 0

#### EF Core Configuration

```csharp
public class CossuranceCalculationConfiguration : IEntityTypeConfiguration<CossuranceCalculation>
{
    public void Configure(EntityTypeBuilder<CossuranceCalculation> builder)
    {
        builder.ToTable("GE399");
        builder.HasKey(c => c.CalculationId);

        builder.HasIndex(c => new { c.PolicyNumber, c.CossuranceCode })
            .HasDatabaseName("IX_GE399_PolicyCossurance");

        builder.HasOne(c => c.Policy)
            .WithMany()
            .HasForeignKey(c => c.PolicyNumber)
            .OnDelete(DeleteBehavior.Restrict);
    }
}
```

---

### 14. SystemConfiguration (V0SISTEMA)

**Purpose**: System configuration parameters including processing dates and system identifiers.

**COBOL Source**: `V0SISTEMA` view, accessed at R0100-00-SELECT-SISTEMAS

#### Properties

```csharp
public class SystemConfiguration
{
    [Key]
    [CobolField(PicClause = "X(2)", Length = 2)]
    [MaxLength(2)]
    public string SystemId { get; set; }  // IDE_SISTEMA (e.g., 'GL', 'RG')

    [CobolField(PicClause = "X(10)", Length = 10)]
    [MaxLength(10)]
    public string ProcessingDate { get; set; }  // DT_MOVABE (YYYY-MM-DD)

    public DateTime ProcessingDateParsed => DateTime.ParseExact(ProcessingDate, "yyyy-MM-dd", CultureInfo.InvariantCulture);

    [CobolField(PicClause = "X(100)", Length = 100)]
    [MaxLength(100)]
    public string SystemName { get; set; }  // NOM_SISTEMA

    [CobolField(PicClause = "X(1)", Length = 1)]
    [MaxLength(1)]
    public string SystemStatus { get; set; }  // IND_SITUACAO ('A'=Active, 'I'=Inactive)

    [CobolField(PicClause = "9(9)", Length = 9)]
    public int CompanyCode { get; set; }  // COD_EMP
}
```

#### Validation Rules
1. `SystemId` must be unique
2. `ProcessingDate` must be valid date
3. `SystemStatus` must be in `['A', 'I']`

#### EF Core Configuration

```csharp
public class SystemConfigurationConfiguration : IEntityTypeConfiguration<SystemConfiguration>
{
    public void Configure(EntityTypeBuilder<SystemConfiguration> builder)
    {
        builder.ToView("V0SISTEMA");
        builder.HasKey(s => s.SystemId);
    }
}
```

---

### 15. ReportDefinition (V0RELATORIOS)

**Purpose**: Report execution metadata including user, date range, and status tracking.

**COBOL Source**: `V0RELATORIOS` view, accessed at R0200-00-SELECT-V0RELATORIO, R0300-00-DELETE-V0RELATORIO

#### Properties

```csharp
public class ReportDefinition
{
    [Key]
    public long ReportId { get; set; }

    [CobolField(PicClause = "X(8)", Length = 8)]
    [MaxLength(8)]
    public string UserCode { get; set; }  // COD_USUARIO

    [CobolField(PicClause = "X(10)", Length = 10)]
    [MaxLength(10)]
    public string RequestDate { get; set; }  // DTA_SOLICTA

    public DateTime RequestDateParsed => DateTime.ParseExact(RequestDate, "yyyy-MM-dd", CultureInfo.InvariantCulture);

    [CobolField(PicClause = "X(2)", Length = 2)]
    [MaxLength(2)]
    public string SystemId { get; set; }  // IDE_SISTEMA

    [CobolField(PicClause = "X(8)", Length = 8)]
    [MaxLength(8)]
    public string ReportCode { get; set; }  // COD_RELAT

    [CobolField(PicClause = "X(10)", Length = 10)]
    [MaxLength(10)]
    public string PeriodStart { get; set; }  // PERI_INICIAL

    [CobolField(PicClause = "X(10)", Length = 10)]
    [MaxLength(10)]
    public string PeriodEnd { get; set; }  // PERI_FINAL

    [CobolField(PicClause = "9(4)", Length = 4)]
    public int ReferenceYear { get; set; }  // ANO_REFER

    [CobolField(PicClause = "9(4)", Length = 4)]
    public int ReferenceMonth { get; set; }  // MES_REFER

    [CobolField(PicClause = "X(10)", Length = 10)]
    [MaxLength(10)]
    public string ReferenceDate { get; set; }  // DATA_REFR
}
```

#### Validation Rules
1. `RequestDate` must be valid date
2. `PeriodStart` must be <= `PeriodEnd`
3. `ReferenceMonth` must be 1-12
4. `ReferenceYear` must be >= 2000

#### EF Core Configuration

```csharp
public class ReportDefinitionConfiguration : IEntityTypeConfiguration<ReportDefinition>
{
    public void Configure(EntityTypeBuilder<ReportDefinition> builder)
    {
        builder.ToView("V0RELATORIOS");
        builder.HasKey(r => r.ReportId);

        builder.HasIndex(r => new { r.SystemId, r.ReportCode, r.RequestDate })
            .HasDatabaseName("IX_V0RELATORIOS_Request");
    }
}
```

---

## Supporting Infrastructure

### Custom Attribute for COBOL Field Metadata

```csharp
[AttributeUsage(AttributeTargets.Property)]
public class CobolFieldAttribute : Attribute
{
    public string PicClause { get; set; }
    public int Length { get; set; }
    public int DecimalPlaces { get; set; }
    public CobolFieldType FieldType { get; set; } = CobolFieldType.Display;
}

public enum CobolFieldType
{
    Display,          // PIC X(n) or PIC 9(n) - standard display
    Numeric,          // PIC 9(n) COMP - binary integer
    PackedDecimal,    // PIC 9(n) COMP-3 - packed decimal
    SignedNumeric     // PIC S9(n) COMP - signed binary
}
```

### DbContext Configuration

```csharp
public class PremiumReportingDbContext : DbContext
{
    public DbSet<PremiumRecord> PremiumRecords { get; set; }
    public DbSet<Policy> Policies { get; set; }
    public DbSet<Endorsement> Endorsements { get; set; }
    public DbSet<Product> Products { get; set; }
    public DbSet<Client> Clients { get; set; }
    public DbSet<Address> Addresses { get; set; }
    public DbSet<Agency> Agencies { get; set; }
    public DbSet<Producer> Producers { get; set; }
    public DbSet<Coverage> Coverages { get; set; }
    public DbSet<Invoice> Invoices { get; set; }
    public DbSet<Installment> Installments { get; set; }
    public DbSet<CossuredPolicy> CossuredPolicies { get; set; }
    public DbSet<CossuranceCalculation> CossuranceCalculations { get; set; }
    public DbSet<SystemConfiguration> SystemConfigurations { get; set; }
    public DbSet<ReportDefinition> ReportDefinitions { get; set; }

    protected override void OnModelCreating(ModelBuilder modelBuilder)
    {
        modelBuilder.ApplyConfiguration(new PremiumRecordConfiguration());
        modelBuilder.ApplyConfiguration(new PolicyConfiguration());
        modelBuilder.ApplyConfiguration(new EndorsementConfiguration());
        modelBuilder.ApplyConfiguration(new ProductConfiguration());
        modelBuilder.ApplyConfiguration(new ClientConfiguration());
        modelBuilder.ApplyConfiguration(new AddressConfiguration());
        modelBuilder.ApplyConfiguration(new AgencyConfiguration());
        modelBuilder.ApplyConfiguration(new ProducerConfiguration());
        modelBuilder.ApplyConfiguration(new CoverageConfiguration());
        modelBuilder.ApplyConfiguration(new InvoiceConfiguration());
        modelBuilder.ApplyConfiguration(new InstallmentConfiguration());
        modelBuilder.ApplyConfiguration(new CossuredPolicyConfiguration());
        modelBuilder.ApplyConfiguration(new CossuranceCalculationConfiguration());
        modelBuilder.ApplyConfiguration(new SystemConfigurationConfiguration());
        modelBuilder.ApplyConfiguration(new ReportDefinitionConfiguration());
    }

    protected override void OnConfiguring(DbContextOptionsBuilder optionsBuilder)
    {
        if (!optionsBuilder.IsConfigured)
        {
            optionsBuilder.UseSqlite("Data Source=premium_reporting.db");
        }
    }
}
```

---

## Data Model Traceability Matrix

| Entity | COBOL View/Table | Cursor Processing | Primary COBOL Section | Key Relationships |
|--------|------------------|-------------------|----------------------|-------------------|
| PremiumRecord | V0PREMIOS | Yes (R0500, R0600) | R0700-00-PROCESSA-REGISTRO | Policy, Product, Client, Endorsement |
| Policy | V0APOLICE | No | R0980-00-SELECT-V0APOLICE | Product, Client, Agency, Producer |
| Endorsement | V0ENDOSSO | No | R0760-00-SELECT-V0ENDOSSO | Policy |
| Product | V0PRODUTO | No | R0740-00-SELECT-V0PRODUTO | None |
| Client | V0CLIENTE | No | R0960-00-SELECT-V0CLIENTE | Address |
| Address | V0ENDERECOS | Yes (R1230, R1240) | R1220-00-PROCESSA-UF-VIDA | Client |
| Agency | V0AGENCIAS | No | R1180-00-SELECT-V0AGENCIAS | None |
| Producer | V0PRODUTOR | No | R1200-00-SELECT-V0PRODUTOR | None |
| Coverage | V0COBERAPOL | No | R0850-00-SELECT-V0COBERAPOL | Policy |
| Invoice | V0FATURAS | No | R1060-00-SELECT-V0FATURAS | Policy, Installment |
| Installment | V0HISTOPARC | No | R0800-00-SELECT-V0HISTOPARC | Invoice |
| CossuredPolicy | V0APOLCOSCED | Yes (R4900, R5000) | R4700-00-PROCESSA-APOL-COSG | Policy |
| CossuranceCalculation | GE399 | Yes (R5300, R5400) | R5500-00-CALCULA-COSG-CED | Policy |
| SystemConfiguration | V0SISTEMA | No | R0100-00-SELECT-SISTEMAS | None |
| ReportDefinition | V0RELATORIOS | No | R0200-00-SELECT-V0RELATORIO | None |

---

## Next Steps

With the data model design complete, the next phase involves:

1. **Phase 1.2**: Generate API contracts (`/contracts/openapi.yaml`) with RESTful endpoints for report generation, query, and data management
2. **Phase 1.3**: Create `quickstart.md` developer onboarding guide
3. **Phase 1.4**: Update agent context with data model documentation

**Document Version**: 1.0
**Status**: ✅ Complete - Ready for Phase 1.2 (API Contract Design)
**Created**: October 22, 2025



### QUICKSTART.MD (Execution Scenarios)

# Developer Quickstart Guide: COBOL RG1866B to .NET 9 Migration

**Feature Branch**: `001-vamos-migrar-sistema`
**Created**: October 22, 2025
**Status**: Phase 1.3 - Developer Onboarding
**Version**: 1.0

## Table of Contents

1. [Introduction](#introduction)
2. [Prerequisites](#prerequisites)
3. [Project Structure](#project-structure)
4. [Getting Started](#getting-started)
5. [Development Workflow](#development-workflow)
6. [Running Tests](#running-tests)
7. [Database Management](#database-management)
8. [API Documentation](#api-documentation)
9. [Frontend Development](#frontend-development)
10. [Troubleshooting](#troubleshooting)
11. [Additional Resources](#additional-resources)

---

## Introduction

Welcome to the SUSEP Circular 360 Premium Reporting System migration project! This guide will help you get up and running quickly with the development environment.

### What We're Building

A modern full-stack application that replaces the legacy COBOL RG1866B batch program with:

- **.NET 9 Web API**: RESTful backend with Clean Architecture
- **React Frontend**: Interactive dashboard and report generation UI
- **SQLite Database**: Local development database mimicking DB2 structure
- **Byte-Level Compatibility**: Exact output matching for regulatory compliance

### Project Goals

1. **Functional Parity**: Replicate all COBOL business logic exactly
2. **Modern UX**: Replace batch processing with interactive web interface
3. **Regulatory Compliance**: Maintain SUSEP Circular 360 report format compatibility
4. **Developer Experience**: Clean architecture, comprehensive tests, clear documentation

---

## Prerequisites

### Required Software

| Software | Version | Purpose | Download |
|----------|---------|---------|----------|
| **.NET SDK** | 9.0+ | Backend development | https://dotnet.microsoft.com/download |
| **Node.js** | 20+ LTS | Frontend development | https://nodejs.org/ |
| **Git** | 2.40+ | Version control | https://git-scm.com/ |
| **VS Code** | Latest | Code editor (recommended) | https://code.visualstudio.com/ |

### Optional but Recommended

| Software | Version | Purpose | Download |
|----------|---------|---------|----------|
| **Docker Desktop** | Latest | Containerization | https://www.docker.com/products/docker-desktop |
| **Postman** | Latest | API testing | https://www.postman.com/ |
| **DB Browser for SQLite** | Latest | Database inspection | https://sqlitebrowser.org/ |

### VS Code Extensions

Install these extensions for optimal development experience:

```bash
# C# Development
code --install-extension ms-dotnettools.csharp
code --install-extension ms-dotnettools.csdevkit

# React/TypeScript Development
code --install-extension dbaeumer.vscode-eslint
code --install-extension esbenp.prettier-vscode
code --install-extension bradlc.vscode-tailwindcss

# REST API Testing
code --install-extension humao.rest-client

# Git Integration
code --install-extension eamodio.gitlens
```

### Verify Prerequisites

Run these commands to verify your environment:

```bash
# .NET SDK
dotnet --version
# Expected: 9.0.0 or higher

# Node.js
node --version
# Expected: v20.0.0 or higher

# npm
npm --version
# Expected: 10.0.0 or higher

# Git
git --version
# Expected: 2.40.0 or higher
```

---

## Project Structure

The repository follows Clean Architecture principles with clear separation between backend, frontend, and specifications:

```
POC Cobol/
├── specs/                                  # Feature specifications (SpecKit)
│   └── 001-vamos-migrar-sistema/
│       ├── spec.md                         # Feature specification
│       ├── plan.md                         # Implementation plan
│       ├── research.md                     # Technical research
│       ├── data-model.md                   # Entity definitions
│       ├── quickstart.md                   # This file
│       ├── tasks.md                        # Implementation tasks (generated)
│       ├── contracts/
│       │   ├── openapi.yaml               # API specification
│       │   └── schemas/README.md          # API documentation
│       └── checklists/
│           └── requirements.md            # Quality validation
│
├── backend/                               # .NET 9 Backend
│   ├── CaixaSeguradora.sln               # Solution file
│   ├── src/
│   │   ├── CaixaSeguradora.Api/          # Web API layer
│   │   │   ├── Controllers/              # REST API controllers
│   │   │   ├── Program.cs                # Application entry point
│   │   │   ├── appsettings.json          # Configuration
│   │   │   └── appsettings.Development.json
│   │   │
│   │   ├── CaixaSeguradora.Core/         # Domain layer (Clean Architecture)
│   │   │   ├── Entities/                 # Domain entities
│   │   │   ├── Interfaces/               # Repository & service contracts
│   │   │   ├── Services/                 # Domain services
│   │   │   └── Attributes/               # CobolFieldAttribute, etc.
│   │   │
│   │   └── CaixaSeguradora.Infrastructure/ # Infrastructure layer
│   │       ├── Data/                     # EF Core DbContext
│   │       ├── Repositories/             # Repository implementations
│   │       ├── Services/                 # External service adapters
│   │       └── Formatters/               # FixedWidthFormatter, etc.
│   │
│   └── tests/
│       ├── CaixaSeguradora.UnitTests/    # Unit tests
│       ├── CaixaSeguradora.IntegrationTests/ # Integration tests
│       └── CaixaSeguradora.ComparisonTests/  # COBOL vs .NET validation
│
├── frontend/                              # React Frontend
│   ├── package.json                      # npm dependencies
│   ├── vite.config.ts                    # Vite configuration
│   ├── tailwind.config.js                # TailwindCSS config (Caixa branding)
│   ├── src/
│   │   ├── components/                   # React components
│   │   │   ├── dashboard/               # Dashboard components
│   │   │   ├── reports/                 # Report generation UI
│   │   │   └── query/                   # Data query UI
│   │   ├── pages/                       # Page components
│   │   ├── services/                    # API client layer
│   │   ├── styles/                      # Global styles
│   │   └── App.tsx                      # Root component
│   │
│   └── public/                          # Static assets
│
├── docs/                                 # Documentation
│   └── parser/                          # COBOL parser analysis
│       ├── FINAL-ANALYSIS-REPORT.md     # Complete program analysis
│       ├── INDEX.md                     # Documentation index
│       └── copybooks/
│           └── RG1866B_unix.cbl         # COBOL source code
│
└── CLAUDE.md                            # Project guide for Claude Code

```

### Key Directories

- **`specs/`**: Feature specifications following SpecKit methodology
- **`backend/src/`**: .NET 9 backend with Clean Architecture (Api → Core → Infrastructure)
- **`frontend/src/`**: React 18+ frontend with TypeScript and TailwindCSS
- **`docs/parser/`**: COBOL program analysis and legacy source code
- **`tests/`**: Comprehensive test suite (unit, integration, comparison)

---

## Getting Started

### 1. Clone the Repository

```bash
# Clone the repository
git clone <repository-url>
cd "POC Cobol"

# Checkout the feature branch
git checkout 001-vamos-migrar-sistema
```

### 2. Backend Setup

#### Install Dependencies

```bash
cd backend

# Restore NuGet packages
dotnet restore

# Verify build
dotnet build --configuration Debug
```

#### Configure Database

The application uses SQLite for local development. The database file will be created automatically on first run.

```bash
# Navigate to API project
cd src/CaixaSeguradora.Api

# Apply migrations (creates database schema)
dotnet ef database update

# Load sample mock data (optional)
dotnet run --seed-data
```

#### Run Backend API

```bash
# From backend/src/CaixaSeguradora.Api/
dotnet run

# Or with hot reload
dotnet watch run
```

**Expected Output**:
```
info: Microsoft.Hosting.Lifetime[14]
      Now listening on: https://localhost:5001
info: Microsoft.Hosting.Lifetime[14]
      Now listening on: http://localhost:5000
info: Microsoft.Hosting.Lifetime[0]
      Application started. Press Ctrl+C to shut down.
```

**Swagger UI**: Open https://localhost:5001/swagger in your browser

### 3. Frontend Setup

#### Install Dependencies

```bash
# From project root
cd frontend

# Install npm packages
npm install
```

#### Configure Environment

Create `.env.local` file for local development:

```bash
# frontend/.env.local
VITE_API_BASE_URL=https://localhost:5001/api/v1
VITE_APP_NAME="SUSEP Premium Reporting"
VITE_ENABLE_MOCK_DATA=true
```

#### Run Frontend Development Server

```bash
# From frontend/
npm run dev
```

**Expected Output**:
```
VITE v5.0.0  ready in 423 ms

➜  Local:   http://localhost:5173/
➜  Network: use --host to expose
➜  press h + enter to show help
```

**Dashboard**: Open http://localhost:5173 in your browser

### 4. Verify Setup

#### Test Backend API

```bash
# Health check
curl https://localhost:5001/api/v1/system/health

# Expected: {"status":"healthy","timestamp":"..."}

# Get dashboard metrics
curl https://localhost:5001/api/v1/dashboard/metrics

# Expected: JSON with program info, data structure, complexity metrics
```

#### Test Frontend

1. Navigate to http://localhost:5173
2. Verify dashboard loads with migration metrics
3. Check that all sections display data (Program Info, Data Structure, Complexity)

---

## Development Workflow

### Daily Development Cycle

```bash
# 1. Pull latest changes
git pull origin 001-vamos-migrar-sistema

# 2. Start backend (Terminal 1)
cd backend/src/CaixaSeguradora.Api
dotnet watch run

# 3. Start frontend (Terminal 2)
cd frontend
npm run dev

# 4. Make code changes
# Edit files in VS Code

# 5. Run tests
dotnet test                    # Backend tests
npm run test                   # Frontend tests

# 6. Commit changes
git add .
git commit -m "feat: add premium query filtering"
git push origin 001-vamos-migrar-sistema
```

### Git Workflow

We follow **trunk-based development** with short-lived feature branches:

```bash
# Create feature branch from main feature branch
git checkout 001-vamos-migrar-sistema
git checkout -b feature/premium-statistics

# Make changes and commit
git add .
git commit -m "feat: implement premium statistics endpoint"

# Push and create pull request
git push origin feature/premium-statistics
```

#### Commit Message Convention

Follow [Conventional Commits](https://www.conventionalcommits.org/):

```
feat: add new feature
fix: bug fix
docs: documentation changes
style: code formatting (no logic change)
refactor: code refactoring
test: add or update tests
chore: build/config changes
```

**Examples**:
```bash
git commit -m "feat: add PREMIT report generation endpoint"
git commit -m "fix: correct decimal precision in premium calculations"
git commit -m "test: add comparison tests for COBOL output validation"
git commit -m "docs: update API documentation with cossurance examples"
```

### Code Style

#### Backend (C#)

- **Naming**: PascalCase for classes/methods, camelCase for variables
- **Formatting**: Use `dotnet format` (configured in `.editorconfig`)
- **Architecture**: Follow Clean Architecture - no business logic in controllers
- **Error Handling**: Always log errors with Serilog before throwing

```csharp
// Good: Clean Architecture separation
public class PremiumController : ControllerBase
{
    private readonly IPremiumService _premiumService;

    [HttpGet("{id}")]
    public async Task<ActionResult<PremiumRecord>> GetPremium(long id)
    {
        var premium = await _premiumService.GetByIdAsync(id);
        if (premium == null)
            return NotFound();
        return Ok(premium);
    }
}

// Good: Decimal precision for financial calculations
[CobolField(PicClause = "9(13)V99", DecimalPlaces = 2)]
public decimal TotalPremiumAmount { get; set; }  // Use decimal, not double!

// Bad: Business logic in controller
public ActionResult Calculate()
{
    var result = premium * rate;  // ❌ Move to service layer
    return Ok(result);
}
```

#### Frontend (TypeScript/React)

- **Naming**: PascalCase for components, camelCase for functions/variables
- **Formatting**: Use Prettier (configured in `.prettierrc`)
- **Components**: Functional components with hooks
- **Styling**: TailwindCSS utility classes (avoid inline styles)

```tsx
// Good: Functional component with TypeScript
interface PremiumCardProps {
  premium: PremiumRecord;
  onSelect: (id: number) => void;
}

export const PremiumCard: React.FC<PremiumCardProps> = ({ premium, onSelect }) => {
  return (
    <div className="rounded-lg border border-gray-200 p-4 hover:shadow-md">
      <h3 className="text-lg font-semibold text-caixa-blue">
        Apólice {premium.policyNumber}
      </h3>
      <p className="text-gray-600">
        Prêmio: R$ {premium.totalPremiumAmount.toFixed(2)}
      </p>
      <button
        onClick={() => onSelect(premium.premiumId)}
        className="mt-2 rounded bg-caixa-blue px-4 py-2 text-white hover:bg-caixa-blue-dark"
      >
        Ver Detalhes
      </button>
    </div>
  );
};

// Good: Use TypeScript interfaces for API responses
interface ApiResponse<T> {
  data: T;
  pagination?: PaginationInfo;
}
```

---

## Running Tests

### Backend Tests

```bash
# Run all tests
cd backend
dotnet test

# Run with detailed output
dotnet test --logger "console;verbosity=detailed"

# Run specific test project
dotnet test tests/CaixaSeguradora.UnitTests/

# Run with coverage
dotnet test /p:CollectCoverage=true /p:CoverageReportFormat=html
# Coverage report: tests/*/coverage/index.html
```

#### Test Categories

**Unit Tests**: Test individual components in isolation
```bash
dotnet test --filter Category=Unit
```

**Integration Tests**: Test database and external dependencies
```bash
dotnet test --filter Category=Integration
```

**Comparison Tests**: Validate COBOL vs .NET output
```bash
dotnet test --filter Category=Comparison
```

### Frontend Tests

```bash
cd frontend

# Run unit tests (Vitest)
npm run test

# Run with watch mode
npm run test:watch

# Run with coverage
npm run test:coverage

# Run E2E tests (Playwright)
npm run test:e2e

# Run E2E in UI mode
npm run test:e2e:ui
```

### Test Data

Use mock data for development and testing:

```bash
# Load mock premium data
curl -X POST https://localhost:5001/api/v1/mock-data/load \
  -F "file=@test-data/premiums.csv" \
  -F "entityType=premiums"

# Validate loaded data
curl -X POST https://localhost:5001/api/v1/mock-data/validate

# Reset database to clean state
curl -X POST https://localhost:5001/api/v1/mock-data/reset
```

---

## Database Management

### Entity Framework Core Migrations

#### Create Migration

```bash
cd backend/src/CaixaSeguradora.Api

# Create new migration
dotnet ef migrations add AddPremiumIndexes

# Review generated migration in Migrations/ folder
```

#### Apply Migrations

```bash
# Update database to latest migration
dotnet ef database update

# Update to specific migration
dotnet ef database update AddPremiumIndexes

# Rollback to previous migration
dotnet ef database update PreviousMigrationName
```

#### View Migration SQL

```bash
# Generate SQL script
dotnet ef migrations script > migration.sql

# Generate SQL for specific range
dotnet ef migrations script FromMigration ToMigration > migration.sql
```

### Inspect Database

Use DB Browser for SQLite to inspect the database:

```bash
# Database location
backend/src/CaixaSeguradora.Api/premium_reporting.db
```

**Useful Queries**:

```sql
-- Count premium records
SELECT COUNT(*) FROM V0PREMIOS;

-- Check data distribution by month
SELECT ReferenceYear, ReferenceMonth, COUNT(*) as RecordCount
FROM V0PREMIOS
GROUP BY ReferenceYear, ReferenceMonth
ORDER BY ReferenceYear DESC, ReferenceMonth DESC;

-- Verify foreign key integrity
SELECT COUNT(*) FROM V0PREMIOS p
LEFT JOIN V0APOLICE a ON p.PolicyNumber = a.PolicyNumber
WHERE a.PolicyNumber IS NULL;
```

---

## API Documentation

### Swagger/OpenAPI

When the backend is running, access interactive API documentation at:

**Swagger UI**: https://localhost:5001/swagger

Features:
- Browse all endpoints
- View request/response schemas
- Execute API calls directly from browser
- Download OpenAPI spec

### Testing API with Postman

1. Import OpenAPI spec into Postman:
   - File → Import → `specs/001-vamos-migrar-sistema/contracts/openapi.yaml`

2. Set environment variables:
   - `baseUrl`: `https://localhost:5001/api/v1`
   - `bearerToken`: (JWT token from authentication)

3. Test common workflows:
   - Generate report
   - Query premiums
   - View policy details

### Testing API with curl

```bash
# Generate report
curl -X POST https://localhost:5001/api/v1/reports/generate \
  -H "Content-Type: application/json" \
  -d '{
    "startDate": "2025-10-01",
    "endDate": "2025-10-31",
    "reportTypes": ["PREMIT"],
    "systemId": "GL",
    "processingMode": "MONTHLY"
  }'

# Get report status
curl https://localhost:5001/api/v1/reports/{reportId}

# Query premiums
curl "https://localhost:5001/api/v1/premiums?page=1&pageSize=20&startDate=2025-10-01"

# Get dashboard metrics
curl https://localhost:5001/api/v1/dashboard/metrics
```

---

## Frontend Development

### Project Structure

```
frontend/src/
├── components/           # Reusable components
│   ├── dashboard/       # Dashboard-specific components
│   ├── reports/         # Report generation components
│   ├── query/           # Query builder components
│   └── common/          # Shared UI components
├── pages/               # Page components (routes)
│   ├── DashboardPage.tsx
│   ├── ReportPage.tsx
│   └── QueryPage.tsx
├── services/            # API client layer
│   ├── apiClient.ts     # Axios instance
│   ├── premiumService.ts
│   ├── reportService.ts
│   └── types.ts         # TypeScript interfaces
├── hooks/               # Custom React hooks
├── utils/               # Utility functions
└── App.tsx              # Root component
```

### TailwindCSS with Caixa Branding

Custom color palette configured in `tailwind.config.js`:

```javascript
module.exports = {
  theme: {
    extend: {
      colors: {
        caixa: {
          blue: {
            DEFAULT: '#0047BB',
            dark: '#003380',
            light: '#E6F0FF',
          },
          yellow: {
            DEFAULT: '#FFB81C',
            dark: '#E6A519',
          },
        },
      },
    },
  },
};
```

**Usage in components**:

```tsx
<div className="bg-caixa-blue text-white">Caixa Seguradora</div>
<button className="bg-caixa-yellow hover:bg-caixa-yellow-dark">Gerar Relatório</button>
```

### API Integration

Use generated TypeScript client from OpenAPI spec:

```bash
# Generate client (run once, or after API changes)
cd frontend
npm run generate-api-client
```

**Example usage**:

```tsx
import { premiumService } from '@/services/premiumService';

// Query premiums
const { data } = await premiumService.queryPremiums({
  startDate: '2025-10-01',
  endDate: '2025-10-31',
  page: 1,
  pageSize: 20,
});

console.log(data.premiums);
console.log(data.pagination.totalRecords);
```

### State Management

Use React hooks for local state, React Query for server state:

```tsx
import { useQuery } from '@tanstack/react-query';
import { premiumService } from '@/services/premiumService';

export const PremiumList = () => {
  const { data, isLoading, error } = useQuery({
    queryKey: ['premiums', { page: 1 }],
    queryFn: () => premiumService.queryPremiums({ page: 1, pageSize: 20 }),
  });

  if (isLoading) return <Spinner />;
  if (error) return <ErrorMessage error={error} />;

  return (
    <div>
      {data.premiums.map(premium => (
        <PremiumCard key={premium.premiumId} premium={premium} />
      ))}
    </div>
  );
};
```

---

## Troubleshooting

### Common Issues

#### Backend Won't Start

**Error**: `Unable to bind to https://localhost:5001`

**Solution**: Port already in use
```bash
# Find process using port
lsof -i :5001

# Kill process
kill -9 <PID>

# Or use different port
dotnet run --urls "https://localhost:5002"
```

**Error**: `No such file or directory: premium_reporting.db`

**Solution**: Run migrations
```bash
cd backend/src/CaixaSeguradora.Api
dotnet ef database update
```

#### Frontend Build Errors

**Error**: `Module not found: Can't resolve '@/services/...'`

**Solution**: Path alias issue
```bash
# Verify tsconfig.json has path mappings
{
  "compilerOptions": {
    "paths": {
      "@/*": ["./src/*"]
    }
  }
}

# Restart dev server
npm run dev
```

**Error**: `PostCSS plugin tailwindcss requires PostCSS 8`

**Solution**: Reinstall dependencies
```bash
rm -rf node_modules package-lock.json
npm install
```

#### Database Issues

**Error**: `SqliteException: database is locked`

**Solution**: Close other connections
```bash
# Close DB Browser for SQLite
# Restart backend API
```

**Error**: `Foreign key constraint failed`

**Solution**: Load data in correct order
```bash
# Load in dependency order:
# 1. Products, Clients, Agencies, Producers
# 2. Policies
# 3. Endorsements, Coverages
# 4. Premiums
```

### Debug Mode

#### Backend Debugging (VS Code)

Create `.vscode/launch.json`:

```json
{
  "version": "0.2.0",
  "configurations": [
    {
      "name": ".NET Core Launch (web)",
      "type": "coreclr",
      "request": "launch",
      "preLaunchTask": "build",
      "program": "${workspaceFolder}/backend/src/CaixaSeguradora.Api/bin/Debug/net9.0/CaixaSeguradora.Api.dll",
      "args": [],
      "cwd": "${workspaceFolder}/backend/src/CaixaSeguradora.Api",
      "env": {
        "ASPNETCORE_ENVIRONMENT": "Development"
      }
    }
  ]
}
```

Set breakpoints and press F5 to debug.

#### Frontend Debugging

Use browser DevTools:
- Chrome: F12 → Sources tab
- Set breakpoints in TypeScript files
- Use `debugger;` statement to break

### Logging

#### Backend Logs

Serilog configured in `appsettings.json`:

```json
{
  "Serilog": {
    "MinimumLevel": {
      "Default": "Information",
      "Override": {
        "Microsoft": "Warning",
        "System": "Warning"
      }
    }
  }
}
```

**View logs**:
```bash
# Console output during development
dotnet watch run

# Production logs (if using Seq)
# Open http://localhost:5341
```

#### Frontend Logs

Console logging with levels:

```typescript
console.log('Info message');
console.warn('Warning message');
console.error('Error message');

// Production: Logs sent to monitoring service
```

---

## Additional Resources

### Documentation

- **Feature Specification**: `specs/001-vamos-migrar-sistema/spec.md`
- **Implementation Plan**: `specs/001-vamos-migrar-sistema/plan.md`
- **Technical Research**: `specs/001-vamos-migrar-sistema/research.md`
- **Data Model**: `specs/001-vamos-migrar-sistema/data-model.md`
- **API Documentation**: `specs/001-vamos-migrar-sistema/contracts/schemas/README.md`
- **COBOL Analysis**: `docs/parser/FINAL-ANALYSIS-REPORT.md`

### External Resources

#### .NET 9

- [ASP.NET Core Documentation](https://learn.microsoft.com/en-us/aspnet/core/)
- [Entity Framework Core](https://learn.microsoft.com/en-us/ef/core/)
- [Clean Architecture Guide](https://learn.microsoft.com/en-us/dotnet/architecture/modern-web-apps-azure/)

#### React

- [React Documentation](https://react.dev/)
- [TypeScript Handbook](https://www.typescriptlang.org/docs/)
- [TailwindCSS Documentation](https://tailwindcss.com/docs)
- [React Query (TanStack Query)](https://tanstack.com/query/latest)

#### Tools

- [Postman Learning Center](https://learning.postman.com/)
- [Git Documentation](https://git-scm.com/doc)
- [VS Code Tips](https://code.visualstudio.com/docs/getstarted/tips-and-tricks)

### Team Communication

- **Slack Channel**: #susep-migration
- **Stand-up**: Daily at 9:30 AM
- **Sprint Planning**: Every 2 weeks on Monday
- **Code Review**: All PRs require 1 approval

### Getting Help

1. **Check Documentation**: Start with this quickstart and referenced docs
2. **Search Issues**: Check GitHub issues for similar problems
3. **Ask Team**: Post in #susep-migration Slack channel
4. **Create Issue**: If bug or feature request, create GitHub issue with:
   - Clear description
   - Steps to reproduce (for bugs)
   - Expected vs actual behavior
   - Environment details (OS, .NET version, etc.)

---

## Quick Reference Commands

### Backend

```bash
# Build
dotnet build

# Run
dotnet run
dotnet watch run    # with hot reload

# Test
dotnet test
dotnet test --filter Category=Unit

# Format
dotnet format

# Migrations
dotnet ef migrations add MigrationName
dotnet ef database update
```

### Frontend

```bash
# Install
npm install

# Run
npm run dev

# Test
npm run test
npm run test:e2e

# Build
npm run build
npm run preview     # preview production build

# Lint
npm run lint
npm run lint:fix
```

### Git

```bash
# Status
git status

# Commit
git add .
git commit -m "feat: description"

# Push
git push origin 001-vamos-migrar-sistema

# Pull latest
git pull origin 001-vamos-migrar-sistema

# Create feature branch
git checkout -b feature/branch-name
```

---

## Next Steps

Now that your environment is set up:

1. ✅ **Familiarize with Codebase**: Browse `specs/` documentation
2. ✅ **Run Application**: Start backend and frontend, verify dashboard loads
3. ✅ **Review Tasks**: Check `specs/001-vamos-migrar-sistema/tasks.md` (after Phase 2)
4. ✅ **Pick First Task**: Start with smallest, well-defined task
5. ✅ **Create Feature Branch**: Branch from `001-vamos-migrar-sistema`
6. ✅ **Implement, Test, Commit**: Follow development workflow
7. ✅ **Create Pull Request**: Request code review

**Welcome to the team! Happy coding! 🚀**

---

**Document Version**: 1.0
**Status**: ✅ Complete - Ready for Phase 1.4 (Agent Context Update)
**Created**: October 22, 2025



### TASKS.MD (Execution Plan)

# Tasks: COBOL RG1866B to .NET 9 React Migration

**Input**: Design documents from `/specs/001-vamos-migrar-sistema/`
**Prerequisites**: plan.md, spec.md, research.md, data-model.md, contracts/openapi.yaml, quickstart.md

**Tests**: NOT requested in specification - following FR-030 which requires unit tests for critical calculation logic only

**Organization**: Tasks are grouped by user story to enable independent implementation and testing of each story.

## Format: `[ID] [P?] [Story] Description`

- **[P]**: Can run in parallel (different files, no dependencies)
- **[Story]**: Which user story this task belongs to (e.g., US1, US2, US3, US4, US5)
- Include exact file paths in descriptions

## Path Conventions

- **Backend**: `backend/src/` (ASP.NET Core Web API structure)
- **Frontend**: `frontend/src/` (React + Vite structure)
- **Tests**: `backend/tests/` and `frontend/tests/`

---

## Phase 1: Setup (Shared Infrastructure)

**Purpose**: Project initialization and basic structure per plan.md

- [x] T001 Create .NET solution structure at `backend/CaixaSeguradora.sln` with three projects (Api, Core, Infrastructure)
- [x] T002 [P] Initialize CaixaSeguradora.Api project with ASP.NET Core Web API 9.0 in `backend/src/CaixaSeguradora.Api/`
- [x] T003 [P] Initialize CaixaSeguradora.Core project (class library) in `backend/src/CaixaSeguradora.Core/`
- [x] T004 [P] Initialize CaixaSeguradora.Infrastructure project (class library) in `backend/src/CaixaSeguradora.Infrastructure/`
- [x] T005 [P] Initialize test project CaixaSeguradora.UnitTests in `backend/tests/CaixaSeguradora.UnitTests/`
- [x] T006 [P] Initialize test project CaixaSeguradora.IntegrationTests in `backend/tests/CaixaSeguradora.IntegrationTests/`
- [x] T007 [P] Initialize test project CaixaSeguradora.ComparisonTests in `backend/tests/CaixaSeguradora.ComparisonTests/`
- [x] T008 Add NuGet packages to Api project (Swashbuckle, Serilog, AutoMapper)
- [ ] T009 [P] Add NuGet packages to Core project (no external dependencies per Clean Architecture)
- [ ] T010 [P] Add NuGet packages to Infrastructure project (EF Core 9.0, SQLite provider, System.Text.Json)
- [ ] T011 [P] Add NuGet packages to test projects (xUnit, FluentAssertions, Moq, Microsoft.AspNetCore.Mvc.Testing)
- [ ] T012 Create React + Vite + TypeScript project structure in `frontend/` using `npm create vite@latest`
- [ ] T013 [P] Install frontend dependencies (React Router 6+, Axios, Recharts, TailwindCSS) in `frontend/package.json`
- [ ] T014 [P] Configure TailwindCSS with Caixa Seguradora branding in `frontend/tailwind.config.js` (colors from research.md R6)
- [ ] T015 [P] Configure ESLint and Prettier for frontend in `frontend/.eslintrc.json` and `frontend/.prettierrc`
- [ ] T016 [P] Configure .NET code formatting (.editorconfig) in `backend/` per quickstart.md guidelines
- [ ] T017 [P] Create `backend/.gitignore` for .NET projects (bin/, obj/, *.db)
- [ ] T018 [P] Create `frontend/.gitignore` for Node projects (node_modules/, dist/)
- [ ] T019 [P] Create Docker Compose file in `docker-compose.yml` for development environment
- [ ] T020 Verify all projects build successfully (dotnet build, npm run build)

---

## Phase 2: Foundational (Blocking Prerequisites)

**Purpose**: Core infrastructure that MUST be complete before ANY user story can be implemented

**⚠️ CRITICAL**: No user story work can begin until this phase is complete

### Database Foundation

- [ ] T021 Create CobolFieldAttribute in `backend/src/CaixaSeguradora.Core/Attributes/CobolFieldAttribute.cs` (from research.md R1)
- [ ] T022 Create CobolFieldType enum in `backend/src/CaixaSeguradora.Core/Attributes/CobolFieldType.cs`
- [ ] T023 Create PremiumReportingDbContext in `backend/src/CaixaSeguradora.Infrastructure/Data/PremiumReportingDbContext.cs`
- [ ] T024 Configure SQLite connection string in `backend/src/CaixaSeguradora.Api/appsettings.json`
- [ ] T025 Configure SQLite connection string for development in `backend/src/CaixaSeguradora.Api/appsettings.Development.json`
- [ ] T026 Add EF Core design-time services in `backend/src/CaixaSeguradora.Api/Program.cs`
- [ ] T027 Create initial EF Core migration for database schema in `backend/src/CaixaSeguradora.Infrastructure/Migrations/`

### Core Domain Entities (from data-model.md)

- [ ] T028 [P] Create PremiumRecord entity in `backend/src/CaixaSeguradora.Core/Entities/PremiumRecord.cs` with all 687 COBOL data items mapped
- [ ] T029 [P] Create Policy entity in `backend/src/CaixaSeguradora.Core/Entities/Policy.cs`
- [ ] T030 [P] Create Endorsement entity in `backend/src/CaixaSeguradora.Core/Entities/Endorsement.cs`
- [ ] T031 [P] Create Product entity in `backend/src/CaixaSeguradora.Core/Entities/Product.cs`
- [ ] T032 [P] Create Client entity in `backend/src/CaixaSeguradora.Core/Entities/Client.cs`
- [ ] T033 [P] Create Address entity in `backend/src/CaixaSeguradora.Core/Entities/Address.cs`
- [ ] T034 [P] Create Agency entity in `backend/src/CaixaSeguradora.Core/Entities/Agency.cs`
- [ ] T035 [P] Create Producer entity in `backend/src/CaixaSeguradora.Core/Entities/Producer.cs`
- [ ] T036 [P] Create Coverage entity in `backend/src/CaixaSeguradora.Core/Entities/Coverage.cs`
- [ ] T037 [P] Create Invoice entity in `backend/src/CaixaSeguradora.Core/Entities/Invoice.cs`
- [ ] T038 [P] Create Installment entity in `backend/src/CaixaSeguradora.Core/Entities/Installment.cs`
- [ ] T039 [P] Create CossuredPolicy entity in `backend/src/CaixaSeguradora.Core/Entities/CossuredPolicy.cs`
- [ ] T040 [P] Create CossuranceCalculation entity in `backend/src/CaixaSeguradora.Core/Entities/CossuranceCalculation.cs`
- [ ] T041 [P] Create SystemConfiguration entity in `backend/src/CaixaSeguradora.Core/Entities/SystemConfiguration.cs`
- [ ] T042 [P] Create ReportDefinition entity in `backend/src/CaixaSeguradora.Core/Entities/ReportDefinition.cs`

### Entity Configurations (EF Core Fluent API)

- [ ] T043 [P] Create PremiumRecordConfiguration in `backend/src/CaixaSeguradora.Infrastructure/Data/Configurations/PremiumRecordConfiguration.cs`
- [ ] T044 [P] Create PolicyConfiguration in `backend/src/CaixaSeguradora.Infrastructure/Data/Configurations/PolicyConfiguration.cs`
- [ ] T045 [P] Create EndorsementConfiguration in `backend/src/CaixaSeguradora.Infrastructure/Data/Configurations/EndorsementConfiguration.cs`
- [ ] T046 [P] Create ProductConfiguration in `backend/src/CaixaSeguradora.Infrastructure/Data/Configurations/ProductConfiguration.cs`
- [ ] T047 [P] Create ClientConfiguration in `backend/src/CaixaSeguradora.Infrastructure/Data/Configurations/ClientConfiguration.cs`
- [ ] T048 [P] Create AddressConfiguration in `backend/src/CaixaSeguradora.Infrastructure/Data/Configurations/AddressConfiguration.cs`
- [ ] T049 [P] Create AgencyConfiguration in `backend/src/CaixaSeguradora.Infrastructure/Data/Configurations/AgencyConfiguration.cs`
- [ ] T050 [P] Create ProducerConfiguration in `backend/src/CaixaSeguradora.Infrastructure/Data/Configurations/ProducerConfiguration.cs`
- [ ] T051 [P] Create CoverageConfiguration in `backend/src/CaixaSeguradora.Infrastructure/Data/Configurations/CoverageConfiguration.cs`
- [ ] T052 [P] Create InvoiceConfiguration in `backend/src/CaixaSeguradora.Infrastructure/Data/Configurations/InvoiceConfiguration.cs`
- [ ] T053 [P] Create InstallmentConfiguration in `backend/src/CaixaSeguradora.Infrastructure/Data/Configurations/InstallmentConfiguration.cs`
- [ ] T054 [P] Create CossuredPolicyConfiguration in `backend/src/CaixaSeguradora.Infrastructure/Data/Configurations/CossuredPolicyConfiguration.cs`
- [ ] T055 [P] Create CossuranceCalculationConfiguration in `backend/src/CaixaSeguradora.Infrastructure/Data/Configurations/CossuranceCalculationConfiguration.cs`
- [ ] T056 [P] Create SystemConfigurationConfiguration in `backend/src/CaixaSeguradora.Infrastructure/Data/Configurations/SystemConfigurationConfiguration.cs`
- [ ] T057 [P] Create ReportDefinitionConfiguration in `backend/src/CaixaSeguradora.Infrastructure/Data/Configurations/ReportDefinitionConfiguration.cs`
- [ ] T058 Apply all entity configurations to DbContext in `backend/src/CaixaSeguradora.Infrastructure/Data/PremiumReportingDbContext.cs`
- [ ] T059 Generate and apply EF Core migration for all entities to create database schema

### Core Infrastructure Services

- [ ] T060 Create FixedWidthFormatter in `backend/src/CaixaSeguradora.Infrastructure/Formatters/FixedWidthFormatter.cs` (from research.md R2)
- [ ] T061 Create CobolMath utility class in `backend/src/CaixaSeguradora.Core/Utilities/CobolMath.cs` with rounding methods (from research.md R1)
- [ ] T062 Create base repository interface IRepository<T> in `backend/src/CaixaSeguradora.Core/Interfaces/IRepository.cs`
- [ ] T063 Create base repository implementation Repository<T> in `backend/src/CaixaSeguradora.Infrastructure/Repositories/Repository.cs`
- [ ] T064 Configure Serilog in `backend/src/CaixaSeguradora.Api/Program.cs` with structured logging
- [ ] T065 Configure Swagger/OpenAPI in `backend/src/CaixaSeguradora.Api/Program.cs` per contracts/openapi.yaml
- [ ] T066 Configure CORS policy in `backend/src/CaixaSeguradora.Api/Program.cs` for frontend origin
- [ ] T067 Configure dependency injection container in `backend/src/CaixaSeguradora.Api/Program.cs` for all services
- [ ] T068 Create global exception handler middleware in `backend/src/CaixaSeguradora.Api/Middleware/ExceptionHandlerMiddleware.cs`
- [ ] T069 Create error response DTO in `backend/src/CaixaSeguradora.Core/DTOs/ErrorResponse.cs`

### Frontend Foundation

- [ ] T070 Create frontend folder structure (`components/`, `pages/`, `services/`, `hooks/`, `utils/`) in `frontend/src/`
- [ ] T071 Create Axios API client instance in `frontend/src/services/apiClient.ts` with base URL configuration
- [ ] T072 Create API service interfaces in `frontend/src/services/types.ts` matching OpenAPI schemas
- [ ] T073 [P] Create common UI components (Button, Card, Spinner, ErrorMessage) in `frontend/src/components/common/`
- [ ] T074 [P] Configure React Router in `frontend/src/App.tsx` with routes for all pages
- [ ] T075 [P] Create global styles with Caixa branding in `frontend/src/styles/globals.css`
- [ ] T076 [P] Create layout component with header/navigation in `frontend/src/components/Layout.tsx`

**Checkpoint**: Foundation ready - user story implementation can now begin in parallel

---

## Phase 3: User Story 1 - View Migration Dashboard (Priority: P1) 🎯 MVP

**Goal**: Provide interactive dashboard showing COBOL program analysis, migration metrics, and project complexity

**Independent Test**: Launch React application at http://localhost:5173, navigate to dashboard, verify all metrics display correctly (program info shows RG1866B with 687 data items, 63 sections, 26+ tables), function points breakdown visible, database dependencies visualized

### Backend Implementation for US1

- [ ] T077 [P] [US1] Create DashboardMetricsDto in `backend/src/CaixaSeguradora.Core/DTOs/DashboardMetricsDto.cs`
- [ ] T078 [P] [US1] Create FunctionPointsDto in `backend/src/CaixaSeguradora.Core/DTOs/FunctionPointsDto.cs`
- [ ] T079 [P] [US1] Create DatabaseDependenciesDto in `backend/src/CaixaSeguradora.Core/DTOs/DatabaseDependenciesDto.cs`
- [ ] T080 [US1] Create IDashboardService interface in `backend/src/CaixaSeguradora.Core/Interfaces/IDashboardService.cs`
- [ ] T081 [US1] Implement DashboardService in `backend/src/CaixaSeguradora.Infrastructure/Services/DashboardService.cs` with hardcoded metrics from parser analysis
- [ ] T082 [US1] Create DashboardController in `backend/src/CaixaSeguradora.Api/Controllers/DashboardController.cs` with three endpoints (metrics, function-points, database-dependencies)
- [ ] T083 [US1] Register DashboardService in dependency injection container in `backend/src/CaixaSeguradora.Api/Program.cs`
- [ ] T084 [US1] Test dashboard endpoints with Swagger UI - verify metrics match FINAL-ANALYSIS-REPORT.md

### Frontend Implementation for US1

- [ ] T085 [P] [US1] Create dashboardService.ts in `frontend/src/services/dashboardService.ts` with API calls
- [ ] T086 [P] [US1] Create ProgramInfoCard component in `frontend/src/components/dashboard/ProgramInfoCard.tsx`
- [ ] T087 [P] [US1] Create DataStructureCard component in `frontend/src/components/dashboard/DataStructureCard.tsx`
- [ ] T088 [P] [US1] Create ComplexityMetricsCard component in `frontend/src/components/dashboard/ComplexityMetricsCard.tsx`
- [ ] T089 [P] [US1] Create DatabaseDependenciesChart component in `frontend/src/components/dashboard/DatabaseDependenciesChart.tsx` using Recharts
- [ ] T090 [P] [US1] Create FunctionPointsChart component in `frontend/src/components/dashboard/FunctionPointsChart.tsx`
- [ ] T091 [P] [US1] Create MigrationProgressCard component in `frontend/src/components/dashboard/MigrationProgressCard.tsx`
- [ ] T092 [US1] Create DashboardPage in `frontend/src/pages/DashboardPage.tsx` composing all dashboard components
- [ ] T093 [US1] Add dashboard route to React Router in `frontend/src/App.tsx` (default route `/`)
- [ ] T094 [US1] Test dashboard page loads with all metrics, charts render correctly, responsive layout works on mobile/tablet/desktop

**Checkpoint**: At this point, User Story 1 (Dashboard) should be fully functional and testable independently. Deploy as MVP.

---

## Phase 4: User Story 2 - Generate Premium Reports (Interactive) (Priority: P2)

**Goal**: Enable interactive PREMIT/PREMCED report generation through web interface, replacing COBOL batch processing

**Independent Test**: Configure report parameters (date range 2025-10-01 to 2025-10-31, system GL, report type PREMIT), click generate, verify processing status updates, download generated file, compare byte-for-byte with COBOL sample output

### Backend Repositories for US2

- [ ] T095 [P] [US2] Create IPremiumRepository interface in `backend/src/CaixaSeguradora.Core/Interfaces/IPremiumRepository.cs` with cursor methods
- [ ] T096 [P] [US2] Create IPolicyRepository interface in `backend/src/CaixaSeguradora.Core/Interfaces/IPolicyRepository.cs`
- [ ] T097 [P] [US2] Create IEndorsementRepository interface in `backend/src/CaixaSeguradora.Core/Interfaces/IEndorsementRepository.cs`
- [ ] T098 [P] [US2] Create IProductRepository interface in `backend/src/CaixaSeguradora.Core/Interfaces/IProductRepository.cs`
- [ ] T099 [P] [US2] Create ICoverageRepository interface in `backend/src/CaixaSeguradora.Core/Interfaces/ICoverageRepository.cs`
- [ ] T100 [P] [US2] Create IClientRepository interface in `backend/src/CaixaSeguradora.Core/Interfaces/IClientRepository.cs`
- [ ] T101 [P] [US2] Create IAddressRepository interface in `backend/src/CaixaSeguradora.Core/Interfaces/IAddressRepository.cs`
- [ ] T102 [P] [US2] Create ICossuredPolicyRepository interface in `backend/src/CaixaSeguradora.Core/Interfaces/ICossuredPolicyRepository.cs`
- [ ] T103 [P] [US2] Create ICossuranceCalculationRepository interface in `backend/src/CaixaSeguradora.Core/Interfaces/ICossuranceCalculationRepository.cs`
- [X] T104 [P] [US2] Implement PremiumRepository in `backend/src/CaixaSeguradora.Infrastructure/Repositories/PremiumRepository.cs` with IAsyncEnumerable (research.md R3)
- [X] T105 [P] [US2] Implement PolicyRepository in `backend/src/CaixaSeguradora.Infrastructure/Repositories/PolicyRepository.cs`
- [X] T106 [P] [US2] Implement EndorsementRepository in `backend/src/CaixaSeguradora.Infrastructure/Repositories/EndorsementRepository.cs`
- [X] T107 [P] [US2] Implement ProductRepository in `backend/src/CaixaSeguradora.Infrastructure/Repositories/ProductRepository.cs`
- [X] T108 [P] [US2] Implement CoverageRepository in `backend/src/CaixaSeguradora.Infrastructure/Repositories/CoverageRepository.cs`
- [X] T109 [P] [US2] Implement ClientRepository in `backend/src/CaixaSeguradora.Infrastructure/Repositories/ClientRepository.cs`
- [X] T110 [P] [US2] Implement AddressRepository in `backend/src/CaixaSeguradora.Infrastructure/Repositories/AddressRepository.cs`
- [X] T111 [P] [US2] Implement CossuredPolicyRepository in `backend/src/CaixaSeguradora.Infrastructure/Repositories/CossuredPolicyRepository.cs`
- [X] T112 [P] [US2] Implement CossuranceCalculationRepository in `backend/src/CaixaSeguradora.Infrastructure/Repositories/CossuranceCalculationRepository.cs`

### Business Logic Services for US2 (COBOL Sections R0500-R5500)

- [ ] T113 [US2] Create IPremiumCalculationService interface in `backend/src/CaixaSeguradora.Core/Interfaces/IPremiumCalculationService.cs`
- [ ] T114 [US2] Create ICossuranceService interface in `backend/src/CaixaSeguradora.Core/Interfaces/ICossuranceService.cs`
- [ ] T115 [US2] Create IExternalModuleService interface in `backend/src/CaixaSeguradora.Core/Interfaces/IExternalModuleService.cs` (for RE0001S, GE0009S, GE0010S mocks)
- [ ] T116 [US2] Implement PremiumCalculationService in `backend/src/CaixaSeguradora.Core/Services/PremiumCalculationService.cs` (COBOL sections R0700-R1300)
- [ ] T117 [US2] Implement CossuranceService in `backend/src/CaixaSeguradora.Core/Services/CossuranceService.cs` (COBOL sections R3000-R5500)
- [ ] T118 [US2] Implement ExternalModuleService mock in `backend/src/CaixaSeguradora.Infrastructure/Services/ExternalModuleService.cs` (research.md R4)
- [ ] T119 [US2] Create unit tests for PremiumCalculationService in `backend/tests/CaixaSeguradora.UnitTests/Services/PremiumCalculationServiceTests.cs` (90%+ coverage per constitution)
- [ ] T120 [US2] Create unit tests for CossuranceService in `backend/tests/CaixaSeguradora.UnitTests/Services/CossuranceServiceTests.cs`

### Report Generation Service for US2

- [ ] T121 [US2] Create IReportGenerationService interface in `backend/src/CaixaSeguradora.Core/Interfaces/IReportGenerationService.cs`
- [ ] T122 [US2] Create ReportGenerationRequest DTO in `backend/src/CaixaSeguradora.Core/DTOs/ReportGenerationRequest.cs`
- [ ] T123 [US2] Create ReportGenerationResponse DTO in `backend/src/CaixaSeguradora.Core/DTOs/ReportGenerationResponse.cs`
- [ ] T124 [US2] Create ReportStatusResponse DTO in `backend/src/CaixaSeguradora.Core/DTOs/ReportStatusResponse.cs`
- [ ] T125 [US2] Implement ReportGenerationService in `backend/src/CaixaSeguradora.Infrastructure/Services/ReportGenerationService.cs` with async processing
- [ ] T126 [US2] Implement PREMIT file generation logic in `backend/src/CaixaSeguradora.Infrastructure/Services/PremitFileGenerator.cs` using FixedWidthFormatter
- [ ] T127 [US2] Implement PREMCED file generation logic in `backend/src/CaixaSeguradora.Infrastructure/Services/PremcedFileGenerator.cs`
- [ ] T128 [US2] Add transaction scope handling in report generation service per research.md R5
- [ ] T129 [US2] Create ReportsController in `backend/src/CaixaSeguradora.Api/Controllers/ReportsController.cs` with five endpoints (generate, status, download, history, compare)
- [ ] T130 [US2] Register all report services in dependency injection in `backend/src/CaixaSeguradora.Api/Program.cs`
- [ ] T131 [US2] Test report generation endpoint with Swagger - verify async 202 response, poll status, download file

### COBOL Comparison Testing for US2

- [ ] T132 [US2] Create OutputValidator class in `backend/tests/CaixaSeguradora.ComparisonTests/OutputValidator.cs` for byte-level comparison (research.md R2)
- [ ] T133 [US2] Create comparison test with sample COBOL output in `backend/tests/CaixaSeguradora.ComparisonTests/PremitOutputComparisonTests.cs`
- [ ] T134 [US2] Create comparison test for PREMCED in `backend/tests/CaixaSeguradora.ComparisonTests/PremcedOutputComparisonTests.cs`
- [ ] T135 [US2] Add 10 sample COBOL output files to `backend/tests/CaixaSeguradora.ComparisonTests/TestData/`
- [ ] T136 [US2] Run comparison tests and verify 100% byte match for all samples (constitution requirement III)

### Error Handling & Database Safeguards for US2

- [ ] T241 [US2] Implement SqlErrorTranslator in `backend/src/CaixaSeguradora.Infrastructure/Services/SqlErrorTranslator.cs` mapping SQLCODE values to domain errors.
- [ ] T242 [US2] Create SQL error handling regression tests in `backend/tests/CaixaSeguradora.IntegrationTests/Reports/SqlErrorHandlingTests.cs`.
- [ ] T243 [US2] Add read-only DB command interceptor in `backend/src/CaixaSeguradora.Infrastructure/Data/ReadOnlyDbCommandInterceptor.cs` to block write operations.
- [ ] T244 [US2] Verify read-only enforcement with integration tests in `backend/tests/CaixaSeguradora.IntegrationTests/Data/ReadOnlyGuardTests.cs`.

### Frontend Implementation for US2

- [ ] T137 [P] [US2] Create reportService.ts in `frontend/src/services/reportService.ts` with API calls
- [ ] T138 [P] [US2] Create ReportParametersForm component in `frontend/src/components/reports/ReportParametersForm.tsx`
- [ ] T139 [P] [US2] Create ReportProgressIndicator component in `frontend/src/components/reports/ReportProgressIndicator.tsx`
- [ ] T140 [P] [US2] Create ReportResultsCard component in `frontend/src/components/reports/ReportResultsCard.tsx`
- [ ] T141 [P] [US2] Create ReportHistoryTable component in `frontend/src/components/reports/ReportHistoryTable.tsx`
- [ ] T142 [US2] Create ReportGenerationPage in `frontend/src/pages/ReportGenerationPage.tsx` with form, status polling, download functionality
- [ ] T143 [US2] Add report generation route `/reports` to React Router in `frontend/src/App.tsx`
- [ ] T144 [US2] Test full report generation flow: fill form, submit, see progress, download file, verify file contents

**Checkpoint**: At this point, User Stories 1 AND 2 should both work independently. Core migration functionality complete.

---

## Phase 5: User Story 3 - Query and Visualize Premium Data (Priority: P3)

**Goal**: Enable interactive querying and visualization of premium data with export capabilities

**Independent Test**: Navigate to query page, build filter (policy number range, date range), execute query, verify results table shows data, create chart visualization, export to CSV, verify exported data accuracy

### Backend Implementation for US3

- [ ] T145 [P] [US3] Create PremiumQueryRequest DTO in `backend/src/CaixaSeguradora.Core/DTOs/PremiumQueryRequest.cs`
- [ ] T146 [P] [US3] Create PremiumQueryResponse DTO in `backend/src/CaixaSeguradora.Core/DTOs/PremiumQueryResponse.cs`
- [ ] T147 [P] [US3] Create PremiumStatisticsRequest DTO in `backend/src/CaixaSeguradora.Core/DTOs/PremiumStatisticsRequest.cs`
- [ ] T148 [P] [US3] Create PremiumStatisticsResponse DTO in `backend/src/CaixaSeguradora.Core/DTOs/PremiumStatisticsResponse.cs`
- [ ] T149 [US3] Create IQueryService interface in `backend/src/CaixaSeguradora.Core/Interfaces/IQueryService.cs`
- [ ] T150 [US3] Implement QueryService in `backend/src/CaixaSeguradora.Infrastructure/Services/QueryService.cs` with dynamic LINQ queries
- [ ] T151 [US3] Create IExportService interface in `backend/src/CaixaSeguradora.Core/Interfaces/IExportService.cs`
- [ ] T152 [US3] Implement CsvExportService in `backend/src/CaixaSeguradora.Infrastructure/Services/CsvExportService.cs`
- [ ] T153 [US3] Implement ExcelExportService in `backend/src/CaixaSeguradora.Infrastructure/Services/ExcelExportService.cs` using EPPlus or ClosedXML
- [ ] T154 [US3] Implement PdfExportService in `backend/src/CaixaSeguradora.Infrastructure/Services/PdfExportService.cs` using iText7 or QuestPDF
- [ ] T155 [US3] Create PremiumsController in `backend/src/CaixaSeguradora.Api/Controllers/PremiumsController.cs` with query and statistics endpoints
- [ ] T156 [US3] Create ExportController in `backend/src/CaixaSeguradora.Api/Controllers/ExportController.cs` with export endpoints
- [ ] T157 [US3] Register query and export services in dependency injection in `backend/src/CaixaSeguradora.Api/Program.cs`
- [ ] T158 [US3] Test query endpoint with Swagger - verify filtering, sorting, pagination work correctly

### Frontend Implementation for US3

- [ ] T159 [P] [US3] Create queryService.ts in `frontend/src/services/queryService.ts`
- [ ] T160 [P] [US3] Create QueryFilterForm component in `frontend/src/components/query/QueryFilterForm.tsx` with date pickers, dropdowns
- [ ] T161 [P] [US3] Create QueryResultsTable component in `frontend/src/components/query/QueryResultsTable.tsx` with pagination, sorting
- [ ] T162 [P] [US3] Create QueryStatisticsCard component in `frontend/src/components/query/QueryStatisticsCard.tsx` showing aggregations
- [ ] T163 [P] [US3] Create QueryVisualizationPanel component in `frontend/src/components/query/QueryVisualizationPanel.tsx` with chart type selector
- [ ] T164 [P] [US3] Create ExportButtonGroup component in `frontend/src/components/query/ExportButtonGroup.tsx` (CSV, Excel, PDF buttons)
- [ ] T165 [US3] Create QueryPage in `frontend/src/pages/QueryPage.tsx` composing all query components
- [ ] T166 [US3] Add query route `/query` to React Router in `frontend/src/App.tsx`
- [ ] T167 [US3] Test query page: build filters, execute query, see results, create charts, export files

**Checkpoint**: User Stories 1, 2, and 3 all work independently. Dashboard, reports, and query capabilities complete.

---

## Phase 6: User Story 4 - Monitor Batch Processing Jobs (Priority: P4)

**Goal**: Enable scheduling and monitoring of automated report generation jobs

**Independent Test**: Create scheduled job (monthly reports on 1st at 2 AM), verify job appears in list, manually trigger job execution, monitor status, verify completion notification sent

### Backend Implementation for US4

- [ ] T168 [P] [US4] Create BatchJobCreateRequest DTO in `backend/src/CaixaSeguradora.Core/DTOs/BatchJobCreateRequest.cs`
- [ ] T169 [P] [US4] Create BatchJob entity in `backend/src/CaixaSeguradora.Core/Entities/BatchJob.cs`
- [ ] T170 [P] [US4] Create JobExecution entity in `backend/src/CaixaSeguradora.Core/Entities/JobExecution.cs`
- [ ] T171 [US4] Create BatchJobConfiguration in `backend/src/CaixaSeguradora.Infrastructure/Data/Configurations/BatchJobConfiguration.cs`
- [ ] T172 [US4] Create JobExecutionConfiguration in `backend/src/CaixaSeguradora.Infrastructure/Data/Configurations/JobExecutionConfiguration.cs`
- [ ] T173 [US4] Generate and apply EF Core migration for batch job tables
- [ ] T174 [US4] Create IBatchJobRepository interface in `backend/src/CaixaSeguradora.Core/Interfaces/IBatchJobRepository.cs`
- [ ] T175 [US4] Implement BatchJobRepository in `backend/src/CaixaSeguradora.Infrastructure/Repositories/BatchJobRepository.cs`
- [ ] T176 [US4] Create IBatchSchedulingService interface in `backend/src/CaixaSeguradora.Core/Interfaces/IBatchSchedulingService.cs`
- [ ] T177 [US4] Implement BatchSchedulingService in `backend/src/CaixaSeguradora.Infrastructure/Services/BatchSchedulingService.cs` using Hangfire or Quartz.NET
- [ ] T178 [US4] Create INotificationService interface in `backend/src/CaixaSeguradora.Core/Interfaces/INotificationService.cs`
- [ ] T179 [US4] Implement EmailNotificationService in `backend/src/CaixaSeguradora.Infrastructure/Services/EmailNotificationService.cs` using MailKit
- [ ] T180 [US4] Create BatchJobsController in `backend/src/CaixaSeguradora.Api/Controllers/BatchJobsController.cs` with CRUD and execution endpoints
- [ ] T181 [US4] Register batch job services and Hangfire in dependency injection in `backend/src/CaixaSeguradora.Api/Program.cs`
- [ ] T182 [US4] Configure Hangfire dashboard in `backend/src/CaixaSeguradora.Api/Program.cs` at `/hangfire`
- [ ] T183 [US4] Test batch job creation, scheduling, and manual execution via Swagger and Hangfire dashboard

### Frontend Implementation for US4

- [ ] T184 [P] [US4] Create batchJobService.ts in `frontend/src/services/batchJobService.ts`
- [ ] T185 [P] [US4] Create BatchJobForm component in `frontend/src/components/batch/BatchJobForm.tsx` with cron expression builder
- [ ] T186 [P] [US4] Create BatchJobsTable component in `frontend/src/components/batch/BatchJobsTable.tsx` showing all jobs
- [ ] T187 [P] [US4] Create JobExecutionHistoryTable component in `frontend/src/components/batch/JobExecutionHistoryTable.tsx`
- [ ] T188 [P] [US4] Create JobStatusBadge component in `frontend/src/components/batch/JobStatusBadge.tsx` (Running, Completed, Failed)
- [ ] T189 [US4] Create BatchJobsPage in `frontend/src/pages/BatchJobsPage.tsx` with create, list, monitor functionality
- [ ] T190 [US4] Add batch jobs route `/batch-jobs` to React Router in `frontend/src/App.tsx`
- [ ] T191 [US4] Test batch jobs page: create job, view list, see execution history, verify notifications work

**Checkpoint**: User Stories 1-4 complete. All operational features working.

---

## Phase 7: User Story 5 - Manage Database Mock Data (Priority: P4)

**Goal**: Enable loading, validating, and managing SQLite mock data for testing

**Independent Test**: Upload CSV file with premium data, verify loading succeeds, check record count, run validation, see any data quality issues, run COBOL vs .NET comparison, export diff report

### Backend Implementation for US5

- [ ] T192 [P] [US5] Create MockDataLoadRequest DTO in `backend/src/CaixaSeguradora.Core/DTOs/MockDataLoadRequest.cs`
- [ ] T193 [P] [US5] Create MockDataLoadResponse DTO in `backend/src/CaixaSeguradora.Core/DTOs/MockDataLoadResponse.cs`
- [ ] T194 [P] [US5] Create DataValidationResponse DTO in `backend/src/CaixaSeguradora.Core/DTOs/DataValidationResponse.cs`
- [ ] T195 [US5] Create IMockDataService interface in `backend/src/CaixaSeguradora.Core/Interfaces/IMockDataService.cs`
- [ ] T196 [US5] Create IDataValidationService interface in `backend/src/CaixaSeguradora.Core/Interfaces/IDataValidationService.cs`
- [ ] T197 [US5] Implement CsvDataLoader in `backend/src/CaixaSeguradora.Infrastructure/Services/CsvDataLoader.cs` using CsvHelper
- [ ] T198 [US5] Implement JsonDataLoader in `backend/src/CaixaSeguradora.Infrastructure/Services/JsonDataLoader.cs`
- [ ] T199 [US5] Implement DataValidationService in `backend/src/CaixaSeguradora.Infrastructure/Services/DataValidationService.cs` with foreign key checks
- [ ] T200 [US5] Implement SchemaInspectionService in `backend/src/CaixaSeguradora.Infrastructure/Services/SchemaInspectionService.cs`
- [ ] T201 [US5] Create MockDataController in `backend/src/CaixaSeguradora.Api/Controllers/MockDataController.cs` with load, validate, reset endpoints
- [ ] T202 [US5] Register mock data services in dependency injection in `backend/src/CaixaSeguradora.Api/Program.cs`
- [ ] T203 [US5] Create sample CSV files for all entities in `backend/tests/SampleData/` (premiums, policies, clients, etc.)
- [ ] T204 [US5] Test mock data loading via Swagger with sample CSV files, verify data appears in database

### Frontend Implementation for US5

- [ ] T205 [P] [US5] Create mockDataService.ts in `frontend/src/services/mockDataService.ts`
- [ ] T206 [P] [US5] Create FileUploadForm component in `frontend/src/components/data/FileUploadForm.tsx` with drag-and-drop
- [ ] T207 [P] [US5] Create SchemaViewer component in `frontend/src/components/data/SchemaViewer.tsx` showing table structures
- [ ] T208 [P] [US5] Create ValidationResultsPanel component in `frontend/src/components/data/ValidationResultsPanel.tsx`
- [ ] T209 [P] [US5] Create ComparisonReportViewer component in `frontend/src/components/data/ComparisonReportViewer.tsx` showing diffs
- [ ] T210 [US5] Create DataManagementPage in `frontend/src/pages/DataManagementPage.tsx` with upload, validate, reset, compare features
- [ ] T211 [US5] Add data management route `/data-management` to React Router in `frontend/src/App.tsx`
- [ ] T212 [US5] Test data management page: upload file, validate data, run comparison, export results

**Checkpoint**: All user stories (1-5) complete and independently testable.

---

## Phase 8: Polish & Cross-Cutting Concerns

**Purpose**: Improvements that affect multiple user stories and final validation

### Integration & Performance

- [ ] T213 [P] Create integration tests for complete workflows in `backend/tests/CaixaSeguradora.IntegrationTests/Workflows/`
- [ ] T214 [P] Create E2E tests using Playwright in `frontend/tests/e2e/` for critical user journeys
- [ ] T215 [P] Add performance benchmarks using BenchmarkDotNet in `backend/tests/CaixaSeguradora.PerformanceTests/` (research.md R8)
- [ ] T216 [P] Run performance comparison: .NET vs COBOL baseline, verify within 120% threshold (SC-015)
- [ ] T217 Test concurrent report generation with 10 simultaneous users, verify <20% degradation (performance goal)
- [ ] T218 Test large dataset processing (10,000+ records), verify <5 minutes completion (SC-003)

### Documentation & Deployment

- [ ] T219 [P] Update README.md in repository root with project overview and quick start links
- [ ] T220 [P] Create API documentation from OpenAPI spec using Redoc or Stoplight in `docs/api/`
- [ ] T221 [P] Add inline code documentation (XML comments) for all public APIs
- [ ] T222 [P] Create deployment guide in `docs/deployment.md` with Docker and Kubernetes instructions
- [ ] T223 [P] Create operations manual in `docs/operations.md` for monitoring, backup, troubleshooting
- [ ] T224 Validate quickstart.md by following all steps from clean environment
- [ ] T225 Create demo video or screenshots of all user stories for stakeholder presentation

### Code Quality & Security

- [ ] T226 [P] Run .NET code analysis (dotnet format, ReSharper inspections), fix all warnings
- [ ] T227 [P] Run frontend linting (eslint, prettier), fix all issues
- [ ] T228 [P] Add authentication/authorization middleware (JWT bearer tokens) per OpenAPI security scheme
- [ ] T229 [P] Add input validation for all API endpoints using FluentValidation
- [ ] T230 [P] Add rate limiting to prevent API abuse
- [ ] T231 [P] Configure HTTPS certificates for production
- [ ] T232 Review all error messages for Portuguese translation accuracy (FR-020)
- [ ] T233 Review Caixa Seguradora branding consistency across all pages (FR-021)

### Final Validation

- [ ] T234 Run full test suite (unit, integration, E2E, comparison) and verify all pass
- [ ] T235 Verify 90%+ code coverage for business logic services (constitution requirement III)
- [ ] T236 Verify byte-for-byte output matching with 100 COBOL samples (constitution requirement III)
- [ ] T237 Verify all 30 functional requirements (FR-001 through FR-030) are met
- [ ] T238 Verify all 19 success criteria (SC-001 through SC-019) are met
- [ ] T239 Conduct user acceptance testing with business stakeholders
- [ ] T240 Create migration sign-off document with validation results

---

## Dependencies & Execution Order

### Phase Dependencies

- **Setup (Phase 1)**: No dependencies - can start immediately
- **Foundational (Phase 2)**: Depends on Setup completion - BLOCKS all user stories
- **User Stories (Phase 3-7)**: All depend on Foundational phase completion
  - User stories can proceed in parallel (if team staffed accordingly)
  - Or sequentially in priority order (P1 → P2 → P3 → P4)
- **Polish (Phase 8)**: Depends on all desired user stories being complete

### User Story Dependencies

- **User Story 1 (P1)**: Can start after Foundational - No dependencies on other stories (Dashboard only)
- **User Story 2 (P2)**: Can start after Foundational - No dependencies on other stories (Report generation standalone)
- **User Story 3 (P3)**: Can start after Foundational - May query same data as US2 but independently testable
- **User Story 4 (P4)**: Can start after Foundational - Schedules reports from US2 but can be tested with mocks
- **User Story 5 (P4)**: Can start after Foundational - Loads data used by all stories but independently testable

### Within Each User Story

- Backend entities before repositories
- Repositories before services
- Services before controllers
- Controllers registered in DI before testing
- Frontend services before components
- Components before pages
- All implementation before independent testing

### Parallel Opportunities

All tasks marked **[P]** can run in parallel within their phase:

- **Setup (Phase 1)**: Tasks T002-T020 can run in parallel (different projects, different files)
- **Foundational (Phase 2)**:
  - Entities T028-T042 can run in parallel (different files)
  - Configurations T043-T057 can run in parallel (different files)
  - Frontend foundation T073-T076 can run in parallel
- **Within User Stories**:
  - DTOs can be created in parallel
  - Repository interfaces can be created in parallel
  - Repository implementations can be created in parallel
  - Frontend components can be created in parallel

Once Foundational phase completes, all 5 user stories can be worked on in parallel by different team members.

---

## Parallel Example: User Story 2

```bash
# Create all repository interfaces together:
Task T095: "Create IPremiumRepository interface in backend/src/CaixaSeguradora.Core/Interfaces/IPremiumRepository.cs"
Task T096: "Create IPolicyRepository interface in backend/src/CaixaSeguradora.Core/Interfaces/IPolicyRepository.cs"
Task T097: "Create IEndorsementRepository interface in backend/src/CaixaSeguradora.Core/Interfaces/IEndorsementRepository.cs"
# ... (all repository interfaces in parallel)

# Create all repository implementations together:
Task T104: "Implement PremiumRepository in backend/src/CaixaSeguradora.Infrastructure/Repositories/PremiumRepository.cs"
Task T105: "Implement PolicyRepository in backend/src/CaixaSeguradora.Infrastructure/Repositories/PolicyRepository.cs"
# ... (all repository implementations in parallel)

# Create all frontend components together:
Task T137: "Create reportService.ts in frontend/src/services/reportService.ts"
Task T138: "Create ReportParametersForm component in frontend/src/components/reports/ReportParametersForm.tsx"
Task T139: "Create ReportProgressIndicator component in frontend/src/components/reports/ReportProgressIndicator.tsx"
# ... (all components in parallel)
```

---

## Implementation Strategy

### MVP First (User Story 1 Only)

1. Complete Phase 1: Setup (T001-T020)
2. Complete Phase 2: Foundational (T021-T076) - CRITICAL, blocks all stories
3. Complete Phase 3: User Story 1 (T077-T094)
4. **STOP and VALIDATE**: Test dashboard independently, verify all metrics display
5. Deploy/demo MVP dashboard

**Timeline**: Estimated 2-3 weeks for skilled .NET/React team

### Incremental Delivery (Recommended)

1. **Week 1-2**: Setup + Foundational → Database schema ready, entities created
2. **Week 3**: User Story 1 → Dashboard complete → **Deploy MVP** 🎯
3. **Week 4-5**: User Story 2 → Report generation complete → **Deploy v1.1**
4. **Week 6**: User Story 3 → Query capability complete → **Deploy v1.2**
5. **Week 7**: User Story 4 → Batch jobs complete → **Deploy v1.3**
6. **Week 8**: User Story 5 → Data management complete → **Deploy v1.4**
7. **Week 9**: Polish & Validation → Final release

Each increment adds value without breaking previous functionality.

### Parallel Team Strategy

With team of 5 developers after Foundational phase complete:

- **Developer A**: User Story 1 (Dashboard) - 1 week
- **Developer B**: User Story 2 (Reports) - 2 weeks (most complex)
- **Developer C**: User Story 3 (Query) - 1.5 weeks
- **Developer D**: User Story 4 (Batch) - 1 week
- **Developer E**: User Story 5 (Data Management) - 1 week

Stories complete and integrate independently. **All 5 stories delivered in 2 weeks** (parallelized).

---

## Task Summary

- **Total Tasks**: 244
- **Setup Tasks**: 20 (Phase 1)
- **Foundational Tasks**: 56 (Phase 2)
- **User Story 1 Tasks**: 18 (Phase 3)
- **User Story 2 Tasks**: 72 (Phase 4)
- **User Story 3 Tasks**: 24 (Phase 5)
- **User Story 4 Tasks**: 24 (Phase 6)
- **User Story 5 Tasks**: 21 (Phase 7)
- **Polish Tasks**: 28 (Phase 8)

**Parallel Opportunities**: 120+ tasks marked [P] can run in parallel

**MVP Scope (Recommended)**: Phase 1 + Phase 2 + Phase 3 = 94 tasks (Weeks 1-3)

**Independent Test Criteria**:
- **US1**: Dashboard loads, all metrics display, charts render
- **US2**: Generate report, download file, byte-match COBOL output
- **US3**: Execute query, view results, export to CSV
- **US4**: Create scheduled job, monitor execution, receive notification
- **US5**: Load CSV data, validate schema, run comparison

---

## Notes

- **[P] tasks** = different files, no dependencies, safe to parallelize
- **[Story] label** maps task to specific user story for traceability
- Each user story is independently completable and testable
- Constitution requirement: 90%+ test coverage for business logic (T119, T120 in US2)
- Constitution requirement: 100% byte-match validation (T132-T136 in US2)
- All user-facing content must be in Portuguese (FR-020)
- Commit after each task or logical group of tasks
- Stop at any checkpoint to validate story independently
- Byte-level COBOL comparison is NON-NEGOTIABLE for regulatory compliance

---

**Generated**: October 22, 2025
**Status**: Ready for implementation
**Next Command**: `/speckit.implement T001` to start implementation



### RESEARCH.MD (Decisions & Constraints)

# Technical Research: COBOL RG1866B to .NET 9 Migration

**Date**: October 22, 2025
**Project**: SUSEP Circular 360 Premium Reporting System Migration
**Status**: Complete - All 8 Research Areas Documented

## Overview

This document captures technical research and decisions for migrating COBOL RG1866B to .NET 9 with React frontend. All research areas address critical requirements for regulatory compliance, particularly byte-for-byte output matching and decimal precision in financial calculations.

---

## R1: COBOL to C# Type Mapping Strategy

**Decision**: Comprehensive type mapping using C# `decimal` for all numeric fields with precision/scale matching COBOL PIC definitions, `string` with fixed-length awareness for alphanumeric, and custom `CobolDateTime` wrapper for date handling

**Rationale**:
- COBOL PIC 9(n)V9(m) represents packed decimal with exact precision - C# `decimal` type provides equivalent precision (up to 28-29 significant digits) required for financial calculations
- Regulatory compliance demands zero arithmetic deviation - `float`/`double` introduce rounding errors unacceptable for insurance premiums
- Fixed-length string handling critical for COBOL compatibility where `PIC X(10)` always occupies 10 bytes with space padding

**Type Mapping Table**:

| COBOL PIC Type | C# Type | Notes |
|----------------|---------|-------|
| PIC 9(n) | `int` or `long` | n ≤ 9: `int`, n > 9: `long` |
| PIC 9(n)V9(m) | `decimal` | Precision: n+m, Scale: m |
| PIC S9(n) | `int` or `long` | Signed integer, same size rules |
| PIC S9(n)V9(m) | `decimal` | Signed decimal with precision/scale |
| PIC S9(n) COMP-3 | `int` | Packed decimal, 2 digits per byte |
| PIC X(n) | `string` | Fixed length n, space-padded |
| PIC A(n) | `string` | Alphabetic only, space-padded |
| YYYYMMDD | `DateTime` | Parse with CultureInfo.InvariantCulture |
| DDMMYYYY | `DateTime` | Custom formatter required |

**Alternatives Considered**:
1. **Use `double` for decimals** - Rejected: Binary floating-point introduces rounding errors (e.g., 0.1 + 0.2 ≠ 0.3 exactly). Insurance calculations require exact decimal arithmetic.
2. **Use `BigDecimal` library** - Rejected: C# `decimal` is native, faster, and sufficient for precision requirements (28-29 digits covers all COBOL use cases in RG1866B)
3. **String-based arithmetic** - Rejected: Overly complex, slower performance, error-prone parsing

**Implementation Notes**:

```csharp
// Custom attribute for COBOL type metadata
[AttributeUsage(AttributeTargets.Property)]
public class CobolFieldAttribute : Attribute
{
    public string PicClause { get; set; }
    public int Length { get; set; }
    public int DecimalPlaces { get; set; }
    public CobolFieldType FieldType { get; set; }
}

// Example entity with COBOL mapping
public class Premium
{
    [CobolField(PicClause = "9(15)V99", Length = 17, DecimalPlaces = 2)]
    public decimal PremiumAmount { get; set; }  // Maps to PIC 9(15)V99

    [CobolField(PicClause = "X(10)", Length = 10)]
    public string PolicyNumber { get; set; }  // Maps to PIC X(10)

    [CobolField(PicClause = "9(8)", Length = 8)]
    public DateTime EffectiveDate { get; set; }  // YYYYMMDD format
}

// Rounding mode matching COBOL
public static class CobolMath
{
    // COBOL ROUND mode equivalent
    public static decimal RoundAwayFromZero(decimal value, int decimals)
    {
        return Math.Round(value, decimals, MidpointRounding.AwayFromZero);
    }

    // COBOL TRUNCATE equivalent
    public static decimal Truncate(decimal value, int decimals)
    {
        decimal multiplier = (decimal)Math.Pow(10, decimals);
        return Math.Truncate(value * multiplier) / multiplier;
    }
}
```

**References**:
- .NET `decimal` type documentation: https://learn.microsoft.com/en-us/dotnet/api/system.decimal
- COBOL PIC clause reference: https://www.ibm.com/docs/en/cobol-zos/6.4?topic=definitions-picture-clause
- Decimal precision in financial systems: https://stackoverflow.com/questions/3730019/why-not-use-double-or-float-to-represent-currency

---

## R2: Fixed-Width File Generation

**Decision**: Custom `FixedWidthFormatter` class using `StringBuilder` with explicit padding rules, validated via byte-level comparison against COBOL output samples

**Rationale**:
- COBOL WRITE statements generate fixed-width records with precise space/zero padding rules that standard .NET formatters don't replicate
- Regulatory requirement for byte-for-byte matching means even a single misplaced space causes compliance failure
- Performance critical for large files (10,000+ records) - `StringBuilder` approach is faster than string concatenation

**Padding Rules (COBOL Behavior)**:

| Data Type | Padding Rule | Example |
|-----------|--------------|---------|
| Numeric PIC 9(n) | Left-pad with zeros | 123 → "00123" for PIC 9(5) |
| Decimal PIC 9(n)V9(m) | Left-pad whole part with zeros, right-pad decimal with zeros | 12.3 → "00012.30" for PIC 9(5)V9(2) |
| Alpha PIC X(n) | Right-pad with spaces | "ABC" → "ABC       " for PIC X(10) |
| Signed PIC S9(n) | Leading sign, left-pad with zeros | -123 → "-00123" for PIC S9(5) |

**Alternatives Considered**:
1. **Use String.Format()** - Rejected: Doesn't support COBOL-specific padding rules (e.g., decimal with 'V' implied decimal point)
2. **TextFieldParser library** - Rejected: Designed for reading, not writing fixed-width files
3. **COBOL copybook parser libraries** - Rejected: Introduces unnecessary dependency, overkill for output generation

**Implementation Notes**:

```csharp
public class FixedWidthFormatter
{
    public string FormatNumeric(decimal value, int totalWidth, int decimalPlaces, bool includeDecimalPoint = false)
    {
        // COBOL PIC 9(n)V9(m) - V means implied decimal, not printed
        if (!includeDecimalPoint)
        {
            // Multiply by 10^decimalPlaces to get integer representation
            decimal multiplied = value * (decimal)Math.Pow(10, decimalPlaces);
            long intValue = (long)Math.Round(multiplied, MidpointRounding.AwayFromZero);
            return intValue.ToString().PadLeft(totalWidth, '0');
        }
        else
        {
            // Explicit decimal point (rare in COBOL output files)
            string formatted = value.ToString($"F{decimalPlaces}");
            return formatted.PadLeft(totalWidth, '0');
        }
    }

    public string FormatAlphanumeric(string value, int width)
    {
        // COBOL PIC X(n) - right-pad with spaces
        if (value == null) value = "";
        if (value.Length > width) value = value.Substring(0, width);  // Truncate if too long
        return value.PadRight(width, ' ');
    }

    public string FormatDate(DateTime date, string format = "yyyyMMdd")
    {
        // COBOL date formats: YYYYMMDD, DDMMYYYY, YYMMDD
        return date.ToString(format);
    }

    // Example usage for PREMIT.TXT record
    public string FormatPremitRecord(PremiumRecord record)
    {
        var sb = new StringBuilder();
        sb.Append(FormatAlphanumeric(record.PolicyNumber, 10));
        sb.Append(FormatNumeric(record.PremiumAmount, 15, 2));  // PIC 9(13)V99
        sb.Append(FormatDate(record.EffectiveDate));
        sb.Append(FormatAlphanumeric(record.ProductCode, 5));
        // ... continue for all 50+ fields in layout
        return sb.ToString();
    }
}

// Validation: Byte-level comparison
public class OutputValidator
{
    public ComparisonResult CompareFiles(string cobolFile, string dotnetFile)
    {
        byte[] cobolBytes = File.ReadAllBytes(cobolFile);
        byte[] dotnetBytes = File.ReadAllBytes(dotnetFile);

        if (cobolBytes.Length != dotnetBytes.Length)
        {
            return new ComparisonResult
            {
                Match = false,
                Error = $"File size mismatch: {cobolBytes.Length} vs {dotnetBytes.Length}"
            };
        }

        for (int i = 0; i < cobolBytes.Length; i++)
        {
            if (cobolBytes[i] != dotnetBytes[i])
            {
                return new ComparisonResult
                {
                    Match = false,
                    Error = $"Byte mismatch at position {i}: {cobolBytes[i]} vs {dotnetBytes[i]}",
                    Context = GetContext(dotnetBytes, i, 50)
                };
            }
        }

        return new ComparisonResult { Match = true };
    }
}
```

**References**:
- StringBuilder performance: https://learn.microsoft.com/en-us/dotnet/api/system.text.stringbuilder
- Fixed-width file patterns: https://www.codeproject.com/Articles/26176/Reading-and-Writing-Fixed-Width-Text-Files
- COBOL file handling: https://www.ibm.com/docs/en/cobol-zos/6.4?topic=division-file-section

---

## R3: Cursor-Based Processing Pattern

**Decision**: Use EF Core `AsNoTracking()` with `IAsyncEnumerable<T>` for streaming large datasets, implementing COBOL cursor semantics through async iteration

**Rationale**:
- COBOL cursors (DECLARE, OPEN, FETCH loop, CLOSE) enable processing millions of records without loading all into memory
- EF Core change tracking consumes significant memory - `AsNoTracking()` disables tracking for read-only operations (all report generation is read-only)
- `IAsyncEnumerable<T>` introduced in C# 8.0 provides native streaming support matching cursor behavior

**COBOL Cursor Example** (from RG1866B):
```cobol
EXEC SQL
    DECLARE C1 CURSOR FOR
        SELECT POLICY_NUM, PREMIUM_AMT, EFFECTIVE_DATE
        FROM V0PREMIOS
        WHERE EFFECTIVE_DATE BETWEEN :START-DATE AND :END-DATE
END-EXEC.

EXEC SQL OPEN C1 END-EXEC.

PERFORM UNTIL SQLCODE NOT = 0
    EXEC SQL FETCH C1 INTO :WS-POLICY-NUM, :WS-PREMIUM-AMT, :WS-EFFECTIVE-DATE END-EXEC
    IF SQLCODE = 0
        PERFORM PROCESS-RECORD
    END-IF
END-PERFORM.

EXEC SQL CLOSE C1 END-EXEC.
```

**C# Equivalent**:
```csharp
// Repository method with streaming
public async IAsyncEnumerable<PremiumRecord> GetPremiumsAsync(
    DateTime startDate,
    DateTime endDate,
    [EnumeratorCancellation] CancellationToken cancellationToken = default)
{
    var query = _context.Premiums
        .AsNoTracking()  // Disable change tracking (read-only)
        .Where(p => p.EffectiveDate >= startDate && p.EffectiveDate <= endDate)
        .OrderBy(p => p.PolicyNumber);  // Match COBOL cursor ordering

    await foreach (var record in query.AsAsyncEnumerable().WithCancellation(cancellationToken))
    {
        yield return record;
    }
}

// Service layer processing (matches COBOL PERFORM loop)
public async Task<ReportResult> GenerateReportAsync(DateTime startDate, DateTime endDate)
{
    int recordsProcessed = 0;
    var reportData = new List<ReportLine>();

    await foreach (var premium in _repository.GetPremiumsAsync(startDate, endDate))
    {
        // Process each record (equivalent to COBOL PERFORM PROCESS-RECORD)
        var reportLine = await ProcessPremiumRecord(premium);
        reportData.Add(reportLine);
        recordsProcessed++;

        // Optional: Report progress for long-running operations
        if (recordsProcessed % 1000 == 0)
        {
            _logger.LogInformation($"Processed {recordsProcessed} records");
        }
    }

    return new ReportResult { RecordsProcessed = recordsProcessed, Data = reportData };
}
```

**Alternatives Considered**:
1. **Load all records with .ToListAsync()** - Rejected: Out-of-memory exception for millions of records; COBOL handles via cursor specifically to avoid memory issues
2. **Manual pagination (Skip/Take)** - Rejected: More complex code, requires tracking page number, less performant than streaming
3. **SqlDataReader directly** - Rejected: Loses EF Core benefits (LINQ, entity mapping), introduces SQL injection risks

**Implementation Notes**:

- **Memory Management**: `AsNoTracking()` reduces memory per entity from ~2KB to ~200 bytes (10x improvement)
- **Batching for Writes**: When writing output files, batch writes every 1000 records to balance memory vs I/O

```csharp
// Batch writing pattern
public async Task WriteReportAsync(IAsyncEnumerable<ReportLine> lines, string filePath)
{
    using var writer = new StreamWriter(filePath, append: false, Encoding.UTF8);
    var batch = new List<string>(1000);

    await foreach (var line in lines)
    {
        batch.Add(_formatter.FormatLine(line));

        if (batch.Count >= 1000)
        {
            await writer.WriteAsync(string.Join(Environment.NewLine, batch));
            batch.Clear();
        }
    }

    // Write remaining records
    if (batch.Count > 0)
    {
        await writer.WriteAsync(string.Join(Environment.NewLine, batch));
    }
}
```

- **Cancellation Support**: Always accept `CancellationToken` for long-running operations to allow user cancellation
- **Transaction Boundaries**: Read-only cursors don't need transactions, but if cursor includes updates, wrap in `TransactionScope`

**References**:
- IAsyncEnumerable: https://learn.microsoft.com/en-us/dotnet/csharp/asynchronous-programming/
- EF Core streaming: https://learn.microsoft.com/en-us/ef/core/performance/efficient-querying#streaming-results
- AsNoTracking performance: https://learn.microsoft.com/en-us/ef/core/querying/tracking

---

## R4: External Module Integration

**Decision**: Create C# service interfaces (`IReinsuranceService`, `ICalculationService`) to abstract external modules, implement mock versions initially, design for future integration or replacement

**Rationale**:
- COBOL modules RE0001S (reinsurance), GE0009S, GE0010S have LINKAGE SECTION parameters that can be mapped to C# method signatures
- Mocking allows migration to proceed without COBOL module source code or runtime
- Service abstraction enables future replacement with modern APIs or third-party services
- Testing strategy: mock services for unit tests, stub services for integration tests

**COBOL Module Call Example** (from RG1866B):
```cobol
CALL 'RE0001S' USING LKRE-PARM-RE0001S.

* LINKAGE SECTION structure
01 LKRE-PARM-RE0001S.
   05 LKRE-INPUT-AREA.
      10 LKRE-POLICY-NUMBER        PIC X(10).
      10 LKRE-EFFECTIVE-DATE       PIC 9(8).
      10 LKRE-PREMIUM-AMOUNT       PIC 9(13)V99.
   05 LKRE-OUTPUT-AREA.
      10 LKRE-RETAINED-PREMIUM     PIC 9(13)V99.
      10 LKRE-CEDED-PREMIUM        PIC 9(13)V99.
      10 LKRE-RETURN-CODE          PIC 9(2).
```

**C# Service Interface**:
```csharp
// Service contract matching COBOL module signature
public interface IReinsuranceService
{
    Task<ReinsuranceResult> CalculateReinsuranceAsync(ReinsuranceRequest request);
}

// Request DTO (maps to LKRE-INPUT-AREA)
public class ReinsuranceRequest
{
    [CobolField(PicClause = "X(10)")]
    public string PolicyNumber { get; set; }

    [CobolField(PicClause = "9(8)")]
    public DateTime EffectiveDate { get; set; }

    [CobolField(PicClause = "9(13)V99")]
    public decimal PremiumAmount { get; set; }
}

// Response DTO (maps to LKRE-OUTPUT-AREA)
public class ReinsuranceResult
{
    [CobolField(PicClause = "9(13)V99")]
    public decimal RetainedPremium { get; set; }

    [CobolField(PicClause = "9(13)V99")]
    public decimal CededPremium { get; set; }

    [CobolField(PicClause = "9(2)")]
    public int ReturnCode { get; set; }

    public bool IsSuccess => ReturnCode == 0;
    public string ErrorMessage { get; set; }
}

// Mock implementation for testing
public class MockReinsuranceService : IReinsuranceService
{
    public Task<ReinsuranceResult> CalculateReinsuranceAsync(ReinsuranceRequest request)
    {
        // Mock logic based on assumed business rules from COBOL analysis
        // For production, would need actual module logic or API integration
        var result = new ReinsuranceResult
        {
            RetainedPremium = request.PremiumAmount * 0.80m,  // Assume 80% retention
            CededPremium = request.PremiumAmount * 0.20m,     // Assume 20% ceded
            ReturnCode = 0
        };

        return Task.FromResult(result);
    }
}

// Real implementation option 1: COBOL module interop (if COBOL runtime available)
public class CobolReinsuranceService : IReinsuranceService
{
    [DllImport("RE0001S.dll", CallingConvention = CallingConvention.Cdecl)]
    private static extern void RE0001S(ref CobolLinkageArea linkage);

    public Task<ReinsuranceResult> CalculateReinsuranceAsync(ReinsuranceRequest request)
    {
        // Marshal request to COBOL structure
        var linkage = MarshalToCobol(request);

        // Call COBOL module
        RE0001S(ref linkage);

        // Marshal response from COBOL structure
        var result = MarshalFromCobol(linkage);

        return Task.FromResult(result);
    }
}

// Real implementation option 2: REST API wrapper (if modules exposed as services)
public class ApiReinsuranceService : IReinsuranceService
{
    private readonly HttpClient _httpClient;

    public async Task<ReinsuranceResult> CalculateReinsuranceAsync(ReinsuranceRequest request)
    {
        var response = await _httpClient.PostAsJsonAsync("/api/reinsurance/calculate", request);
        response.EnsureSuccessStatusCode();
        return await response.Content.ReadFromJsonAsync<ReinsuranceResult>();
    }
}
```

**Alternatives Considered**:
1. **Direct P/Invoke to COBOL DLLs** - Rejected: Requires COBOL runtime on .NET server, marshalling complexity, not cross-platform
2. **Reverse-engineer and reimplement in C#** - Rejected: High risk of logic errors, time-consuming, requires deep business knowledge
3. **Keep COBOL modules in separate process** - Rejected: Adds deployment complexity, inter-process communication overhead

**Implementation Notes**:

- **Dependency Injection Setup**:
```csharp
// In Program.cs
builder.Services.AddScoped<IReinsuranceService, MockReinsuranceService>();  // For development
// builder.Services.AddScoped<IReinsuranceService, CobolReinsuranceService>();  // For production with COBOL runtime
// builder.Services.AddScoped<IReinsuranceService, ApiReinsuranceService>();  // For production with API gateway
```

- **Testing Strategy**:
  - Unit tests use `Mock<IReinsuranceService>` with Moq library
  - Integration tests use `MockReinsuranceService` with controlled test data
  - Validation tests compare mock outputs against documented COBOL module examples (if available)

- **Documentation Requirement**: Document assumptions for each mocked module in `docs/migration/external-modules.md`

**References**:
- P/Invoke fundamentals: https://learn.microsoft.com/en-us/dotnet/standard/native-interop/pinvoke
- Dependency injection: https://learn.microsoft.com/en-us/aspnet/core/fundamentals/dependency-injection
- Testing with Moq: https://github.com/moq/moq4/wiki/Quickstart

---

## R5: Transaction Boundary Replication

**Decision**: Use explicit `TransactionScope` with `TransactionScopeAsyncFlowOption.Enabled` for multi-operation transactions, matching COBOL COMMIT points exactly

**Rationale**:
- COBOL program has explicit COMMIT statements after completing logical units of work (e.g., after processing all records for a report)
- EF Core `SaveChanges()` auto-commits each time called - must wrap multiple saves in transaction to match COBOL semantics
- `TransactionScope` enables distributed transactions if future production requires multiple databases
- Async flow option required for async/await code paths

**COBOL Transaction Example**:
```cobol
* Process all premium records
PERFORM VARYING WS-IDX FROM 1 BY 1 UNTIL WS-IDX > WS-TOTAL-RECORDS
    PERFORM PROCESS-RECORD
    IF SQL-ERROR
        EXEC SQL ROLLBACK END-EXEC
        PERFORM ERROR-HANDLING
        STOP RUN
    END-IF
END-PERFORM.

* Commit all changes if successful
EXEC SQL COMMIT END-EXEC.
```

**C# Equivalent**:
```csharp
public async Task<ReportResult> GenerateReportAsync(DateTime startDate, DateTime endDate)
{
    using var scope = new TransactionScope(
        TransactionScopeOption.Required,
        new TransactionOptions { IsolationLevel = IsolationLevel.ReadCommitted },
        TransactionScopeAsyncFlowOption.Enabled);  // CRITICAL for async methods

    try
    {
        // Process all records (read-only in this case, but pattern shows transaction usage)
        int recordsProcessed = 0;
        await foreach (var premium in _repository.GetPremiumsAsync(startDate, endDate))
        {
            await ProcessPremiumRecord(premium);
            recordsProcessed++;
        }

        // Write report metadata to database (this DOES modify database)
        var reportMetadata = new ReportDefinition
        {
            ReportDate = DateTime.Now,
            StartDate = startDate,
            EndDate = endDate,
            RecordsProcessed = recordsProcessed,
            Status = ReportStatus.Completed
        };

        await _context.Reports.AddAsync(reportMetadata);
        await _context.SaveChangesAsync();  // Part of transaction

        // COMMIT equivalent
        scope.Complete();

        return new ReportResult { Success = true, RecordsProcessed = recordsProcessed };
    }
    catch (Exception ex)
    {
        // ROLLBACK automatic when scope disposes without Complete()
        _logger.LogError(ex, "Report generation failed, transaction rolled back");
        throw;
    }
}
```

**EF Core-Specific Pattern** (alternative to TransactionScope):
```csharp
public async Task<Result> MultiStepOperationAsync()
{
    using var transaction = await _context.Database.BeginTransactionAsync(IsolationLevel.ReadCommitted);

    try
    {
        // Step 1: Insert report header
        var report = new Report { /*...*/ };
        _context.Reports.Add(report);
        await _context.SaveChangesAsync();  // Writes to database but not committed yet

        // Step 2: Insert report details
        foreach (var detail in reportDetails)
        {
            _context.ReportDetails.Add(detail);
        }
        await _context.SaveChangesAsync();  // Still in same transaction

        // COMMIT
        await transaction.CommitAsync();

        return Result.Success();
    }
    catch (Exception ex)
    {
        // ROLLBACK
        await transaction.RollbackAsync();
        _logger.LogError(ex, "Transaction failed");
        return Result.Failure(ex.Message);
    }
}
```

**Alternatives Considered**:
1. **Auto-commit with SaveChanges()** - Rejected: Can't replicate COBOL multi-step transactions, risk of partial updates
2. **Manual SQL transactions** - Rejected: Loses EF Core benefits, harder to maintain
3. **Saga pattern** - Rejected: Overkill for single-database operations, adds complexity

**Implementation Notes**:

- **Isolation Levels**:
  - COBOL default: typically `ReadCommitted`
  - Match COBOL isolation level in C#: `IsolationLevel.ReadCommitted`
  - For COBOL `SELECT FOR UPDATE`: use `IsolationLevel.Serializable` or EF Core `.FromSqlRaw("SELECT ... FOR UPDATE")`

- **Deadlock Handling** (matches COBOL -911 SQLCODE):
```csharp
public async Task<Result> OperationWithDeadlockRetryAsync()
{
    int maxRetries = 3;
    int retryCount = 0;

    while (retryCount < maxRetries)
    {
        try
        {
            using var scope = new TransactionScope(/* ... */);
            // Perform operations
            scope.Complete();
            return Result.Success();
        }
        catch (DbUpdateException ex) when (IsDeadlock(ex))
        {
            retryCount++;
            if (retryCount >= maxRetries) throw;

            _logger.LogWarning($"Deadlock detected, retry {retryCount}/{maxRetries}");
            await Task.Delay(TimeSpan.FromMilliseconds(100 * retryCount));  // Exponential backoff
        }
    }
}

private bool IsDeadlock(DbUpdateException ex)
{
    // SQLite: SQLITE_BUSY (5), SQL Server: 1205, DB2: -911
    return ex.InnerException?.Message.Contains("deadlock") == true;
}
```

- **Read-Only Operations**: Don't need transactions unless multiple reads must be consistent snapshot

**References**:
- TransactionScope: https://learn.microsoft.com/en-us/dotnet/api/system.transactions.transactionscope
- EF Core transactions: https://learn.microsoft.com/en-us/ef/core/saving/transactions
- Isolation levels: https://learn.microsoft.com/en-us/sql/t-sql/statements/set-transaction-isolation-level-transact-sql

---

## R6: Caixa Seguradora Branding Implementation

**Decision**: Extract color palette and typography from website, implement with TailwindCSS custom theme configuration, use shadcn/ui component library as foundation with Caixa Seguradora customization

**Rationale**:
- TailwindCSS provides utility-first CSS matching modern React best practices, easy to customize with brand colors
- shadcn/ui offers accessible, unstyled components (headless UI) that can be themed to match Caixa Seguradora branding exactly
- Extracting colors directly from website ensures brand consistency
- Component library approach ensures UI consistency across all pages

**Brand Analysis** (from https://www.caixaseguradora.com.br/):

**Color Palette**:
```css
/* Primary Colors */
--caixa-blue: #0047BB;          /* Primary brand color (header, buttons) */
--caixa-blue-dark: #003380;     /* Darker blue for hover states */
--caixa-blue-light: #E6F0FF;    /* Light blue for backgrounds */

/* Secondary Colors */
--caixa-yellow: #FFB81C;        /* Accent color (CTA buttons, highlights) */
--caixa-yellow-dark: #E6A519;   /* Darker yellow for hover */

/* Neutral Colors */
--caixa-gray-900: #1A1A1A;      /* Headings */
--caixa-gray-700: #4A4A4A;      /* Body text */
--caixa-gray-400: #BDBDBD;      /* Borders */
--caixa-gray-100: #F5F5F5;      /* Light backgrounds */
--caixa-white: #FFFFFF;         /* White */

/* Semantic Colors */
--caixa-success: #28A745;       /* Success messages */
--caixa-error: #DC3545;         /* Error messages */
--caixa-warning: #FFC107;       /* Warning messages */
--caixa-info: #17A2B8;          /* Info messages */
```

**Typography Stack**:
```css
/* Font Families */
--font-primary: 'Segoe UI', 'Helvetica Neue', Arial, sans-serif;  /* Body text */
--font-headings: 'Segoe UI', 'Helvetica Neue', Arial, sans-serif;  /* Headings */

/* Font Sizes (Tailwind scale) */
--text-xs: 0.75rem;     /* 12px */
--text-sm: 0.875rem;    /* 14px */
--text-base: 1rem;      /* 16px */
--text-lg: 1.125rem;    /* 18px */
--text-xl: 1.25rem;     /* 20px */
--text-2xl: 1.5rem;     /* 24px */
--text-3xl: 1.875rem;   /* 30px */
--text-4xl: 2.25rem;    /* 36px */

/* Font Weights */
--font-normal: 400;
--font-medium: 500;
--font-semibold: 600;
--font-bold: 700;
```

**Implementation**:

**1. Tailwind Configuration** (`tailwind.config.js`):
```javascript
/** @type {import('tailwindcss').Config} */
export default {
  content: [
    "./index.html",
    "./src/**/*.{js,ts,jsx,tsx}",
  ],
  theme: {
    extend: {
      colors: {
        caixa: {
          blue: {
            DEFAULT: '#0047BB',
            dark: '#003380',
            light: '#E6F0FF',
          },
          yellow: {
            DEFAULT: '#FFB81C',
            dark: '#E6A519',
          },
          gray: {
            900: '#1A1A1A',
            700: '#4A4A4A',
            400: '#BDBDBD',
            100: '#F5F5F5',
          },
        },
        success: '#28A745',
        error: '#DC3545',
        warning: '#FFC107',
        info: '#17A2B8',
      },
      fontFamily: {
        sans: ['Segoe UI', 'Helvetica Neue', 'Arial', 'sans-serif'],
      },
    },
  },
  plugins: [],
}
```

**2. Global Styles** (`src/styles/globals.css`):
```css
@tailwind base;
@tailwind components;
@tailwind utilities;

@layer base {
  body {
    @apply font-sans text-base text-caixa-gray-700 bg-white;
  }

  h1 {
    @apply text-4xl font-bold text-caixa-gray-900;
  }

  h2 {
    @apply text-3xl font-semibold text-caixa-gray-900;
  }

  h3 {
    @apply text-2xl font-semibold text-caixa-gray-900;
  }
}

@layer components {
  .btn-primary {
    @apply bg-caixa-blue hover:bg-caixa-blue-dark text-white font-medium px-4 py-2 rounded transition-colors;
  }

  .btn-secondary {
    @apply bg-caixa-yellow hover:bg-caixa-yellow-dark text-caixa-gray-900 font-medium px-4 py-2 rounded transition-colors;
  }

  .card {
    @apply bg-white border border-caixa-gray-400 rounded-lg shadow-sm p-6;
  }
}
```

**3. Component Example** (Header with branding):
```tsx
export function Header() {
  return (
    <header className="bg-caixa-blue text-white shadow-md">
      <div className="container mx-auto px-4 py-4 flex items-center justify-between">
        <div className="flex items-center space-x-4">
          <img
            src="/assets/logo-caixa.png"
            alt="Caixa Seguradora"
            className="h-10"
          />
          <h1 className="text-2xl font-bold text-white">
            Sistema de Relatórios SUSEP
          </h1>
        </div>

        <nav className="flex space-x-6">
          <a href="/dashboard" className="hover:text-caixa-yellow transition-colors">
            Dashboard
          </a>
          <a href="/reports" className="hover:text-caixa-yellow transition-colors">
            Relatórios
          </a>
          <a href="/query" className="hover:text-caixa-yellow transition-colors">
            Consultas
          </a>
        </nav>
      </div>
    </header>
  );
}
```

**Alternatives Considered**:
1. **Material-UI with theme override** - Rejected: Harder to match exact branding, larger bundle size, opinionated styling
2. **Bootstrap with SASS customization** - Rejected: Less modern than Tailwind, more opinionated class names
3. **Pure CSS** - Rejected: Harder to maintain consistency, no utility classes, slower development

**Implementation Notes**:

- **Logo Usage**: Verify licensing for Caixa Seguradora logo - may need written permission for internal application usage
- **Accessibility**: Ensure color contrast ratios meet WCAG AA standards (blue #0047BB on white passes at 8.59:1)
- **Responsive Design**: Use Tailwind responsive prefixes (`sm:`, `md:`, `lg:`, `xl:`) for mobile-first design
- **Dark Mode**: Not required per spec, but Tailwind supports if needed future

**References**:
- TailwindCSS customization: https://tailwindcss.com/docs/theme
- shadcn/ui components: https://ui.shadcn.com/
- WCAG contrast checker: https://webaim.org/resources/contrastchecker/

---

## R7: SQLite to DB2 Compatibility Layer

**Decision**: Document SQL dialect differences, create abstract repository layer to isolate database-specific queries, use EF Core query translation with custom SQLite functions for DB2-specific operations

**Rationale**:
- SQLite chosen for development to avoid mainframe access requirement, but must be production-ready for DB2 migration
- Repository pattern abstracts database access - switching from SQLite to DB2 only requires changing connection string and minor query adjustments
- EF Core LINQ queries translate to both SQLite and DB2 SQL, minimizing dialect-specific code
- Known limitations can be worked around with documented patterns

**Key Differences & Solutions**:

| Feature | COBOL/DB2 | SQLite | Solution |
|---------|-----------|--------|----------|
| **Date Functions** | `DAYS(date1) - DAYS(date2)` | `julianday(date1) - julianday(date2)` | Abstract in repository method `GetDaysBetween()` |
| **String Functions** | `SUBSTR(str, pos, len)` (1-indexed) | `substr(str, pos, len)` (1-indexed, compatible!) | No change needed |
| **Decimal Precision** | `DECIMAL(p, s)` explicit | SQLite stores as TEXT or REAL | EF Core maps `decimal` correctly, validate precision in tests |
| **Stored Procedures** | Supported | Not supported | Move logic to C# service layer |
| **Cursors** | Native DECLARE CURSOR | Not needed | Use IAsyncEnumerable as shown in R3 |
| **Isolation Levels** | Full ACID with READ COMMITTED default | Serialized by default (single writer) | Use `PRAGMA read_uncommitted=1` for testing concurrency |
| **Sequences** | `CREATE SEQUENCE`, `NEXTVAL` | `AUTOINCREMENT` on INTEGER PRIMARY KEY | Use EF Core value generation, abstracts both |

**Repository Abstraction Example**:
```csharp
public interface IPremiumRepository
{
    Task<IEnumerable<PremiumRecord>> GetPremiumsByDateRangeAsync(DateTime startDate, DateTime endDate);
    Task<int> GetDaysBetweenDatesAsync(DateTime date1, DateTime date2);
}

// SQLite implementation
public class SqlitePremiumRepository : IPremiumRepository
{
    private readonly ApplicationDbContext _context;

    public async Task<int> GetDaysBetweenDatesAsync(DateTime date1, DateTime date2)
    {
        // SQLite-specific function
        var sql = "SELECT CAST(julianday(@date1) - julianday(@date2) AS INTEGER)";
        return await _context.Database.ExecuteSqlRawAsync(sql,
            new SqliteParameter("@date1", date1),
            new SqliteParameter("@date2", date2));
    }
}

// DB2 implementation (for future production)
public class Db2PremiumRepository : IPremiumRepository
{
    private readonly ApplicationDbContext _context;

    public async Task<int> GetDaysBetweenDatesAsync(DateTime date1, DateTime date2)
    {
        // DB2-specific function
        var sql = "SELECT DAYS(@date1) - DAYS(@date2) FROM SYSIBM.SYSDUMMY1";
        return await _context.Database.ExecuteSqlRawAsync(sql,
            new Db2Parameter("@date1", date1),
            new Db2Parameter("@date2", date2));
    }
}
```

**EF Core Configuration**:
```csharp
// Startup configuration
services.AddDbContext<ApplicationDbContext>(options =>
{
    if (isDevelopment)
    {
        options.UseSqlite(connectionString, sqliteOptions =>
        {
            sqliteOptions.UseQuerySplittingBehavior(QuerySplittingBehavior.SplitQuery);
        });
    }
    else
    {
        options.UseDb2(connectionString, db2Options =>
        {
            db2Options.SetServerInfo(new DB2ServerInfo { ServerType = DB2ServerType.LUW });
        });
    }
});
```

**Alternatives Considered**:
1. **Use DB2 Express-C for development** - Rejected: Complex setup, licensing questions, doesn't run well on macOS/Linux dev machines
2. **PostgreSQL as dev database** - Rejected: Still requires server setup, SQLite simpler for POC
3. **In-memory database** - Rejected: Loses data between runs, harder to inspect data for debugging

**Implementation Notes**:

- **Schema Generation**: Create SQLite schema matching DB2 exactly (table names, column names, data types)
```sql
-- Example matching V0PREMIOS view structure
CREATE TABLE V0PREMIOS (
    POLICY_NUMBER VARCHAR(10) NOT NULL,
    PREMIUM_AMOUNT DECIMAL(15, 2) NOT NULL,
    EFFECTIVE_DATE DATE NOT NULL,
    PRODUCT_CODE VARCHAR(5),
    /* ... 50+ columns matching DB2 view */
    PRIMARY KEY (POLICY_NUMBER, EFFECTIVE_DATE)
);

CREATE INDEX IDX_V0PREMIOS_DATE ON V0PREMIOS(EFFECTIVE_DATE);
```

- **Mock Data Loading**: Create CSV files matching DB2 export format, load with SQLite `.import` command or bulk insert via EF Core

- **Type Mapping Validation**: Write unit tests confirming decimal precision maintained:
```csharp
[Fact]
public void DecimalPrecision_MaintainedInSqlite()
{
    var value = 123456789012345.67m;  // 15 digits + 2 decimal places

    _context.TestDecimals.Add(new TestDecimal { Value = value });
    _context.SaveChanges();

    var retrieved = _context.TestDecimals.First().Value;

    Assert.Equal(value, retrieved);  // Must be exact match
}
```

**References**:
- SQLite vs DB2 comparison: https://db-engines.com/en/system/DB2%3BSQLite
- EF Core SQLite provider: https://learn.microsoft.com/en-us/ef/core/providers/sqlite/
- IBM Db2 .NET provider: https://www.ibm.com/docs/en/db2/11.5?topic=apis-db2-net

---

## R8: Performance Baseline Establishment

**Decision**: Use BenchmarkDotNet for micro-benchmarks, Application Insights or Serilog + Seq for production profiling, custom comparison framework to validate .NET performance vs COBOL baseline

**Rationale**:
- Need quantitative evidence that .NET migration meets success criteria (within 120% of COBOL execution time)
- BenchmarkDotNet industry standard for .NET performance testing, provides statistical analysis and warmup handling
- Continuous profiling during development catches regressions early
- Success criteria includes specific metrics (10,000 records in 5 minutes, dashboard load in 2 seconds)

**Benchmark Framework**:
```csharp
using BenchmarkDotNet.Attributes;
using BenchmarkDotNet.Running;

[MemoryDiagnoser]
[SimpleJob(iterationCount: 10, warmupCount: 5)]
public class ReportGenerationBenchmark
{
    private IReportService _reportService;
    private DateTime _startDate;
    private DateTime _endDate;

    [GlobalSetup]
    public void Setup()
    {
        // Initialize service with test database
        _reportService = new ReportService(/* dependencies */);
        _startDate = new DateTime(2025, 1, 1);
        _endDate = new DateTime(2025, 1, 31);
    }

    [Benchmark]
    public async Task GenerateReport_10000Records()
    {
        await _reportService.GenerateReportAsync(_startDate, _endDate);
    }

    [Benchmark]
    public async Task ProcessSingleRecord()
    {
        var premium = new PremiumRecord { /* test data */ };
        await _reportService.ProcessPremiumRecordAsync(premium);
    }
}

// Run benchmarks
class Program
{
    static void Main(string[] args)
    {
        var summary = BenchmarkRunner.Run<ReportGenerationBenchmark>();

        // Compare against COBOL baseline
        var cobolBaseline = TimeSpan.FromMinutes(4.5);  // Example: COBOL takes 4.5 min
        var dotnetActual = summary.Reports.First().ResultStatistics.Mean;
        var tolerance = 1.2;  // 120% per success criteria

        if (dotnetActual <= cobolBaseline.TotalSeconds * tolerance)
        {
            Console.WriteLine($"✓ Performance OK: {dotnetActual}s vs {cobolBaseline.TotalSeconds}s baseline (limit: {cobolBaseline.TotalSeconds * tolerance}s)");
        }
        else
        {
            Console.WriteLine($"✗ Performance FAILED: {dotnetActual}s exceeds {tolerance}x baseline");
        }
    }
}
```

**Profiling Setup** (Development):
```csharp
// Program.cs
builder.Services.AddSerilog(config =>
{
    config
        .Enrich.FromLogContext()
        .Enrich.WithProperty("Application", "CaixaSeguradora.Api")
        .WriteTo.Console()
        .WriteTo.Seq("http://localhost:5341")  // Seq for log aggregation
        .WriteTo.File("logs/app-.txt", rollingInterval: RollingInterval.Day);
});

// Middleware for request timing
public class PerformanceLoggingMiddleware
{
    private readonly RequestDelegate _next;
    private readonly ILogger<PerformanceLoggingMiddleware> _logger;

    public async Task InvokeAsync(HttpContext context)
    {
        var stopwatch = Stopwatch.StartNew();

        await _next(context);

        stopwatch.Stop();

        if (stopwatch.ElapsedMilliseconds > 500)  // Log slow requests
        {
            _logger.LogWarning(
                "Slow request: {Method} {Path} took {ElapsedMs}ms",
                context.Request.Method,
                context.Request.Path,
                stopwatch.ElapsedMilliseconds);
        }

        // Metrics for dashboard
        context.Response.Headers.Add("X-Response-Time-ms", stopwatch.ElapsedMilliseconds.ToString());
    }
}
```

**Comparison Test Framework**:
```csharp
public class PerformanceComparisonTests
{
    [Fact]
    public async Task ReportGeneration_MeetsPerformanceGoal()
    {
        // Arrange
        var startDate = new DateTime(2025, 1, 1);
        var endDate = new DateTime(2025, 1, 31);
        int expectedRecordCount = 10000;
        TimeSpan maxExecutionTime = TimeSpan.FromMinutes(5);  // Success criteria

        // Act
        var stopwatch = Stopwatch.StartNew();
        var result = await _reportService.GenerateReportAsync(startDate, endDate);
        stopwatch.Stop();

        // Assert
        Assert.Equal(expectedRecordCount, result.RecordsProcessed);
        Assert.True(stopwatch.Elapsed < maxExecutionTime,
            $"Report generation took {stopwatch.Elapsed.TotalMinutes:F2} minutes, exceeds {maxExecutionTime.TotalMinutes} minute limit");
    }

    [Fact]
    public async Task DashboardLoad_MeetsResponseTimeGoal()
    {
        // Arrange
        TimeSpan maxResponseTime = TimeSpan.FromSeconds(2);  // Success criteria

        // Act
        var stopwatch = Stopwatch.StartNew();
        var metrics = await _dashboardService.GetMetricsAsync();
        stopwatch.Stop();

        // Assert
        Assert.NotNull(metrics);
        Assert.True(stopwatch.Elapsed < maxResponseTime,
            $"Dashboard load took {stopwatch.Elapsed.TotalSeconds:F2}s, exceeds {maxResponseTime.TotalSeconds}s limit");
    }
}
```

**Metrics Collection**:
```csharp
public class PerformanceMetrics
{
    public string OperationName { get; set; }
    public TimeSpan ExecutionTime { get; set; }
    public long MemoryUsedBytes { get; set; }
    public int RecordsProcessed { get; set; }
    public DateTime Timestamp { get; set; }

    // Comparison with COBOL baseline
    public TimeSpan? CobolBaseline { get; set; }
    public double PerformanceRatio => CobolBaseline.HasValue
        ? ExecutionTime.TotalSeconds / CobolBaseline.Value.TotalSeconds
        : 0;

    public bool MeetsSuccessCriteria => PerformanceRatio <= 1.2;  // Within 120%
}

// Metrics storage
public class MetricsRepository
{
    public async Task SaveMetricsAsync(PerformanceMetrics metrics)
    {
        await _context.PerformanceMetrics.AddAsync(metrics);
        await _context.SaveChangesAsync();
    }

    public async Task<PerformanceReport> GetPerformanceReportAsync(string operationName)
    {
        var recent = await _context.PerformanceMetrics
            .Where(m => m.OperationName == operationName)
            .OrderByDescending(m => m.Timestamp)
            .Take(100)
            .ToListAsync();

        return new PerformanceReport
        {
            OperationName = operationName,
            AverageExecutionTime = TimeSpan.FromSeconds(recent.Average(m => m.ExecutionTime.TotalSeconds)),
            MinExecutionTime = recent.Min(m => m.ExecutionTime),
            MaxExecutionTime = recent.Max(m => m.ExecutionTime),
            AveragePerformanceRatio = recent.Where(m => m.CobolBaseline.HasValue).Average(m => m.PerformanceRatio),
            MeetsSuccessCriteria = recent.All(m => m.MeetsSuccessCriteria)
        };
    }
}
```

**Alternatives Considered**:
1. **Manual timing with Stopwatch** - Rejected: No statistical analysis, no warmup handling, harder to compare runs
2. **Application Insights only** - Rejected: Overkill for development, requires Azure subscription
3. **Custom benchmark framework** - Rejected: Reinventing wheel, BenchmarkDotNet battle-tested

**Implementation Notes**:

- **COBOL Baseline Acquisition**: If possible, run COBOL system with instrumentation to get actual timings; otherwise estimate from user reports or job logs
- **Environment Consistency**: Run benchmarks on equivalent hardware (COBOL on mainframe vs .NET on x86 server isn't apples-to-apples, but document differences)
- **Continuous Monitoring**: Integrate benchmark runs into CI/CD pipeline to catch regressions
- **Visualization**: Build dashboard showing performance trends over time (part of User Story 1)

**References**:
- BenchmarkDotNet: https://benchmarkdotnet.org/
- Serilog: https://serilog.net/
- Seq log server: https://datalust.co/seq
- Application Insights: https://learn.microsoft.com/en-us/azure/azure-monitor/app/app-insights-overview

---

## Summary

All 8 research areas have been thoroughly investigated with concrete technical decisions documented. Key takeaways:

**Critical Decisions for Regulatory Compliance**:
1. **R1**: C# `decimal` type mandatory for all financial calculations
2. **R2**: Custom fixed-width formatter with byte-level validation
3. **R3**: Streaming with `IAsyncEnumerable` for memory efficiency
4. **R5**: Explicit transaction boundaries matching COBOL COMMIT points

**Pragmatic Development Decisions**:
1. **R4**: Mock external modules initially, design for future integration
2. **R6**: TailwindCSS + shadcn/ui for rapid, branded UI development
3. **R7**: SQLite for development with repository abstraction for DB2 migration
4. **R8**: BenchmarkDotNet for continuous performance validation

**Risk Mitigation**:
- All decisions include fallback alternatives
- Performance testing integrated from start
- Regulatory compliance validated through byte comparison
- Abstraction layers enable future production migration (SQLite → DB2)

**Next Steps**: Proceed to Phase 1 (Data Model Design, API Contracts, Quickstart Guide)

---

**Research Complete**: October 22, 2025
**Approved For**: Phase 1 Design

**IMPLEMENTATION CONTEXT (from design artifacts):**


### PLAN.MD (Tech Stack & Architecture)

# Implementation Plan: COBOL RG1866B to .NET 9 React Migration

**Branch**: `001-vamos-migrar-sistema` | **Date**: October 22, 2025 | **Spec**: [spec.md](spec.md)
**Input**: Feature specification from `/specs/001-vamos-migrar-sistema/spec.md`

## Summary

Migrate legacy COBOL batch program RG1866B (SUSEP Circular 360 Premium Reporting System) to modern full-stack application with .NET 9 backend and React frontend. The system generates regulated insurance premium reports by processing policy data, premiums, endorsements, and cossurance information from 26+ database tables. Key technical challenge is ensuring byte-for-byte output compatibility with legacy system while modernizing architecture. Implementation uses SQLite for development with mocked DB2 data structure, Clean Architecture for backend, and Caixa Seguradora-branded responsive UI.

## Technical Context

**Language/Version**:
- Backend: C# with .NET 9 SDK
- Frontend: TypeScript with React 18+
- Database: SQLite 3.x (development), DB2 compatibility layer

**Primary Dependencies**:
- Backend: ASP.NET Core Web API 9.0, Entity Framework Core 9.0, Serilog (logging), AutoMapper (DTO mapping), Swashbuckle (Swagger/OpenAPI), xUnit (testing)
- Frontend: React 18+, React Router 6+ (navigation), Axios (HTTP client), Recharts or Chart.js (visualizations), TailwindCSS (styling), Vite (build tool)
- Shared: SQLite driver (Microsoft.Data.Sqlite), Newtonsoft.Json or System.Text.Json

**Storage**: SQLite database with schema mirroring 26+ DB2 views/tables (V0PREMIOS, V0APOLICE, V0ENDOSSO, V0PRODUTO, V0CLIENTE, V0TOMADOR, V0ENDERECOS, V0AGENCIAS, V0PRODUTOR, V0COBERAPOL, V0FATURAS, V0HISTOPARC, V0APOLCOSCED, GE399, etc.)

**Testing**:
- Backend: xUnit (unit tests), FluentAssertions (assertions), Moq (mocking), Microsoft.AspNetCore.Mvc.Testing (integration tests)
- Frontend: Vitest or Jest (unit tests), React Testing Library (component tests), Playwright or Cypress (E2E tests)
- Migration validation: Custom comparison framework for COBOL vs .NET output validation

**Target Platform**:
- Backend: Linux/Windows/macOS server (containerized via Docker)
- Frontend: Modern browsers (Chrome 120+, Firefox 120+, Edge 120+, Safari 17+)
- Deployment: Docker Compose for development, Kubernetes-ready for production

**Project Type**: Web application (separate backend API + frontend SPA)

**Performance Goals**:
- Report generation: Process 10,000+ premium records in under 5 minutes
- API response: <2 seconds for dashboard load, <500ms for standard queries
- Concurrent users: Support 10+ simultaneous report generation without 20%+ degradation
- Database queries: Cursor-based processing for large datasets to prevent memory overflow

**Constraints**:
- **Byte-level compatibility**: Output files (PREMIT.TXT, PREMCED.TXT) must match COBOL output exactly for regulatory compliance
- **Decimal precision**: Financial calculations must use C# decimal type (not float/double) to match COBOL arithmetic exactly
- **Fixed-width formatting**: Custom formatters required to replicate COBOL space/zero padding
- **Transaction boundaries**: Must replicate COBOL COMMIT/ROLLBACK semantics precisely
- **Language**: All user-facing content in Portuguese (Brazilian)
- **Branding**: Must follow Caixa Seguradora corporate style guide
- **Legacy coexistence**: Must run in parallel with COBOL system during validation period

**Scale/Scope**:
- **Code migration**: ~5,000 lines COBOL → estimated 15,000+ lines C#/TypeScript
- **Data structures**: 687 COBOL data items → C# models
- **Business logic**: 63 COBOL sections, 65 paragraphs → C# services/repositories
- **Database**: 26+ views/tables, 4 cursor operations
- **External modules**: 3 COBOL modules (RE0001S, GE0009S, GE0010S) → C# services or APIs
- **User stories**: 5 prioritized stories (dashboard, report generation, querying, batch jobs, data management)
- **Functional requirements**: 30 requirements covering report generation, database integration, business logic, UI, data management, testing

## Constitution Check

*GATE: Must pass before Phase 0 research. Re-check after Phase 1 design.*

**Note**: Constitution defined at `.specify/memory/constitution.md`; principles below summarize the ratified mandates and must remain aligned with that document.

### Proposed Principles for This Migration

Given the nature of this project (legacy migration with regulatory compliance requirements), proposing these architectural principles:

**I. Functional Parity First (NON-NEGOTIABLE)**
- Every COBOL section must have documented C# equivalent with traceability
- All business calculations must produce identical results (zero deviation)
- Output files must match byte-for-byte for regulatory compliance
- No new features added during migration phase (scope protection)

**II. Clean Architecture Mandatory**
- Domain models independent of infrastructure
- Repository pattern for database access (enables future DB2 → production DB migration)
- Service layer encapsulates business logic
- API controllers handle HTTP concerns only
- Dependency injection for testability

**III. Test-Driven Migration (NON-NEGOTIABLE)**
- Side-by-side comparison tests required for all business logic
- Unit tests for all calculation services (90%+ coverage target)
- Integration tests for database operations
- E2E tests for complete report generation workflow
- Validation: 100 production samples must show 100% output equivalence

**IV. Data Type Precision**
- C# decimal type mandatory for all financial calculations
- Custom type converters for COBOL PIC → C# type mappings
- Rounding mode configuration matching COBOL arithmetic
- String padding/formatting replicates COBOL fixed-width behavior

**V. Observability & Traceability**
- Comprehensive logging (similar to COBOL DISPLAY statements)
- Audit trail for all report generation operations
- Performance metrics for comparison with COBOL baseline
- Structured logging (JSON) for troubleshooting

**Constitution Status**: ✅ PASS (principles codified in `.specify/memory/constitution.md`, amendments require governance workflow)

## Project Structure

### Documentation (this feature)

```text
specs/001-vamos-migrar-sistema/
├── spec.md              # Feature specification (created)
├── plan.md              # This file (/speckit.plan command output)
├── research.md          # Phase 0 output (next step)
├── data-model.md        # Phase 1 output
├── quickstart.md        # Phase 1 output
├── contracts/           # Phase 1 output (API contracts)
│   ├── openapi.yaml    # OpenAPI 3.0 specification
│   └── schemas/        # JSON schemas for data models
├── checklists/          # Quality validation checklists
│   └── requirements.md  # Specification quality checklist (created)
└── tasks.md             # Phase 2 output (/speckit.tasks command - created)
```

### Source Code (repository root)

```text
# Web application structure (backend + frontend)

backend/
├── src/
│   ├── CaixaSeguradora.Api/              # ASP.NET Core Web API
│   │   ├── Controllers/                   # API controllers
│   │   │   ├── ReportsController.cs      # Report generation endpoints
│   │   │   ├── DashboardController.cs    # Dashboard metrics
│   │   │   ├── QueryController.cs        # Data query endpoints
│   │   │   └── DataManagementController.cs # Mock data management
│   │   ├── Program.cs                     # Application entry point
│   │   ├── appsettings.json              # Configuration
│   │   └── Middleware/                    # Custom middleware
│   │
│   ├── CaixaSeguradora.Core/             # Domain layer (Clean Architecture)
│   │   ├── Entities/                      # Domain entities
│   │   │   ├── Premium.cs                # Premium record
│   │   │   ├── Policy.cs                 # Insurance policy
│   │   │   ├── Endorsement.cs            # Policy endorsement
│   │   │   ├── Product.cs                # Insurance product
│   │   │   ├── Client.cs                 # Policyholder
│   │   │   ├── Coverage.cs               # Coverage details
│   │   │   ├── Invoice.cs                # Billing invoice
│   │   │   └── CossuredPolicy.cs         # Cossurance arrangement
│   │   ├── Interfaces/                    # Repository & service contracts
│   │   │   ├── IReportService.cs
│   │   │   ├── IPremiumRepository.cs
│   │   │   ├── IPolicyRepository.cs
│   │   │   └── ICalculationService.cs
│   │   ├── Services/                      # Domain services
│   │   │   ├── PremiumCalculationService.cs   # Business calculations
│   │   │   ├── CossuranceService.cs           # Cossurance logic
│   │   │   └── ValidationService.cs           # Business rules validation
│   │   ├── DTOs/                          # Data transfer objects
│   │   └── Exceptions/                    # Domain exceptions
│   │
│   ├── CaixaSeguradora.Infrastructure/    # Infrastructure layer
│   │   ├── Data/                          # Database context & repositories
│   │   │   ├── ApplicationDbContext.cs   # EF Core DbContext
│   │   │   ├── Repositories/
│   │   │   │   ├── PremiumRepository.cs
│   │   │   │   ├── PolicyRepository.cs
│   │   │   │   └── BaseRepository.cs
│   │   │   └── Configurations/            # EF entity configurations
│   │   ├── Services/                      # External service implementations
│   │   │   ├── FileGenerationService.cs  # PREMIT/PREMCED file generation
│   │   │   ├── FixedWidthFormatter.cs    # COBOL-compatible formatting
│   │   │   └── ExternalModuleService.cs  # Mock for GE0009S, GE0010S, RE0001S
│   │   ├── Migrations/                    # EF Core migrations
│   │   └── MockData/                      # SQLite data seeding
│   │
│   ├── CaixaSeguradora.Tests/             # Test projects
│   │   ├── UnitTests/                     # Unit tests
│   │   │   ├── Services/
│   │   │   └── Calculations/
│   │   ├── IntegrationTests/              # Integration tests
│   │   │   ├── Api/
│   │   │   └── Database/
│   │   └── ComparisonTests/               # COBOL vs .NET validation
│   │       ├── OutputComparison.cs
│   │       └── TestDataSets/
│   │
│   └── CaixaSeguradora.sln                # Solution file
│
frontend/
├── src/
│   ├── components/                        # Reusable React components
│   │   ├── common/                        # Generic components
│   │   │   ├── Header.tsx                # Caixa Seguradora header
│   │   │   ├── Footer.tsx
│   │   │   ├── LoadingSpinner.tsx
│   │   │   └── ErrorMessage.tsx
│   │   ├── dashboard/                     # Dashboard components
│   │   │   ├── MigrationMetrics.tsx
│   │   │   ├── ComplexityChart.tsx
│   │   │   ├── FunctionPointsCard.tsx
│   │   │   └── DatabaseDependencies.tsx
│   │   ├── reports/                       # Report generation components
│   │   │   ├── ReportForm.tsx
│   │   │   ├── ProgressIndicator.tsx
│   │   │   └── ResultsDownload.tsx
│   │   └── query/                         # Query builder components
│   │       ├── QueryBuilder.tsx
│   │       ├── ResultsTable.tsx
│   │       └── ChartVisualization.tsx
│   │
│   ├── pages/                             # Page components (routes)
│   │   ├── DashboardPage.tsx             # Landing page (P1)
│   │   ├── ReportGenerationPage.tsx      # Report generation (P2)
│   │   ├── QueryPage.tsx                 # Data querying (P3)
│   │   ├── BatchJobsPage.tsx             # Job monitoring (P4)
│   │   └── DataManagementPage.tsx        # Mock data management (P4)
│   │
│   ├── services/                          # API integration layer
│   │   ├── apiClient.ts                  # Axios configuration
│   │   ├── reportService.ts              # Report generation API calls
│   │   ├── dashboardService.ts           # Dashboard data API calls
│   │   └── queryService.ts               # Query execution API calls
│   │
│   ├── models/                            # TypeScript interfaces
│   │   ├── Premium.ts
│   │   ├── Policy.ts
│   │   ├── Report.ts
│   │   └── DashboardMetrics.ts
│   │
│   ├── hooks/                             # Custom React hooks
│   │   ├── useReportGeneration.ts
│   │   ├── useDashboardData.ts
│   │   └── useQuery.ts
│   │
│   ├── utils/                             # Utility functions
│   │   ├── formatters.ts                 # Data formatting
│   │   ├── validators.ts                 # Input validation
│   │   └── chartHelpers.ts               # Chart configuration
│   │
│   ├── styles/                            # Global styles
│   │   ├── globals.css                   # Tailwind imports + globals
│   │   ├── caixa-theme.css              # Caixa Seguradora branding
│   │   └── variables.css                 # CSS custom properties
│   │
│   ├── App.tsx                            # Root component
│   ├── main.tsx                           # Entry point
│   └── router.tsx                         # React Router configuration
│
├── tests/                                 # Frontend tests
│   ├── unit/                              # Component unit tests
│   ├── integration/                       # Integration tests
│   └── e2e/                               # End-to-end tests (Playwright)
│
├── public/                                # Static assets
│   ├── favicon.ico
│   └── assets/
│       ├── logo-caixa.png
│       └── images/
│
├── package.json                           # NPM dependencies
├── vite.config.ts                         # Vite configuration
├── tsconfig.json                          # TypeScript configuration
└── tailwind.config.js                     # Tailwind CSS configuration

docker/
├── Dockerfile.backend                     # Backend container
├── Dockerfile.frontend                    # Frontend container
└── docker-compose.yml                     # Development environment

docs/
├── parser/                                # COBOL analysis (existing)
│   ├── FINAL-ANALYSIS-REPORT.md
│   ├── INDEX.md
│   └── detailed-structure.txt
├── migration/                             # Migration documentation
│   ├── data-dictionary.md                # COBOL → C# type mappings
│   ├── business-rules.md                 # Extracted business logic
│   ├── comparison-results.md             # Validation test results
│   └── deployment-guide.md               # Deployment instructions
└── api/                                   # API documentation
    └── README.md                          # API usage guide

database/
├── schema/                                # SQLite schema
│   ├── create-tables.sql                 # DDL for all 26+ tables
│   └── indexes.sql                       # Performance indexes
├── mock-data/                             # Test data
│   ├── load-data.sql                     # Data loading scripts
│   └── csv/                              # CSV files for bulk import
│       ├── v0premios.csv
│       ├── v0apolice.csv
│       └── [other tables].csv
└── migrations/                            # Schema version control
```

**Structure Decision**: Web application with separate backend and frontend projects. Backend uses Clean Architecture (Api → Core → Infrastructure) for maintainability and testability. Frontend uses component-based architecture with React Router for navigation. Docker Compose orchestrates both services for development. This structure supports the migration strategy: clear separation allows parallel development of backend logic migration and frontend UI creation, facilitates independent testing of business logic vs. UI, and enables future scaling (e.g., deploying backend to production DB2 while keeping frontend unchanged).

## Complexity Tracking

> **Fill ONLY if Constitution Check has violations that must be justified**

**Note**: No constitution violations - this is a greenfield migration project establishing its own architectural patterns. Complexity is inherent to the legacy system being migrated:

| Complexity Source | Why Needed | Simpler Alternative Rejected Because |
|-------------------|------------|-------------------------------------|
| Clean Architecture (3 layers) | Separation of concerns for 687 data items, 63 sections of business logic | Direct coupling would make testing impossible; regulatory compliance requires isolated business logic for validation |
| Repository Pattern | Abstract database access for future DB2 → production DB migration | Direct EF Core usage would hardcode SQLite specifics; need flexibility for production database transition |
| Custom Formatters | COBOL fixed-width format with space/zero padding | Standard .NET formatters don't replicate COBOL behavior; regulatory compliance requires byte-for-byte matching |
| SQLite Mock + Production DB Layer | Development environment without mainframe access | Mocking all 26+ tables inline would be unmaintainable; need realistic database structure for accurate testing |
| Dual Frontend/Backend | React SPA + REST API | Monolithic Razor Pages insufficient for modern UX; dashboard with charts requires rich client-side interaction |

---

## Phase 0: Research & Technical Decisions

**Status**: In Progress

### Research Areas

Based on Technical Context analysis, the following areas require research and decision documentation:

#### R1: COBOL to C# Type Mapping Strategy
**Question**: What is the precise mapping for all COBOL PIC types to C# types ensuring arithmetic precision?
**Priority**: Critical (affects all 687 data items)
**Focus Areas**:
- PIC 9(n)V9(m) → C# decimal with exact scale/precision
- PIC X(n) → C# string with fixed-length handling
- PIC S9(n) COMP-3 → C# integer types
- Date formats (YYYYMMDD, DDMMYYYY) → C# DateTime
- Rounding mode configuration for Math.Round

#### R2: Fixed-Width File Generation
**Question**: How to replicate COBOL WRITE with fixed-width records, space padding, zero padding?
**Priority**: Critical (regulatory compliance)
**Focus Areas**:
- Custom formatter implementation patterns
- String padding: PadRight for spaces, PadLeft with '0' for numbers
- Binary comparison techniques for validation
- Performance optimization for large files (streaming writes)

#### R3: Cursor-Based Processing Pattern
**Question**: How to implement COBOL cursor behavior (DECLARE, OPEN, FETCH, CLOSE) in EF Core?
**Priority**: High (performance for large datasets)
**Focus Areas**:
- EF Core AsNoTracking with streaming
- IAsyncEnumerable<T> for async streaming
- Pagination strategies
- Memory management for millions of records

#### R4: External Module Integration
**Question**: How to integrate or mock COBOL modules RE0001S, GE0009S, GE0010S?
**Priority**: Medium (required for complete business logic)
**Focus Areas**:
- Parameter marshalling from COBOL LINKAGE SECTION
- Service interface design for mockability
- Potential reverse-engineering approaches if source unavailable
- Testing strategies for external dependencies

#### R5: Transaction Boundary Replication
**Question**: How to replicate COBOL COMMIT/ROLLBACK semantics in EF Core?
**Priority**: High (data integrity)
**Focus Areas**:
- EF Core transaction scopes
- SaveChanges behavior and transaction boundaries
- Error handling and rollback patterns
- Distributed transaction considerations (if multiple databases)

#### R6: Caixa Seguradora Branding Implementation
**Question**: How to extract and implement corporate branding from website?
**Priority**: Medium (user experience)
**Focus Areas**:
- Color palette extraction (primary, secondary, accent colors)
- Typography stack (fonts, sizes, weights)
- Component library approach (custom vs. Tailwind + shadcn/ui)
- Logo and asset licensing/usage

#### R7: SQLite to DB2 Compatibility Layer
**Question**: What are the limitations and workarounds for SQLite mimicking DB2?
**Priority**: High (data access foundation)
**Focus Areas**:
- SQL dialect differences (date functions, string functions)
- Stored procedure alternatives (in-code logic)
- Cursor behavior differences
- Concurrency control (locking vs. optimistic concurrency)
- Type system differences (DECIMAL precision)

#### R8: Performance Baseline Establishment
**Question**: How to measure and compare COBOL vs .NET performance?
**Priority**: Medium (success criteria validation)
**Focus Areas**:
- Profiling tools for C# (.NET diagnostic tools)
- Benchmark framework selection
- Metrics collection (execution time, memory usage, I/O operations)
- Reporting and comparison visualization

### Research Deliverable

All research findings will be documented in `research.md` with the following structure for each area:

```markdown
### [R#]: [Research Area Name]

**Decision**: [What was chosen]

**Rationale**: [Why this approach was selected]

**Alternatives Considered**:
1. [Alternative 1] - Rejected because [reason]
2. [Alternative 2] - Rejected because [reason]

**Implementation Notes**: [Key considerations, gotchas, best practices]

**References**: [Links to documentation, blog posts, Stack Overflow, etc.]
```

---

## Phase 1: Design & Contracts (After Research Complete)

**Status**: ✅ Complete (October 22, 2025)

### Phase 1.1: Data Model Design

**Output**: `data-model.md` with comprehensive entity definitions

**Scope**: Map all key entities from feature spec to C# models with:
- Entity name and purpose
- Properties with C# types (informed by R1 research)
- Relationships (foreign keys, navigation properties)
- Validation rules (from functional requirements)
- EF Core configuration (fluent API, indexes, constraints)

**Key Entities to Define** (from spec):
1. Premium Record (V0PREMIOS)
2. Policy (V0APOLICE)
3. Endorsement (V0ENDOSSO)
4. Product (V0PRODUTO, V0PRODUTOSVG)
5. Client (V0CLIENTE, V0TOMADOR)
6. Address (V0ENDERECOS)
7. Agency (V0AGENCIAS)
8. Producer (V0PRODUTOR)
9. Coverage (V0COBERAPOL)
10. Invoice (V0FATURAS)
11. Installment (V0HISTOPARC)
12. Cossured Policy (V0APOLCOSCED)
13. Cossurance Calculation (GE399)
14. System Configuration (V0SISTEMA)
15. Report Definition (V0RELATORIOS)

### Phase 1.2: API Contracts

**Output**: `/contracts/openapi.yaml` and `/contracts/schemas/`

**Scope**: Generate OpenAPI 3.0 specification for all API endpoints based on functional requirements:

**Endpoints to Define**:

```yaml
# Dashboard APIs (User Story 1 - P1)
GET /api/dashboard/metrics           # System overview metrics
GET /api/dashboard/complexity        # Processing complexity stats
GET /api/dashboard/function-points   # Function points estimation
GET /api/dashboard/database-deps     # Database dependencies

# Report Generation APIs (User Story 2 - P2)
POST /api/reports/generate           # Generate PREMIT/PREMCED reports
  Request: { systemId, startDate, endDate, reportType, mode }
  Response: { jobId, status, message }
GET /api/reports/{jobId}/status      # Check generation status
GET /api/reports/{jobId}/download    # Download generated files
GET /api/reports/history             # List past report generations

# Query APIs (User Story 3 - P3)
POST /api/query/execute              # Execute ad-hoc query
  Request: { filters, columns, aggregations, sorting }
  Response: { data, summary, pagination }
GET /api/query/saved                 # List saved queries
POST /api/query/export               # Export query results (CSV/Excel/PDF)

# Batch Job APIs (User Story 4 - P4)
POST /api/jobs/schedule              # Schedule batch report job
GET /api/jobs                        # List scheduled jobs
GET /api/jobs/{jobId}                # Get job details
PUT /api/jobs/{jobId}                # Update job configuration
DELETE /api/jobs/{jobId}             # Delete scheduled job
GET /api/jobs/{jobId}/history        # Job execution history

# Data Management APIs (User Story 5 - P4)
GET /api/data/schema                 # Get SQLite schema info
POST /api/data/load                  # Load mock data from CSV/JSON
POST /api/data/validate              # Validate data integrity
DELETE /api/data/reset               # Clear and reset database
GET /api/data/comparison             # Get COBOL vs .NET comparison results
```

**Schema Definitions**: JSON schemas for all request/response DTOs will be generated in `/contracts/schemas/` directory.

### Phase 1.3: Quickstart Guide

**Output**: `quickstart.md` with developer onboarding instructions

**Contents**:
- Prerequisites (SDKs, tools, versions)
- Repository clone and setup
- Database initialization (SQLite schema creation, mock data loading)
- Backend build and run instructions
- Frontend build and run instructions
- Docker Compose quick start
- Running tests
- API documentation access (Swagger UI)
- Troubleshooting common setup issues

### Phase 1.4: Agent Context Update

After completing design artifacts, will run:
```bash
.specify/scripts/bash/update-agent-context.sh claude
```

This will update `.claude/context.md` with:
- Technology stack from this plan
- Project structure references
- Key architectural decisions from research.md
- Links to data-model.md and contracts/

---

## Phase 2: Task Breakdown (Separate Command)

**Status**: Not started (requires `/speckit.tasks` command)

This phase is executed by a separate command (`/speckit.tasks`) and will generate `tasks.md` with:
- Dependency-ordered implementation tasks
- Assignments to user stories (P1-P4)
- Effort estimates
- Acceptance criteria references
- Technology-specific implementation details

---

## Notes

### Critical Success Factors

1. **Research Quality**: Phase 0 research must thoroughly address all 8 research areas. Incomplete research on type mapping or formatting could cause regulatory non-compliance.

2. **Data Model Accuracy**: Entity definitions in Phase 1.1 must precisely map all 687 COBOL data items. Missing fields or incorrect types will cause calculation discrepancies.

3. **API Contract Completeness**: All 30 functional requirements must map to API endpoints. Missing endpoints will block frontend implementation.

4. **Test Strategy**: Comparison tests (COBOL vs .NET) are non-negotiable. Without these, no confidence in migration accuracy.

### Risk Mitigation

**Risk**: COBOL business logic misinterpretation
**Mitigation**: Document every COBOL section with pseudocode in business-rules.md; validate with SMEs

**Risk**: Decimal precision errors in calculations
**Mitigation**: R1 research must include unit tests comparing decimal operations; use decimal type exclusively

**Risk**: Performance regression vs COBOL
**Mitigation**: R8 establishes baseline; continuous benchmarking during implementation

**Risk**: External module unavailability (RE0001S, GE0009S, GE0010S)
**Mitigation**: R4 research includes mocking strategy; document assumptions for each module

### Completion Summary

**Phase 0: Research & Technical Decisions** - ✅ Complete
- `research.md` created with comprehensive research for all 8 areas (R1-R8)
- Type mapping strategy defined (COBOL PIC → C# types)
- Fixed-width file generation approach established
- Cursor processing mapped to IAsyncEnumerable<T>
- External module integration strategy documented
- Transaction boundary replication designed
- Caixa Seguradora branding guidelines extracted
- Database compatibility layer architected
- Performance baseline methodology established

**Phase 1: Design & Contracts** - ✅ Complete
- **Phase 1.1**: `data-model.md` created with 15 comprehensive entity definitions
  - All COBOL views/tables mapped to C# entities
  - Complete EF Core configurations with fluent API
  - Validation rules documented for each entity
  - Navigation properties and relationships defined
  - Traceability matrix linking entities to COBOL sections
- **Phase 1.2**: `contracts/openapi.yaml` created with complete API specification
  - 28 RESTful endpoints across 9 categories
  - Request/response schemas for all operations
  - OpenAPI 3.0.3 compliant specification
  - Comprehensive API documentation in `contracts/schemas/README.md`
  - Examples and usage patterns documented
- **Phase 1.3**: `quickstart.md` created with developer onboarding guide
  - Prerequisites and environment setup instructions
  - Step-by-step getting started guide
  - Development workflow and best practices
  - Testing instructions for backend and frontend
  - Database management with EF Core migrations
  - Troubleshooting common issues
  - Quick reference commands

### Next Steps

1. ✅ Complete Technical Context
2. ✅ Pass Constitution Check (greenfield project)
3. ✅ **Complete**: Generate `research.md` (Phase 0)
4. ✅ **Complete**: Generate `data-model.md` (Phase 1.1)
5. ✅ **Complete**: Generate API contracts (Phase 1.2)
6. ✅ **Complete**: Generate `quickstart.md` (Phase 1.3)
7. 🔄 **In Progress**: Update agent context (Phase 1.4)
8. ⏳ **Pending**: Execute `/speckit.tasks` for task breakdown (Phase 2)

---

**Plan Version**: 1.1 | **Created**: October 22, 2025 | **Updated**: October 22, 2025 | **Status**: Phase 1 Complete, Ready for Phase 2



### SPEC.MD (User Stories & Acceptance)

# Feature Specification: COBOL RG1866B to .NET 9 React Migration

**Feature Branch**: `001-vamos-migrar-sistema`
**Created**: October 22, 2025
**Status**: Draft
**Legacy System**: COBOL RG1866B - SUSEP Circular 360 Premium Reporting System

## Executive Summary

Migrate the legacy COBOL batch processing program RG1866B (SUSEP Circular 360 Premium Reports) to a modern full-stack application using .NET 9 backend with React frontend. The system generates regulated insurance premium reports for Brazilian insurance regulator (SUSEP), processing policy data, premiums, endorsements, and cossurance information from 26+ database tables.

### Current State
- **Legacy System**: COBOL batch program RG1866B (~5,000 lines)
- **Database**: IBM DB2 with 26+ views/tables
- **Processing**: Batch processing with 4 cursors
- **Output**: 2 text files (PREMIT.TXT, PREMCED.TXT)
- **External Dependencies**: 3 COBOL modules (RE0001S, GE0009S, GE0010S)
- **Data Structures**: 687 data items, 63 sections, 65 paragraphs

### Target State
- **Backend**: .NET 9 Web API with C#
- **Frontend**: React application with dashboard
- **Database**: SQLite local database with mocked DB2 data structure
- **Architecture**: Clean Architecture with RESTful APIs
- **UI/UX**: Caixa Seguradora branding and styling
- **Deployment**: Containerized solution

## User Scenarios & Testing

### User Story 1 - View Migration Dashboard (Priority: P1)

Users need to understand the scope and complexity of the migration project, view current system metrics, and track migration progress through an interactive dashboard.

**Why this priority**: Provides immediate value by visualizing the migration scope, establishing baseline metrics, and creating transparency for stakeholders. Can be developed independently without backend logic migration.

**Independent Test**: Can be fully tested by launching the React application, navigating to the dashboard, and verifying all metrics display correctly with mock data. Delivers value by documenting system complexity and providing project visibility.

**Acceptance Scenarios**:

1. **Given** a user accesses the application, **When** they land on the homepage, **Then** they see a comprehensive dashboard showing system overview (program name, lines of code, creation date), data structure metrics (687 data items, table breakdown), processing complexity (63 sections, 65 paragraphs, 4 cursors), database dependencies (26+ tables with access patterns), and external module integrations (3 modules)

2. **Given** the dashboard is displayed, **When** user views the Function Points section, **Then** they see estimated function points for migration, breakdown by component (backend, frontend, database, integration), complexity ratings (High/Medium/Low), and effort estimates

3. **Given** user is on the dashboard, **When** they interact with visualizations, **Then** they can view interactive charts showing data distribution, drill down into specific sections/paragraphs, see database table relationships, and navigate to detailed analysis reports

---

### User Story 2 - Generate Premium Reports (Interactive) (Priority: P2)

Users need to generate SUSEP Circular 360 premium reports on-demand through a web interface, replacing the batch COBOL process with an interactive workflow that allows parameter selection and real-time execution.

**Why this priority**: Core business functionality that delivers immediate operational value by replacing the batch process with interactive capabilities. Represents the primary use case of the legacy system.

**Independent Test**: Can be tested by configuring report parameters (date range, system ID, report type), executing the generation process, and verifying output files match legacy COBOL output format byte-for-byte.

**Acceptance Scenarios**:

1. **Given** user is logged into the system, **When** they navigate to Report Generation, **Then** they see a form with date range selectors (start date, end date), system selection dropdown, report type selection (PREMIT, PREMCED, or Both), and processing mode (weekly cumulative, monthly)

2. **Given** user has filled the report parameters, **When** they click "Generate Report", **Then** system validates all required parameters, displays processing progress indicator, executes premium calculation logic identical to COBOL, accesses required database tables (V0PREMIOS, V0APOLICE, etc.), and generates output files in correct format

3. **Given** report generation completes successfully, **When** user views results, **Then** they can download PREMIT.TXT file, download PREMCED.TXT file, view generation summary (records processed, execution time), and see any warnings or validation messages

4. **Given** report generation encounters errors, **When** processing fails, **Then** system displays clear error message in Portuguese, logs detailed error information for support, maintains data integrity (no partial writes), and allows user to retry with corrected parameters

---

### User Story 3 - Query and Visualize Premium Data (Priority: P3)

Users need to query premium data interactively, view results in tables and charts, and export data for analysis, providing modern data exploration capabilities not available in the legacy batch system.

**Why this priority**: Adds modern capabilities beyond legacy functionality, enabling better business insights. Builds on core report generation but is not critical for initial operational parity.

**Independent Test**: Can be tested by executing various queries against mocked database, verifying results display correctly in tables and charts, and validating export functionality produces accurate files.

**Acceptance Scenarios**:

1. **Given** user is on the Query screen, **When** they build a query, **Then** they can filter by policy number, product, date range, select specific columns to display, sort results by any column, and apply aggregations (sum, average, count)

2. **Given** query results are displayed, **When** user views the data, **Then** they see paginated table with responsive design, summary statistics at the top, visual charts (bar, line, pie) based on data, and export buttons (CSV, Excel, PDF)

3. **Given** user wants to analyze trends, **When** they create visualizations, **Then** system generates charts from query results, allows customization (chart type, colors, labels), updates charts in real-time as filters change, and saves favorite queries for future use

---

### User Story 4 - Monitor Batch Processing Jobs (Priority: P4)

Users need to schedule and monitor batch report generation jobs, view execution history, and receive notifications about job completion or failures, providing operational visibility for automated processing.

**Why this priority**: Addresses operational requirements for scheduled processing but is not critical for initial MVP. Can be added once interactive generation is stable.

**Independent Test**: Can be tested by creating scheduled jobs, monitoring their execution status, and verifying notification delivery without impacting other system functionality.

**Acceptance Scenarios**:

1. **Given** user wants to automate reports, **When** they create a scheduled job, **Then** they can define job name and description, set recurrence pattern (daily, weekly, monthly), specify report parameters, and configure notification recipients

2. **Given** batch jobs are scheduled, **When** user views job monitor, **Then** they see list of all scheduled jobs, current execution status (Running, Completed, Failed), last execution time and duration, and next scheduled execution time

3. **Given** a batch job completes, **When** results are ready, **Then** system sends email notification to configured recipients, stores output files in designated location, updates job history with execution details, and triggers any configured downstream processes

---

### User Story 5 - Manage Database Mock Data (Priority: P4)

Developers and testers need to manage mock SQLite database data that replicates DB2 structure, load test datasets, and validate data integrity for thorough testing of migration logic.

**Why this priority**: Critical for testing but not user-facing functionality. Required for comprehensive validation but can use minimal datasets initially.

**Independent Test**: Can be tested by loading mock data files, verifying schema matches DB2, querying data, and confirming calculations produce expected results.

**Acceptance Scenarios**:

1. **Given** developer needs test data, **When** they access data management interface, **Then** they can view current SQLite schema, load mock data from CSV/JSON files, validate data against DB2 schema rules, and clear and reset test database

2. **Given** tester wants realistic data, **When** they load production-like dataset, **Then** system validates all foreign key relationships, checks data type compatibility, reports any data quality issues, and confirms record counts match source

3. **Given** migration testing is ongoing, **When** comparing outputs, **Then** developers can run side-by-side comparisons (COBOL vs .NET), generate diff reports highlighting discrepancies, export comparison results for analysis, and flag any business logic deviations

---

### Edge Cases

- **What happens when database query returns zero records?** System displays "No data found for selected parameters" message and allows user to adjust filters without error.

- **How does system handle cursor operations with large datasets?** Implements pagination and streaming results for cursors processing millions of records to prevent memory overflow, matching COBOL's cursor-based processing.

- **What if external module calls (GE0009S, GE0010S) are unavailable?** System displays descriptive error, logs the failure for diagnostics, and allows retry. Admin can configure module endpoints and fallback behavior.

- **How are concurrent users handled during report generation?** System queues requests, provides estimated wait time, and processes reports asynchronously to prevent database locking conflicts.

- **What happens with malformed date inputs?** System validates dates before processing, provides clear error messages in Portuguese ("Data inválida"), and highlights the problematic field.

- **How are DB2-specific data types handled in SQLite?** Mapping layer converts DB2 types (DECIMAL with scale, CHAR fixed-length) to SQLite equivalents, preserving precision and padding rules.

- **What if output file generation fails midway?** Transaction-based file writing ensures atomic operations - either complete file is written or nothing, with rollback capability.

- **How are COBOL numeric computations (PIC 9V99) replicated exactly?** Uses decimal types with exact precision matching, includes rounding mode configuration to replicate COBOL arithmetic behavior.

- **What happens when report parameters conflict (end date before start date)?** Validation layer catches logical errors before processing, returns specific error code and user-friendly message.

- **How is legacy fixed-width file format maintained?** Custom formatter applies padding (spaces for strings, zeros for numbers) matching COBOL WRITE statements exactly, validated by byte comparison.

## Requirements

### Functional Requirements

#### Core Report Generation
- **FR-001**: System MUST generate PREMIT.TXT file with identical layout and content to legacy COBOL output, including all columns, fixed-width formatting, and data precision
- **FR-002**: System MUST generate PREMCED.TXT file for cossurance/ceded premium data with exact legacy format compatibility
- **FR-003**: System MUST process premium records using same business logic as COBOL sections R0500-R5500, ensuring calculation parity
- **FR-004**: System MUST support date range parameters for report generation (initial date, final date) matching legacy WHERE clause logic
- **FR-005**: System MUST validate all input parameters before processing and return descriptive errors in Portuguese

#### Database Integration
- **FR-006**: System MUST connect to SQLite database with schema matching 26+ DB2 views/tables used by legacy COBOL
- **FR-007**: System MUST implement cursor-like processing for large datasets (V0PREMIOS, V0ENDERECOS, V0APOLCOSCED, GE399)
- **FR-008**: System MUST maintain transactional integrity for multi-step operations matching COBOL COMMIT/ROLLBACK behavior
- **FR-009**: System MUST handle all SQL error conditions (duplicate keys, not found, etc.) with equivalent error handling to COBOL SQLCODE checks
- **FR-010**: System MUST support read-only access to all database views without modifying existing data

#### Business Logic Migration
- **FR-011**: System MUST replicate all 687 COBOL data items as C# models with equivalent data types and precision
- **FR-012**: System MUST implement all calculation logic from COBOL sections (premium calculations, accumulations, cossurance)
- **FR-013**: System MUST call equivalent functionality for external modules RE0001S, GE0009S, GE0010S through internal services or APIs
- **FR-014**: System MUST apply all business validation rules encoded in COBOL IF statements (date validations, ramo-specific logic, cancellation checks)
- **FR-015**: System MUST handle endorsement processing (V0ENDOSSO) including cancelled endorsements with same logic as COBOL

#### User Interface
- **FR-016**: System MUST provide dashboard as landing page showing system analysis metrics (sections, data items, tables, complexity)
- **FR-017**: System MUST display function points estimation for migration with breakdown by component
- **FR-018**: System MUST provide report generation interface with parameter selection (dates, systems, report types)
- **FR-019**: System MUST show processing progress indicator during long-running operations
- **FR-020**: System MUST display all error messages and labels in Portuguese (Brazilian)
- **FR-021**: System MUST apply Caixa Seguradora branding (colors, logos, typography) following corporate guidelines from website
- **FR-022**: System MUST be responsive and work on desktop, tablet, and mobile viewports

#### Data Management
- **FR-023**: System MUST provide capability to load mock DB2 data into SQLite from CSV or JSON files
- **FR-024**: System MUST validate mock data schema compatibility with DB2 structure
- **FR-025**: System MUST support export of generated reports in multiple formats (TXT original format, CSV, Excel)
- **FR-026**: System MUST maintain data type precision when converting COBOL PIC formats to C# types (e.g., PIC 9(9)V99 to decimal(11,2))

#### Testing & Validation
- **FR-027**: System MUST provide side-by-side comparison capability between COBOL output and .NET output for validation
- **FR-028**: System MUST log all operations with sufficient detail for debugging and audit (similar to COBOL DISPLAY statements)
- **FR-029**: System MUST generate test reports with sample data to validate business logic migration
- **FR-030**: System MUST include automated unit tests for all critical calculation logic

### Non-Functional Requirements

#### Performance & Scalability
- **NFR-001**: System MUST process 10,000+ premium records in under 5 minutes, matching or improving legacy COBOL throughput.
- **NFR-002**: System MUST deliver API responses under 2 seconds for dashboard endpoints and under 500 ms for standard query endpoints.
- **NFR-003**: System MUST sustain at least 10 concurrent report generations with no more than 20% degradation in processing time.

#### Reliability & Data Integrity
- **NFR-004**: System MUST enforce read-only database access for legacy-mirrored views and block unintended write operations.
- **NFR-005**: System MUST guarantee transactional safeguards so partial failures rollback state consistently across services.

#### Observability & Auditability
- **NFR-006**: System MUST emit structured JSON logs enriched with correlation identifiers and COBOL section references.
- **NFR-007**: System MUST persist audit trails for report requests, parameters, comparison outcomes, and user actions subject to regulatory review.

#### Localization & Compliance
- **NFR-008**: System MUST present all UI text, error messages, and generated user-facing documentation in Brazilian Portuguese.
- **NFR-009**: System MUST maintain byte-level PREMIT/PREMCED compatibility that satisfies SUSEP Circular 360 validation.

#### Deployment & Operations
- **NFR-010**: System MUST build and run inside Docker containers, keeping environment parity between development, validation, and production stages.
- **NFR-011**: System MUST externalize secrets and environment configuration, ensuring sensitive values never reside in source control.

### Key Entities

#### Premium Data
- **Premium Record**: Represents a premium emission record from V0PREMIOS view, including policy number, product code, premium amount, emission date, effective date, status, and calculation components
- **Policy**: Insurance policy master data from V0APOLICE, including policy number, client ID, product, start/end dates, status, and agency information
- **Endorsement**: Policy modification from V0ENDOSSO, including endorsement number, type, date, premium impact, and cancellation status
- **Product**: Insurance product definition from V0PRODUTO/V0PRODUTOSVG, including product code, name, line of business (ramo), SUSEP code, and calculation rules

#### Party & Location
- **Client**: Policyholder or insured party from V0CLIENTE/V0TOMADOR, including client ID, name, document number (CPF/CNPJ), type (person/company)
- **Address**: Location data from V0ENDERECOS, including address components, city, state (UF), postal code, and address type
- **Agency**: Sales agency from V0AGENCIAS, including agency code, name, region, and channel information
- **Producer**: Insurance broker/producer from V0PRODUTOR, including producer code, name, commission rates, and affiliation

#### Coverage & Billing
- **Coverage**: Insurance coverage details from V0COBERAPOL, including coverage code, insured amount (IS), premium calculation basis, rates, and limits
- **Invoice**: Billing information from V0FATURAS, including invoice number, installment details, due dates, payment status, and amounts
- **Installment**: Premium installment from V0HISTOPARC, including parcel number, due date, payment date, amount, and status

#### Cossurance & Reinsurance
- **Cossured Policy**: Cossurance arrangement from V0APOLCOSCED, including ceding/acquiring company, percentage share, and premium distribution
- **Cossurance Calculation**: Cossurance computation data from GE399 table, including quota percentages, retained premium, and ceded amounts
- **Reinsurance Data**: Reinsurance calculations processed through external module RE0001S, including treaty information, retention limits, and ceded premium

## Success Criteria

### Measurable Outcomes

#### Functional Accuracy
- **SC-001**: Generated PREMIT.TXT and PREMCED.TXT files match legacy COBOL output byte-for-byte for identical input datasets (100% accuracy target)
- **SC-002**: All business calculations (premium, cossurance, accumulations) produce identical results to COBOL with zero deviation
- **SC-003**: System processes complete test dataset and generates valid output files in under 5 minutes for datasets with 10,000+ premium records

#### User Experience
- **SC-004**: Users can generate reports through web interface in 30 seconds or less from parameter selection to download (excluding processing time)
- **SC-005**: Dashboard loads and displays all migration metrics within 2 seconds on standard internet connection
- **SC-006**: 95% of report generation requests complete successfully on first attempt without user intervention
- **SC-007**: Error messages provide sufficient clarity that users can self-correct 80% of parameter errors without support

#### Technical Quality
- **SC-008**: System maintains 100% database transaction integrity with zero data corruption during concurrent operations
- **SC-009**: All critical business logic has automated unit test coverage achieving 90%+ code coverage
- **SC-010**: System handles 10 concurrent report generation requests without performance degradation exceeding 20%
- **SC-011**: SQLite mock database supports all 26+ tables with referential integrity constraints matching DB2 structure

#### Migration Validation
- **SC-012**: Side-by-side comparison tests with 100 production samples show 100% output equivalence between COBOL and .NET
- **SC-013**: All 63 COBOL sections have documented equivalent functionality in C# codebase with traceability matrix
- **SC-014**: All 687 COBOL data items have mapped C# models with validated type conversions
- **SC-015**: Performance testing shows .NET system processes equivalent workload within 120% of COBOL execution time (allowing 20% overhead for modernization benefits)

#### Operational Readiness
- **SC-016**: System includes comprehensive logging capturing all operations for 30-day troubleshooting and audit period
- **SC-017**: Documentation covers 100% of migrated business rules with examples and test cases
- **SC-018**: Development team successfully trains 5 business users who can independently generate reports and interpret results
- **SC-019**: System deployed successfully in containerized environment with zero-downtime deployment capability

## Out of Scope

The following items are explicitly excluded from this migration:

### Legacy Systems Not Included
- Migration of external COBOL modules RE0001S, GE0009S, GE0010S (will be called through adapters or mocked)
- Migration of other COBOL programs in the REGISTROS GERAIS system beyond RG1866B
- Integration with production DB2 mainframe database (using SQLite mock only)
- Migration of JCL job scheduling infrastructure

### Advanced Features
- Real-time premium calculation engine (beyond report generation)
- Online policy issuance or endorsement processing
- Integration with external SUSEP submission systems
- Multi-language support (Portuguese Brazilian only)
- Mobile native applications (responsive web only)

### Infrastructure
- Production hosting environment setup
- High availability / disaster recovery infrastructure
- Production security hardening and penetration testing
- Production monitoring and alerting setup

### Data Migration
- Historical data migration from DB2 to production database
- Data cleansing or transformation beyond mock data loading
- Archive strategies for old reports

## Assumptions

### Technical Assumptions
1. **Parser Accuracy**: ProLeap COBOL parser output accurately represents program structure, though business logic will be validated against source code
2. **SQLite Capability**: SQLite database can adequately replicate DB2 functionality for development and testing, including complex joins and cursor operations
3. **External Module Behavior**: External COBOL modules (RE0001S, GE0009S, GE0010S) can be adequately mocked or replaced with equivalent C# implementations
4. **Development Environment**: Team has access to .NET 9 SDK, Node.js 20+, and standard development tools
5. **Browser Compatibility**: Modern browsers (Chrome 120+, Firefox 120+, Edge 120+, Safari 17+) will be supported

### Business Assumptions
1. **Report Format Stability**: SUSEP Circular 360 report layouts remain stable during migration period
2. **Business Rules Documentation**: COBOL comments and header documentation accurately describe business intent
3. **Test Data Availability**: Sufficient representative test data can be obtained or generated for validation
4. **User Availability**: Subject matter experts will be available for business logic clarification during migration
5. **Timeline Flexibility**: Migration can proceed iteratively with user story prioritization allowing early feedback

## Dependencies

### External Dependencies
- **COBOL Source Code**: Complete, readable RG1866B.cbl source file (available)
- **DB2 Schema Documentation**: Database schema definitions for all 26+ tables/views
- **External Module Interfaces**: Interface contracts for RE0001S, GE0009S, GE0010S modules
- **Sample Data**: Representative datasets from production for testing and validation
- **Business Logic Documentation**: Any existing documentation of business rules and calculations
- **Caixa Seguradora Branding**: Corporate style guide, logos, color palette from website

### Technical Dependencies
- **.NET 9 SDK**: Backend framework for API development
- **React 18+**: Frontend framework for user interface
- **SQLite**: Local development database
- **Entity Framework Core**: ORM for database access
- **Serilog**: Logging framework
- **xUnit or MSTest**: Unit testing framework

## Constraints

### Technical Constraints
- **Legacy Compatibility**: Output files must maintain byte-level compatibility with legacy format for regulatory compliance
- **Precision Requirements**: Financial calculations must maintain exact decimal precision matching COBOL arithmetic
- **Database Limitations**: SQLite used for development has limitations vs. production DB2 (no stored procedures, limited concurrency)
- **Browser Requirements**: Must work in standard browsers without plugins or special configurations

### Regulatory Constraints
- **SUSEP Compliance**: Report format and content must comply with SUSEP Circular 360 regulations
- **Data Accuracy**: Insurance premium calculations must be auditable and match regulatory requirements
- **Report Retention**: Generated reports must be stored for regulatory retention period (defined by SUSEP)

### Business Constraints
- **Zero Downtime Requirement**: Migration must not disrupt ongoing report generation capabilities
- **Parallel Operation**: New system must run in parallel with legacy for validation period
- **User Acceptance**: Business users must approve migration before legacy decommission

## Migration Strategy

### Phase 1: Foundation (Weeks 1-2)
**Goal**: Establish project structure and baseline understanding

**Activities**:
1. Analyze parser output and COBOL source code comprehensively
2. Create detailed data dictionary mapping all 687 data items to C# types
3. Extract and document all business rules from COBOL IF/PERFORM logic
4. Set up .NET 9 Web API project structure with Clean Architecture
5. Initialize React project with Caixa Seguradora branding
6. Create SQLite database schema matching 26+ DB2 tables
7. Implement dashboard (User Story 1) with migration metrics

**Deliverables**:
- Data dictionary (COBOL to C# type mappings)
- Business rules documentation
- Project scaffolding (backend + frontend)
- Dashboard showing system complexity

### Phase 2: Core Backend (Weeks 3-5)
**Goal**: Implement backend services with business logic

**Activities**:
1. Create C# entity models for all key database tables
2. Implement repository pattern with Entity Framework Core
3. Migrate premium processing logic (sections R0500-R0700)
4. Implement policy and product data access (sections R0720-R0990)
5. Create calculation services for premium accumulation (R1300)
6. Implement cossurance processing logic (sections R3000-R5500)
7. Develop API endpoints for report generation
8. Unit test all business logic with known test cases

**Deliverables**:
- Backend API with core business logic
- Unit tests for calculations
- API documentation (Swagger)

### Phase 3: Report Generation (Weeks 6-7)
**Goal**: Implement end-to-end report generation

**Activities**:
1. Implement file generation services (PREMIT, PREMCED)
2. Create fixed-width file formatters matching COBOL output
3. Implement cursor-like batch processing for large datasets
4. Develop transaction management for data integrity
5. Create React report generation UI (User Story 2)
6. Implement error handling and validation
7. Load representative test data into SQLite
8. Execute side-by-side comparison tests

**Deliverables**:
- Working report generation (interactive)
- Test results comparing COBOL vs .NET output
- Report generation UI

### Phase 4: Validation & Enhancement (Weeks 8-9)
**Goal**: Validate accuracy and add value-added features

**Activities**:
1. Run comprehensive validation with 100+ test scenarios
2. Implement query and visualization features (User Story 3)
3. Add batch job monitoring (User Story 4)
4. Create data management utilities (User Story 5)
5. Conduct user acceptance testing
6. Performance optimization
7. Documentation completion

**Deliverables**:
- Validation report (COBOL parity achieved)
- Enhanced UI features
- Complete user and technical documentation

## References

### Documentation
- **Parser Analysis**: `/docs/parser/FINAL-ANALYSIS-REPORT.md` - Complete COBOL program structure analysis
- **Detailed Structure**: `/docs/parser/detailed-structure.txt` - Section and paragraph breakdown
- **Parser Index**: `/docs/parser/INDEX.md` - Navigation guide to all parser documentation

### Legacy System
- **COBOL Source**: `/RG1866B.cbl` - Original COBOL program source code
- **Program ID**: RG1866B - REGISTROS GERAIS system
- **Function**: SUSEP Circular 360 - Premium emission reports (PREMIT.TXT, PREMCED.TXT)
- **Created**: May 21, 2014 by Wellington F R C Veras

### External Resources
- **SUSEP Circular 360**: Brazilian insurance regulator reporting requirements
- **Caixa Seguradora Website**: https://www.caixaseguradora.com.br/ - Corporate branding reference
- **Dashboard Reference**: https://sicoob-sge3-jv1x.vercel.app/dashboard - UI inspiration

## Notes

### Critical Implementation Considerations

1. **Decimal Precision**: COBOL PIC fields use exact decimal precision. C# decimal type MUST be used (not double/float) for all financial calculations to avoid rounding errors that would cause regulatory non-compliance.

2. **Fixed-Width Formatting**: COBOL writes fixed-width records with space-padding for strings and zero-padding for numbers. Custom formatters required to replicate exact byte layout.

3. **Cursor Processing**: COBOL uses 4 database cursors for sequential processing. .NET implementation should use streaming/pagination to handle large datasets without loading all into memory.

4. **Date Handling**: COBOL date validations are complex (comparing proposal date vs. effective date by ramo). All date logic must be carefully migrated with timezone considerations.

5. **External Module Calls**: COBOL calls RE0001S, GE0009S, GE0010S with specific parameter structures. These must be mocked initially or replaced with equivalent C# services.

6. **Transaction Semantics**: COBOL has explicit COMMIT points. .NET must replicate same transactional boundaries to maintain data integrity.

### Known Limitations

1. **SQLite vs. DB2**: SQLite lacks some DB2 features (no stored procedures, limited concurrency, different date functions). Production deployment would require migration to SQL Server, PostgreSQL, or actual DB2.

2. **Parser Limitations**: While ProLeap parser successfully extracted structure, some complex COBOL idioms may require manual interpretation from source code.

3. **External Module Availability**: If external COBOL modules source code is unavailable, their functionality must be reverse-engineered from call parameters and expected behaviors.



### DATA-MODEL.MD (Entities & Relationships)

# Data Model Design: COBOL RG1866B to .NET 9 Migration

**Feature Branch**: `001-vamos-migrar-sistema`
**Created**: October 22, 2025
**Status**: Phase 1.1 - Data Model Design
**Version**: 1.0

## Overview

This document defines the C# entity models for the SUSEP Circular 360 Premium Reporting System migration. All entities map to DB2 views/tables used by the legacy COBOL RG1866B program and follow Clean Architecture principles with precise type mappings to preserve COBOL data semantics.

## Design Principles

### Type Mapping Strategy
- **Financial Fields**: Use C# `decimal` type exclusively (never `float`/`double`) to match COBOL packed decimal precision
- **Fixed-Length Strings**: Preserve COBOL `PIC X(n)` semantics with `[MaxLength(n)]` attributes
- **Date Fields**: Use `DateTime` with explicit format handling for COBOL date representations (YYYYMMDD, DDMMYYYY)
- **COBOL Metadata**: Apply `[CobolField]` custom attributes to preserve PIC clause information for validation and file generation

### Entity Framework Configuration
- **Fluent API**: Configure complex relationships, indexes, and constraints
- **No Tracking**: Read-only queries use `AsNoTracking()` for performance
- **View Mapping**: Use `ToView()` for DB2 views, `ToTable()` for tables
- **Concurrency**: Not required (read-only operations)

### Relationship Patterns
- **Navigation Properties**: Defined for foreign key relationships
- **Lazy Loading**: Disabled (use explicit `Include()` for performance control)
- **Cascade Delete**: Not applicable (read-only system)

---

## Core Domain Entities

### 1. Premium Record (V0PREMIOS)

**Purpose**: Represents premium emission records - the core entity for report generation, aggregating policy, product, and financial data.

**COBOL Source**: `V0PREMIOS` view, processed via cursor at section R0500-00-DECLARE-V0PREMIOS

#### Properties

```csharp
public class PremiumRecord
{
    // Primary Key
    [Key]
    public long PremiumId { get; set; }

    // Business Identifiers
    [CobolField(PicClause = "9(9)", Length = 9, FieldType = CobolFieldType.Numeric)]
    public int CompanyCode { get; set; }  // V0PREM-COD-EMP (COMP)

    [CobolField(PicClause = "9(4)", Length = 4)]
    public int ReferenceYear { get; set; }  // V0PREM-ANO-REFER

    [CobolField(PicClause = "9(4)", Length = 4)]
    public int ReferenceMonth { get; set; }  // V0PREM-MES-REFER

    [CobolField(PicClause = "9(4)", Length = 4)]
    public int ReferenceDay { get; set; }  // V0PREM-DIA-REFER

    [CobolField(PicClause = "X(1)", Length = 1)]
    [MaxLength(1)]
    public string MovementType { get; set; }  // V0PREM-TIPO-MOVT ('E', 'C', 'R', etc.)

    [CobolField(PicClause = "9(13)", Length = 13, FieldType = CobolFieldType.PackedDecimal)]
    public long PolicyNumber { get; set; }  // V0PREM-NUM-APOL (COMP-3)

    [CobolField(PicClause = "9(9)", Length = 9)]
    public int EndorsementNumber { get; set; }  // V0PREM-NRENDOS

    [CobolField(PicClause = "9(4)", Length = 4)]
    public int InstallmentNumber { get; set; }  // V0PREM-NRPARCEL

    [CobolField(PicClause = "9(4)", Length = 4)]
    public int OccurrenceNumber { get; set; }  // V0PREM-NUM-OCORR

    [CobolField(PicClause = "9(4)", Length = 4)]
    public int HistoricalOccurrence { get; set; }  // V0PREM-OCORHIST

    // Product Classification
    [CobolField(PicClause = "9(4)", Length = 4)]
    public int LineOfBusiness { get; set; }  // V0PREM-RAMOFR (Ramo)

    [CobolField(PicClause = "9(4)", Length = 4)]
    public int ProductModality { get; set; }  // V0PREM-MODALIFR

    [CobolField(PicClause = "9(4)", Length = 4)]
    public int OperationType { get; set; }  // V0PREM-OPERACAO

    [CobolField(PicClause = "9(4)", Length = 4)]
    public int BusinessOperationType { get; set; }  // V0PREM-TIPO-OPER

    [CobolField(PicClause = "9(9)", Length = 9)]
    public int ClientCode { get; set; }  // V0PREM-CODCLIEN

    // Currency & Exchange
    [CobolField(PicClause = "9(6)V9(9)", Length = 16, DecimalPlaces = 9, FieldType = CobolFieldType.PackedDecimal)]
    [Column(TypeName = "decimal(15,9)")]
    public decimal ExchangeRate { get; set; }  // V0PREM-VALOR-COT

    // Premium Components - Installment (Item)
    [CobolField(PicClause = "9(10)V9(5)", Length = 16, DecimalPlaces = 5, FieldType = CobolFieldType.PackedDecimal)]
    [Column(TypeName = "decimal(15,5)")]
    public decimal InsuredAmountItem { get; set; }  // V0PREM-IMP-SEG-IT

    [CobolField(PicClause = "9(10)V9(5)", Length = 16, DecimalPlaces = 5, FieldType = CobolFieldType.PackedDecimal)]
    [Column(TypeName = "decimal(15,5)")]
    public decimal BasePremiumItem { get; set; }  // V0PREM-VLPRMBAS-IT

    [CobolField(PicClause = "9(10)V9(5)", Length = 16, DecimalPlaces = 5, FieldType = CobolFieldType.PackedDecimal)]
    [Column(TypeName = "decimal(15,5)")]
    public decimal FixedPremiumItem { get; set; }  // V0PREM-VLPREFIX-IT

    [CobolField(PicClause = "9(10)V9(5)", Length = 16, DecimalPlaces = 5, FieldType = CobolFieldType.PackedDecimal)]
    [Column(TypeName = "decimal(15,5)")]
    public decimal TariffPremiumItem { get; set; }  // V0PREM-VLPRMTAR-IT

    [CobolField(PicClause = "9(10)V9(5)", Length = 16, DecimalPlaces = 5, FieldType = CobolFieldType.PackedDecimal)]
    [Column(TypeName = "decimal(15,5)")]
    public decimal DiscountItem { get; set; }  // V0PREM-VLDESCON-IT

    [CobolField(PicClause = "9(10)V9(5)", Length = 16, DecimalPlaces = 5, FieldType = CobolFieldType.PackedDecimal)]
    [Column(TypeName = "decimal(15,5)")]
    public decimal NetPremiumItem { get; set; }  // V0PREM-VLPRMLIQ-IT

    [CobolField(PicClause = "9(10)V9(5)", Length = 16, DecimalPlaces = 5, FieldType = CobolFieldType.PackedDecimal)]
    [Column(TypeName = "decimal(15,5)")]
    public decimal AdditionalFractionalItem { get; set; }  // V0PREM-VLADIFRA-IT

    [CobolField(PicClause = "9(10)V9(5)", Length = 16, DecimalPlaces = 5, FieldType = CobolFieldType.PackedDecimal)]
    [Column(TypeName = "decimal(15,5)")]
    public decimal IssuanceCostItem { get; set; }  // V0PREM-VLCUSEMI-IT

    [CobolField(PicClause = "9(10)V9(5)", Length = 16, DecimalPlaces = 5, FieldType = CobolFieldType.PackedDecimal)]
    [Column(TypeName = "decimal(15,5)")]
    public decimal IofItem { get; set; }  // V0PREM-VLIOCC-IT

    [CobolField(PicClause = "9(10)V9(5)", Length = 16, DecimalPlaces = 5, FieldType = CobolFieldType.PackedDecimal)]
    [Column(TypeName = "decimal(15,5)")]
    public decimal TotalPremiumItem { get; set; }  // V0PREM-VLPRMTOT-IT

    [CobolField(PicClause = "9(10)V9(5)", Length = 16, DecimalPlaces = 5, FieldType = CobolFieldType.PackedDecimal)]
    [Column(TypeName = "decimal(15,5)")]
    public decimal CommissionItem { get; set; }  // V0PREM-VLCOMIS-IT

    [CobolField(PicClause = "9(10)V9(5)", Length = 16, DecimalPlaces = 5, FieldType = CobolFieldType.PackedDecimal)]
    [Column(TypeName = "decimal(15,5)")]
    public decimal AdministrationFeeItem { get; set; }  // V0PREM-VLADMN-IT

    [CobolField(PicClause = "9(10)V9(5)", Length = 16, DecimalPlaces = 5, FieldType = CobolFieldType.PackedDecimal)]
    [Column(TypeName = "decimal(15,5)")]
    public decimal AgencyCommissionItem { get; set; }  // V0PREM-VLAGENC-IT

    [CobolField(PicClause = "9(10)V9(5)", Length = 16, DecimalPlaces = 5, FieldType = CobolFieldType.PackedDecimal)]
    [Column(TypeName = "decimal(15,5)")]
    public decimal PreferentialCommissionItem { get; set; }  // V0PREM-VLPREFCM-IT

    // Premium Components - Net (Liquido)
    [CobolField(PicClause = "9(10)V9(5)", Length = 16, DecimalPlaces = 5, FieldType = CobolFieldType.PackedDecimal)]
    [Column(TypeName = "decimal(15,5)")]
    public decimal InsuredAmountNet { get; set; }  // V0PREM-IMP-SEG-IL

    [CobolField(PicClause = "9(10)V9(5)", Length = 16, DecimalPlaces = 5, FieldType = CobolFieldType.PackedDecimal)]
    [Column(TypeName = "decimal(15,5)")]
    public decimal BasePremiumNet { get; set; }  // V0PREM-VLPRMBAS-IL

    [CobolField(PicClause = "9(10)V9(5)", Length = 16, DecimalPlaces = 5, FieldType = CobolFieldType.PackedDecimal)]
    [Column(TypeName = "decimal(15,5)")]
    public decimal FixedPremiumNet { get; set; }  // V0PREM-VLPREFIX-IL

    [CobolField(PicClause = "9(10)V9(5)", Length = 16, DecimalPlaces = 5, FieldType = CobolFieldType.PackedDecimal)]
    [Column(TypeName = "decimal(15,5)")]
    public decimal TariffPremiumNet { get; set; }  // V0PREM-VLPRMTAR-IL

    [CobolField(PicClause = "9(10)V9(5)", Length = 16, DecimalPlaces = 5, FieldType = CobolFieldType.PackedDecimal)]
    [Column(TypeName = "decimal(15,5)")]
    public decimal DiscountNet { get; set; }  // V0PREM-VLDESCON-IL

    [CobolField(PicClause = "9(10)V9(5)", Length = 16, DecimalPlaces = 5, FieldType = CobolFieldType.PackedDecimal)]
    [Column(TypeName = "decimal(15,5)")]
    public decimal NetPremiumNet { get; set; }  // V0PREM-VLPRMLIQ-IL

    [CobolField(PicClause = "9(10)V9(5)", Length = 16, DecimalPlaces = 5, FieldType = CobolFieldType.PackedDecimal)]
    [Column(TypeName = "decimal(15,5)")]
    public decimal AdditionalFractionalNet { get; set; }  // V0PREM-VLADIFRA-IL

    [CobolField(PicClause = "9(10)V9(5)", Length = 16, DecimalPlaces = 5, FieldType = CobolFieldType.PackedDecimal)]
    [Column(TypeName = "decimal(15,5)")]
    public decimal IssuanceCostNet { get; set; }  // V0PREM-VLCUSEMI-IL

    [CobolField(PicClause = "9(10)V9(5)", Length = 16, DecimalPlaces = 5, FieldType = CobolFieldType.PackedDecimal)]
    [Column(TypeName = "decimal(15,5)")]
    public decimal IofNet { get; set; }  // V0PREM-VLIOCC-IL

    [CobolField(PicClause = "9(10)V9(5)", Length = 16, DecimalPlaces = 5, FieldType = CobolFieldType.PackedDecimal)]
    [Column(TypeName = "decimal(15,5)")]
    public decimal TotalPremiumNet { get; set; }  // V0PREM-VLPRMTOT-IL

    [CobolField(PicClause = "9(10)V9(5)", Length = 16, DecimalPlaces = 5, FieldType = CobolFieldType.PackedDecimal)]
    [Column(TypeName = "decimal(15,5)")]
    public decimal CommissionNet { get; set; }  // V0PREM-VLCOMIS-IL

    [CobolField(PicClause = "9(10)V9(5)", Length = 16, DecimalPlaces = 5, FieldType = CobolFieldType.PackedDecimal)]
    [Column(TypeName = "decimal(15,5)")]
    public decimal AdministrationFeeNet { get; set; }  // V0PREM-VLADMN-IL

    [CobolField(PicClause = "9(10)V9(5)", Length = 16, DecimalPlaces = 5, FieldType = CobolFieldType.PackedDecimal)]
    [Column(TypeName = "decimal(15,5)")]
    public decimal AgencyCommissionNet { get; set; }  // V0PREM-VLAGENC-IL

    [CobolField(PicClause = "9(10)V9(5)", Length = 16, DecimalPlaces = 5, FieldType = CobolFieldType.PackedDecimal)]
    [Column(TypeName = "decimal(15,5)")]
    public decimal PreferentialCommissionNet { get; set; }  // V0PREM-VLPREFCM-IL

    // Premium Components - Cossurance (Cosseguro)
    [CobolField(PicClause = "9(10)V9(5)", Length = 16, DecimalPlaces = 5, FieldType = CobolFieldType.PackedDecimal)]
    [Column(TypeName = "decimal(15,5)")]
    public decimal InsuredAmountCossurance { get; set; }  // V0PREM-IMP-SEG-IC

    [CobolField(PicClause = "9(10)V9(5)", Length = 16, DecimalPlaces = 5, FieldType = CobolFieldType.PackedDecimal)]
    [Column(TypeName = "decimal(15,5)")]
    public decimal BasePremiumCossurance { get; set; }  // V0PREM-VLPRMBAS-IC

    [CobolField(PicClause = "9(10)V9(5)", Length = 16, DecimalPlaces = 5, FieldType = CobolFieldType.PackedDecimal)]
    [Column(TypeName = "decimal(15,5)")]
    public decimal FixedPremiumCossurance { get; set; }  // V0PREM-VLPREFIX-IC

    [CobolField(PicClause = "9(10)V9(5)", Length = 16, DecimalPlaces = 5, FieldType = CobolFieldType.PackedDecimal)]
    [Column(TypeName = "decimal(15,5)")]
    public decimal TariffPremiumCossurance { get; set; }  // V0PREM-VLPRMTAR-IC

    [CobolField(PicClause = "9(10)V9(5)", Length = 16, DecimalPlaces = 5, FieldType = CobolFieldType.PackedDecimal)]
    [Column(TypeName = "decimal(15,5)")]
    public decimal DiscountCossurance { get; set; }  // V0PREM-VLDESCON-IC

    [CobolField(PicClause = "9(10)V9(5)", Length = 16, DecimalPlaces = 5, FieldType = CobolFieldType.PackedDecimal)]
    [Column(TypeName = "decimal(15,5)")]
    public decimal NetPremiumCossurance { get; set; }  // V0PREM-VLPRMLIQ-IC

    [CobolField(PicClause = "9(10)V9(5)", Length = 16, DecimalPlaces = 5, FieldType = CobolFieldType.PackedDecimal)]
    [Column(TypeName = "decimal(15,5)")]
    public decimal AdditionalFractionalCossurance { get; set; }  // V0PREM-VLADIFRA-IC

    [CobolField(PicClause = "9(10)V9(5)", Length = 16, DecimalPlaces = 5, FieldType = CobolFieldType.PackedDecimal)]
    [Column(TypeName = "decimal(15,5)")]
    public decimal CommissionCossurance { get; set; }  // V0PREM-VLCOMIS-IC

    [CobolField(PicClause = "9(10)V9(5)", Length = 16, DecimalPlaces = 5, FieldType = CobolFieldType.PackedDecimal)]
    [Column(TypeName = "decimal(15,5)")]
    public decimal AdministrationFeeCossurance { get; set; }  // V0PREM-VLADMN-IC

    [CobolField(PicClause = "9(10)V9(5)", Length = 16, DecimalPlaces = 5, FieldType = CobolFieldType.PackedDecimal)]
    [Column(TypeName = "decimal(15,5)")]
    public decimal AgencyCommissionCossurance { get; set; }  // V0PREM-VLAGENC-IC

    [CobolField(PicClause = "9(10)V9(5)", Length = 16, DecimalPlaces = 5, FieldType = CobolFieldType.PackedDecimal)]
    [Column(TypeName = "decimal(15,5)")]
    public decimal PreferentialCommissionCossurance { get; set; }  // V0PREM-VLPREFCM-IC

    // Premium Components - Reinsurance
    [CobolField(PicClause = "9(10)V9(5)", Length = 16, DecimalPlaces = 5, FieldType = CobolFieldType.PackedDecimal)]
    [Column(TypeName = "decimal(15,5)")]
    public decimal InsuredAmountReinsurance { get; set; }  // V0PREM-IMP-SEG-IR

    [CobolField(PicClause = "9(10)V9(5)", Length = 16, DecimalPlaces = 5, FieldType = CobolFieldType.PackedDecimal)]
    [Column(TypeName = "decimal(15,5)")]
    public decimal TariffPremiumReinsurance { get; set; }  // V0PREM-VLPRMTAR-IR

    [CobolField(PicClause = "9(10)V9(5)", Length = 16, DecimalPlaces = 5, FieldType = CobolFieldType.PackedDecimal)]
    [Column(TypeName = "decimal(15,5)")]
    public decimal DiscountReinsurance { get; set; }  // V0PREM-VLDESCON-IR

    [CobolField(PicClause = "9(10)V9(5)", Length = 16, DecimalPlaces = 5, FieldType = CobolFieldType.PackedDecimal)]
    [Column(TypeName = "decimal(15,5)")]
    public decimal NetPremiumReinsurance { get; set; }  // V0PREM-VLPRMLIQ-IR

    [CobolField(PicClause = "9(10)V9(5)", Length = 16, DecimalPlaces = 5, FieldType = CobolFieldType.PackedDecimal)]
    [Column(TypeName = "decimal(15,5)")]
    public decimal AdditionalFractionalReinsurance { get; set; }  // V0PREM-VLADIFRA-IR

    [CobolField(PicClause = "9(10)V9(5)", Length = 16, DecimalPlaces = 5, FieldType = CobolFieldType.PackedDecimal)]
    [Column(TypeName = "decimal(15,5)")]
    public decimal CommissionReinsurance { get; set; }  // V0PREM-VLCOMIS-IR

    // Premium Totals
    [CobolField(PicClause = "9(13)V99", Length = 15, DecimalPlaces = 2, FieldType = CobolFieldType.PackedDecimal)]
    [Column(TypeName = "decimal(15,2)")]
    public decimal InsuredAmountTotal { get; set; }  // V0PREM-IMP-SEG-T

    [CobolField(PicClause = "9(13)V99", Length = 15, DecimalPlaces = 2, FieldType = CobolFieldType.PackedDecimal)]
    [Column(TypeName = "decimal(15,2)")]
    public decimal BasePremiumTotal { get; set; }  // V0PREM-VLPRMBAS-T

    [CobolField(PicClause = "9(13)V99", Length = 15, DecimalPlaces = 2, FieldType = CobolFieldType.PackedDecimal)]
    [Column(TypeName = "decimal(15,2)")]
    public decimal FixedPremiumTotal { get; set; }  // V0PREM-VLPREFIX-T

    [CobolField(PicClause = "9(13)V99", Length = 15, DecimalPlaces = 2, FieldType = CobolFieldType.PackedDecimal)]
    [Column(TypeName = "decimal(15,2)")]
    public decimal TariffPremiumTotal { get; set; }  // V0PREM-VLPRMTAR-T

    [CobolField(PicClause = "9(13)V99", Length = 15, DecimalPlaces = 2, FieldType = CobolFieldType.PackedDecimal)]
    [Column(TypeName = "decimal(15,2)")]
    public decimal DiscountTotal { get; set; }  // V0PREM-VLDESCON-T

    [CobolField(PicClause = "9(13)V99", Length = 15, DecimalPlaces = 2, FieldType = CobolFieldType.PackedDecimal)]
    [Column(TypeName = "decimal(15,2)")]
    public decimal NetPremiumTotal { get; set; }  // V0PREM-VLPRMLIQ-T

    [CobolField(PicClause = "9(13)V99", Length = 15, DecimalPlaces = 2, FieldType = CobolFieldType.PackedDecimal)]
    [Column(TypeName = "decimal(15,2)")]
    public decimal AdditionalFractionalTotal { get; set; }  // V0PREM-VLADIFRA-T

    [CobolField(PicClause = "9(13)V99", Length = 15, DecimalPlaces = 2, FieldType = CobolFieldType.PackedDecimal)]
    [Column(TypeName = "decimal(15,2)")]
    public decimal IssuanceCostTotal { get; set; }  // V0PREM-VLCUSEMI-T

    [CobolField(PicClause = "9(13)V99", Length = 15, DecimalPlaces = 2, FieldType = CobolFieldType.PackedDecimal)]
    [Column(TypeName = "decimal(15,2)")]
    public decimal IofTotal { get; set; }  // V0PREM-VLIOCC-T

    [CobolField(PicClause = "9(13)V99", Length = 15, DecimalPlaces = 2, FieldType = CobolFieldType.PackedDecimal)]
    [Column(TypeName = "decimal(15,2)")]
    public decimal TotalPremiumTotal { get; set; }  // V0PREM-VLPRMTOT-T

    [CobolField(PicClause = "9(13)V99", Length = 15, DecimalPlaces = 2, FieldType = CobolFieldType.PackedDecimal)]
    [Column(TypeName = "decimal(15,2)")]
    public decimal CommissionTotal { get; set; }  // V0PREM-VLCOMIS-T

    [CobolField(PicClause = "9(13)V99", Length = 15, DecimalPlaces = 2, FieldType = CobolFieldType.PackedDecimal)]
    [Column(TypeName = "decimal(15,2)")]
    public decimal AdministrationFeeTotal { get; set; }  // V0PREM-VLADMN-T

    [CobolField(PicClause = "9(13)V99", Length = 15, DecimalPlaces = 2, FieldType = CobolFieldType.PackedDecimal)]
    [Column(TypeName = "decimal(15,2)")]
    public decimal AgencyCommissionTotal { get; set; }  // V0PREM-VLAGENC-T

    [CobolField(PicClause = "9(13)V99", Length = 15, DecimalPlaces = 2, FieldType = CobolFieldType.PackedDecimal)]
    [Column(TypeName = "decimal(15,2)")]
    public decimal PreferentialCommissionTotal { get; set; }  // V0PREM-VLPREFCM-T

    // Net Local Currency Totals
    [CobolField(PicClause = "9(13)V99", Length = 15, DecimalPlaces = 2, FieldType = CobolFieldType.PackedDecimal)]
    [Column(TypeName = "decimal(15,2)")]
    public decimal InsuredAmountLocalTotal { get; set; }  // V0PREM-IMP-SEG-L

    [CobolField(PicClause = "9(13)V99", Length = 15, DecimalPlaces = 2, FieldType = CobolFieldType.PackedDecimal)]
    [Column(TypeName = "decimal(15,2)")]
    public decimal BasePremiumLocalTotal { get; set; }  // V0PREM-VLPRMBAS-L

    [CobolField(PicClause = "9(13)V99", Length = 15, DecimalPlaces = 2, FieldType = CobolFieldType.PackedDecimal)]
    [Column(TypeName = "decimal(15,2)")]
    public decimal FixedPremiumLocalTotal { get; set; }  // V0PREM-VLPREFIX-L

    // Navigation Properties
    public Policy Policy { get; set; }
    public Product Product { get; set; }
    public Client Client { get; set; }
    public Endorsement Endorsement { get; set; }
}
```

#### Validation Rules
1. `PolicyNumber` must exist in `Policy` entity
2. `EndorsementNumber` > 0 indicates endorsement-related premium
3. `ReferenceYear` must be >= 2000
4. `ReferenceMonth` must be 1-12
5. `ReferenceDay` must be 1-31
6. `MovementType` must be in `['E', 'C', 'R', 'S', 'A']` (Emission, Cancellation, Reversal, Supplement, Adjustment)
7. All financial totals must equal sum of corresponding item/net/cossurance/reinsurance components

#### EF Core Configuration

```csharp
public class PremiumRecordConfiguration : IEntityTypeConfiguration<PremiumRecord>
{
    public void Configure(EntityTypeBuilder<PremiumRecord> builder)
    {
        builder.ToView("V0PREMIOS");
        builder.HasKey(p => p.PremiumId);

        // Indexes for cursor processing (COBOL WHERE clause equivalents)
        builder.HasIndex(p => new { p.CompanyCode, p.ReferenceYear, p.ReferenceMonth, p.ReferenceDay })
            .HasDatabaseName("IX_V0PREMIOS_DateRange");

        builder.HasIndex(p => p.PolicyNumber)
            .HasDatabaseName("IX_V0PREMIOS_PolicyNumber");

        // Relationships
        builder.HasOne(p => p.Policy)
            .WithMany()
            .HasForeignKey(p => p.PolicyNumber)
            .OnDelete(DeleteBehavior.Restrict);

        builder.HasOne(p => p.Client)
            .WithMany()
            .HasForeignKey(p => p.ClientCode)
            .OnDelete(DeleteBehavior.Restrict);
    }
}
```

---

### 2. Policy (V0APOLICE)

**Purpose**: Insurance policy master data containing contract information, effective dates, and status.

**COBOL Source**: `V0APOLICE` view, accessed at sections R0980-00-SELECT-V0APOLICE, R0990-00-SELECT-EF-APOLICE

#### Properties

```csharp
public class Policy
{
    [Key]
    [CobolField(PicClause = "9(13)", Length = 13, FieldType = CobolFieldType.PackedDecimal)]
    public long PolicyNumber { get; set; }  // NUM_APOLICE

    [CobolField(PicClause = "9(9)", Length = 9)]
    public int CompanyCode { get; set; }  // COD_EMP

    [CobolField(PicClause = "9(4)", Length = 4)]
    public int ProductCode { get; set; }  // COD_PROD

    [CobolField(PicClause = "9(9)", Length = 9)]
    public int ClientCode { get; set; }  // COD_CLIEN (Policyholder)

    [CobolField(PicClause = "X(10)", Length = 10)]
    [MaxLength(10)]
    public string EffectiveDate { get; set; }  // DT_INIVIG (YYYY-MM-DD)

    public DateTime EffectiveDateParsed => DateTime.ParseExact(EffectiveDate, "yyyy-MM-dd", CultureInfo.InvariantCulture);

    [CobolField(PicClause = "X(10)", Length = 10)]
    [MaxLength(10)]
    public string ExpirationDate { get; set; }  // DT_FIMVIG

    public DateTime ExpirationDateParsed => DateTime.ParseExact(ExpirationDate, "yyyy-MM-dd", CultureInfo.InvariantCulture);

    [CobolField(PicClause = "X(10)", Length = 10)]
    [MaxLength(10)]
    public string IssuanceDate { get; set; }  // DT_EMIS

    public DateTime IssuanceDateParsed => DateTime.ParseExact(IssuanceDate, "yyyy-MM-dd", CultureInfo.InvariantCulture);

    [CobolField(PicClause = "X(10)", Length = 10)]
    [MaxLength(10)]
    public string ProposalDate { get; set; }  // DT_PROPT

    [CobolField(PicClause = "X(1)", Length = 1)]
    [MaxLength(1)]
    public string PolicyStatus { get; set; }  // IND_SITUACAO ('A'=Active, 'C'=Cancelled, etc.)

    [CobolField(PicClause = "9(4)", Length = 4)]
    public int AgencyCode { get; set; }  // COD_AGENC

    [CobolField(PicClause = "9(9)", Length = 9)]
    public int ProducerCode { get; set; }  // COD_PRODU

    [CobolField(PicClause = "9(13)", Length = 13)]
    public long ProposalNumber { get; set; }  // NUM_PROPT

    [CobolField(PicClause = "9(4)", Length = 4)]
    public int LineOfBusiness { get; set; }  // RAMO_SUSEP

    [CobolField(PicClause = "9(13)V99", Length = 15, DecimalPlaces = 2, FieldType = CobolFieldType.PackedDecimal)]
    [Column(TypeName = "decimal(15,2)")]
    public decimal InsuredAmount { get; set; }  // IMP_SEG

    [CobolField(PicClause = "9(13)V99", Length = 15, DecimalPlaces = 2, FieldType = CobolFieldType.PackedDecimal)]
    [Column(TypeName = "decimal(15,2)")]
    public decimal TotalPremium { get; set; }  // VL_PRM_TOT

    [CobolField(PicClause = "9(4)", Length = 4)]
    public int RenewalType { get; set; }  // TIP_RENOV

    // Navigation Properties
    public Product Product { get; set; }
    public Client Policyholder { get; set; }
    public Agency Agency { get; set; }
    public Producer Producer { get; set; }
    public ICollection<Endorsement> Endorsements { get; set; }
    public ICollection<Coverage> Coverages { get; set; }
}
```

#### Validation Rules
1. `EffectiveDate` must be <= `ExpirationDate`
2. `IssuanceDate` should be <= `EffectiveDate` (with exceptions for specific products)
3. `PolicyStatus` must be in `['A', 'C', 'S', 'E']` (Active, Cancelled, Suspended, Expired)
4. `PolicyNumber` must be unique per `CompanyCode`

#### EF Core Configuration

```csharp
public class PolicyConfiguration : IEntityTypeConfiguration<Policy>
{
    public void Configure(EntityTypeBuilder<Policy> builder)
    {
        builder.ToView("V0APOLICE");
        builder.HasKey(p => p.PolicyNumber);

        builder.HasIndex(p => new { p.CompanyCode, p.ProductCode })
            .HasDatabaseName("IX_V0APOLICE_Product");

        builder.HasIndex(p => p.ClientCode)
            .HasDatabaseName("IX_V0APOLICE_Client");

        builder.HasOne(p => p.Product)
            .WithMany()
            .HasForeignKey(p => p.ProductCode)
            .OnDelete(DeleteBehavior.Restrict);

        builder.HasOne(p => p.Policyholder)
            .WithMany()
            .HasForeignKey(p => p.ClientCode)
            .OnDelete(DeleteBehavior.Restrict);

        builder.HasOne(p => p.Agency)
            .WithMany()
            .HasForeignKey(p => p.AgencyCode)
            .OnDelete(DeleteBehavior.Restrict);

        builder.HasOne(p => p.Producer)
            .WithMany()
            .HasForeignKey(p => p.ProducerCode)
            .OnDelete(DeleteBehavior.Restrict);
    }
}
```

---

### 3. Endorsement (V0ENDOSSO)

**Purpose**: Policy modifications (endorsements) that alter coverage, premium, or other policy terms.

**COBOL Source**: `V0ENDOSSO` view, accessed at sections R0760-00-SELECT-V0ENDOSSO, R0780-00-SELECT-ENDOS-CANCLM

#### Properties

```csharp
public class Endorsement
{
    [Key]
    public long EndorsementId { get; set; }

    [CobolField(PicClause = "9(13)", Length = 13, FieldType = CobolFieldType.PackedDecimal)]
    public long PolicyNumber { get; set; }  // NUM_APOLICE

    [CobolField(PicClause = "9(9)", Length = 9)]
    public int EndorsementNumber { get; set; }  // NUM_ENDOS

    [CobolField(PicClause = "X(10)", Length = 10)]
    [MaxLength(10)]
    public string EndorsementDate { get; set; }  // DT_ENDOS

    public DateTime EndorsementDateParsed => DateTime.ParseExact(EndorsementDate, "yyyy-MM-dd", CultureInfo.InvariantCulture);

    [CobolField(PicClause = "9(4)", Length = 4)]
    public int EndorsementType { get; set; }  // TIP_ENDOS

    [CobolField(PicClause = "X(1)", Length = 1)]
    [MaxLength(1)]
    public string EndorsementStatus { get; set; }  // IND_SITUACAO

    [CobolField(PicClause = "X(1)", Length = 1)]
    [MaxLength(1)]
    public string CancellationFlag { get; set; }  // IND_CANCELM ('S'/'N')

    [CobolField(PicClause = "X(10)", Length = 10)]
    [MaxLength(10)]
    public string CancellationDate { get; set; }  // DT_CANCELM

    [CobolField(PicClause = "9(13)V99", Length = 15, DecimalPlaces = 2, FieldType = CobolFieldType.PackedDecimal)]
    [Column(TypeName = "decimal(15,2)")]
    public decimal PremiumImpact { get; set; }  // VL_PRM_ENDOS (can be negative for cancellations)

    [CobolField(PicClause = "9(13)V99", Length = 15, DecimalPlaces = 2, FieldType = CobolFieldType.PackedDecimal)]
    [Column(TypeName = "decimal(15,2)")]
    public decimal InsuredAmountChange { get; set; }  // IMP_SEG_ENDOS

    [CobolField(PicClause = "9(4)", Length = 4)]
    public int CancellationReason { get; set; }  // COD_MOTIVO_CANCEL

    [CobolField(PicClause = "X(200)", Length = 200)]
    [MaxLength(200)]
    public string EndorsementDescription { get; set; }  // DES_ENDOS

    // Navigation Properties
    public Policy Policy { get; set; }
}
```

#### Validation Rules
1. `PolicyNumber` must exist in `Policy` entity
2. `EndorsementNumber` must be > 0
3. `CancellationFlag` must be 'S' or 'N'
4. If `CancellationFlag` = 'S', `CancellationDate` must not be null
5. `EndorsementDate` must be >= Policy `EffectiveDate`

#### EF Core Configuration

```csharp
public class EndorsementConfiguration : IEntityTypeConfiguration<Endorsement>
{
    public void Configure(EntityTypeBuilder<Endorsement> builder)
    {
        builder.ToView("V0ENDOSSO");
        builder.HasKey(e => e.EndorsementId);

        builder.HasIndex(e => new { e.PolicyNumber, e.EndorsementNumber })
            .IsUnique()
            .HasDatabaseName("IX_V0ENDOSSO_PolicyEndorsement");

        builder.HasIndex(e => e.CancellationFlag)
            .HasDatabaseName("IX_V0ENDOSSO_Cancellation");

        builder.HasOne(e => e.Policy)
            .WithMany(p => p.Endorsements)
            .HasForeignKey(e => e.PolicyNumber)
            .OnDelete(DeleteBehavior.Restrict);
    }
}
```

---

### 4. Product (V0PRODUTO, V0PRODUTOSVG)

**Purpose**: Insurance product definitions including SUSEP codes, line of business classification, and product metadata.

**COBOL Source**: `V0PRODUTO` view (R0740-00-SELECT-V0PRODUTO), `V0PRODUTOSVG` view (R1020-00-SELECT-V0PRODUTOSVG)

#### Properties

```csharp
public class Product
{
    [Key]
    [CobolField(PicClause = "9(4)", Length = 4)]
    public int ProductCode { get; set; }  // COD_PROD

    [CobolField(PicClause = "9(9)", Length = 9)]
    public int CompanyCode { get; set; }  // COD_EMP

    [CobolField(PicClause = "X(100)", Length = 100)]
    [MaxLength(100)]
    public string ProductName { get; set; }  // NOM_PROD

    [CobolField(PicClause = "9(4)", Length = 4)]
    public int LineOfBusiness { get; set; }  // RAMO_SUSEP

    [CobolField(PicClause = "9(4)", Length = 4)]
    public int LineOfBusinessGroup { get; set; }  // GRUPO_RAMO_SUSEP

    [CobolField(PicClause = "X(20)", Length = 20)]
    [MaxLength(20)]
    public string SusepProcessNumber { get; set; }  // NUM_PROC_SUSEP

    [CobolField(PicClause = "X(1)", Length = 1)]
    [MaxLength(1)]
    public string ProductType { get; set; }  // TIP_PROD ('A'=Auto, 'V'=Vida, 'R'=Residencial, etc.)

    [CobolField(PicClause = "X(1)", Length = 1)]
    [MaxLength(1)]
    public string ProductStatus { get; set; }  // IND_SITUACAO ('A'=Active, 'I'=Inactive)

    [CobolField(PicClause = "9(4)", Length = 4)]
    public int ProductModality { get; set; }  // MODALIFR

    [CobolField(PicClause = "X(1)", Length = 1)]
    [MaxLength(1)]
    public string IsLifeInsurance { get; set; }  // IND_VIDA_GRUPO ('S'/'N')

    // Navigation Properties
    public ICollection<Policy> Policies { get; set; }
}
```

#### Validation Rules
1. `ProductCode` must be unique per `CompanyCode`
2. `LineOfBusiness` must be valid SUSEP code (e.g., 0118 = Auto, 0969 = Vida Individual)
3. `ProductStatus` must be in `['A', 'I', 'S']` (Active, Inactive, Suspended)
4. `SusepProcessNumber` format must match SUSEP standards (e.g., "15414.900XXX/XXXX-XX")

#### EF Core Configuration

```csharp
public class ProductConfiguration : IEntityTypeConfiguration<Product>
{
    public void Configure(EntityTypeBuilder<Product> builder)
    {
        builder.ToView("V0PRODUTO");
        builder.HasKey(p => p.ProductCode);

        builder.HasIndex(p => new { p.CompanyCode, p.LineOfBusiness })
            .HasDatabaseName("IX_V0PRODUTO_LineOfBusiness");

        builder.HasIndex(p => p.ProductStatus)
            .HasDatabaseName("IX_V0PRODUTO_Status");
    }
}
```

---

### 5. Client (V0CLIENTE, V0TOMADOR)

**Purpose**: Customer/party information for policyholders, insured parties, and beneficiaries.

**COBOL Source**: `V0CLIENTE` view (R0960-00-SELECT-V0CLIENTE), `V0TOMADOR` view (R1140-00-SELECT-V0TOMADOR)

#### Properties

```csharp
public class Client
{
    [Key]
    [CobolField(PicClause = "9(9)", Length = 9)]
    public int ClientCode { get; set; }  // COD_CLIEN

    [CobolField(PicClause = "9(9)", Length = 9)]
    public int CompanyCode { get; set; }  // COD_EMP

    [CobolField(PicClause = "X(100)", Length = 100)]
    [MaxLength(100)]
    public string ClientName { get; set; }  // NOM_CLIEN

    [CobolField(PicClause = "X(1)", Length = 1)]
    [MaxLength(1)]
    public string ClientType { get; set; }  // TIP_PESSOA ('F'=Fisica/Person, 'J'=Juridica/Company)

    [CobolField(PicClause = "X(14)", Length = 14)]
    [MaxLength(14)]
    public string DocumentNumber { get; set; }  // NUM_CPF_CNPJ (CPF or CNPJ)

    [CobolField(PicClause = "X(20)", Length = 20)]
    [MaxLength(20)]
    public string IdentityDocument { get; set; }  // NUM_RG_IE

    [CobolField(PicClause = "X(10)", Length = 10)]
    [MaxLength(10)]
    public string BirthDate { get; set; }  // DT_NASC (YYYY-MM-DD)

    public DateTime? BirthDateParsed => string.IsNullOrWhiteSpace(BirthDate)
        ? null
        : DateTime.ParseExact(BirthDate, "yyyy-MM-dd", CultureInfo.InvariantCulture);

    [CobolField(PicClause = "X(1)", Length = 1)]
    [MaxLength(1)]
    public string Gender { get; set; }  // IND_SEXO ('M', 'F')

    [CobolField(PicClause = "X(50)", Length = 50)]
    [MaxLength(50)]
    public string Email { get; set; }  // DES_EMAIL

    [CobolField(PicClause = "X(20)", Length = 20)]
    [MaxLength(20)]
    public string PhoneNumber { get; set; }  // NUM_FONE

    [CobolField(PicClause = "X(1)", Length = 1)]
    [MaxLength(1)]
    public string ClientStatus { get; set; }  // IND_SITUACAO ('A'=Active, 'I'=Inactive)

    // Navigation Properties
    public ICollection<Address> Addresses { get; set; }
}
```

#### Validation Rules
1. `ClientCode` must be unique per `CompanyCode`
2. `ClientType` must be 'F' or 'J'
3. If `ClientType` = 'F', `DocumentNumber` must be valid CPF (11 digits)
4. If `ClientType` = 'J', `DocumentNumber` must be valid CNPJ (14 digits)
5. `Email` must match email format regex if not null
6. `Gender` must be in `['M', 'F', 'O']` (Male, Female, Other)

#### EF Core Configuration

```csharp
public class ClientConfiguration : IEntityTypeConfiguration<Client>
{
    public void Configure(EntityTypeBuilder<Client> builder)
    {
        builder.ToView("V0CLIENTE");
        builder.HasKey(c => c.ClientCode);

        builder.HasIndex(c => c.DocumentNumber)
            .IsUnique()
            .HasDatabaseName("IX_V0CLIENTE_DocumentNumber");

        builder.HasIndex(c => c.ClientType)
            .HasDatabaseName("IX_V0CLIENTE_Type");
    }
}
```

---

### 6. Address (V0ENDERECOS)

**Purpose**: Address information for clients, agencies, and other parties. COBOL uses cursor processing for multiple addresses per client.

**COBOL Source**: `V0ENDERECOS` view, cursor declared at R1230-00-DECLARE-V0ENDERECOS, fetched at R1240-00-FETCH-V0ENDERECOS

#### Properties

```csharp
public class Address
{
    [Key]
    public long AddressId { get; set; }

    [CobolField(PicClause = "9(9)", Length = 9)]
    public int ClientCode { get; set; }  // COD_CLIEN

    [CobolField(PicClause = "9(4)", Length = 4)]
    public int AddressSequence { get; set; }  // SEQ_ENDER

    [CobolField(PicClause = "X(1)", Length = 1)]
    [MaxLength(1)]
    public string AddressType { get; set; }  // TIP_ENDER ('R'=Residential, 'C'=Commercial, etc.)

    [CobolField(PicClause = "X(100)", Length = 100)]
    [MaxLength(100)]
    public string StreetAddress { get; set; }  // DES_LOGRADOURO

    [CobolField(PicClause = "X(10)", Length = 10)]
    [MaxLength(10)]
    public string Number { get; set; }  // NUM_LOGRA

    [CobolField(PicClause = "X(50)", Length = 50)]
    [MaxLength(50)]
    public string Complement { get; set; }  // DES_COMPL

    [CobolField(PicClause = "X(50)", Length = 50)]
    [MaxLength(50)]
    public string Neighborhood { get; set; }  // DES_BAIRRO

    [CobolField(PicClause = "X(50)", Length = 50)]
    [MaxLength(50)]
    public string City { get; set; }  // NOM_MUNIC

    [CobolField(PicClause = "X(2)", Length = 2)]
    [MaxLength(2)]
    public string State { get; set; }  // COD_UF (e.g., 'SP', 'RJ')

    [CobolField(PicClause = "X(8)", Length = 8)]
    [MaxLength(8)]
    public string PostalCode { get; set; }  // NUM_CEP (Brazilian CEP format XXXXX-XXX)

    [CobolField(PicClause = "9(4)", Length = 4)]
    public int CountryCode { get; set; }  // COD_PAIS (default 1058 = Brazil)

    // Navigation Properties
    public Client Client { get; set; }
}
```

#### Validation Rules
1. `ClientCode` must exist in `Client` entity
2. `AddressSequence` must be > 0
3. Combination of `ClientCode` + `AddressSequence` must be unique
4. `State` must be valid Brazilian UF code (e.g., 'SP', 'RJ', 'MG')
5. `PostalCode` must match Brazilian CEP format (NNNNN-NNN)
6. `AddressType` must be in `['R', 'C', 'P', 'O']` (Residential, Commercial, Postal, Other)

#### EF Core Configuration

```csharp
public class AddressConfiguration : IEntityTypeConfiguration<Address>
{
    public void Configure(EntityTypeBuilder<Address> builder)
    {
        builder.ToView("V0ENDERECOS");
        builder.HasKey(a => a.AddressId);

        builder.HasIndex(a => new { a.ClientCode, a.AddressSequence })
            .IsUnique()
            .HasDatabaseName("IX_V0ENDERECOS_ClientSequence");

        builder.HasIndex(a => a.State)
            .HasDatabaseName("IX_V0ENDERECOS_State");

        builder.HasOne(a => a.Client)
            .WithMany(c => c.Addresses)
            .HasForeignKey(a => a.ClientCode)
            .OnDelete(DeleteBehavior.Restrict);
    }
}
```

---

### 7. Agency (V0AGENCIAS)

**Purpose**: Sales agency/branch information for distribution channel tracking.

**COBOL Source**: `V0AGENCIAS` view, accessed at R1180-00-SELECT-V0AGENCIAS

#### Properties

```csharp
public class Agency
{
    [Key]
    [CobolField(PicClause = "9(4)", Length = 4)]
    public int AgencyCode { get; set; }  // COD_AGENC

    [CobolField(PicClause = "9(9)", Length = 9)]
    public int CompanyCode { get; set; }  // COD_EMP

    [CobolField(PicClause = "X(100)", Length = 100)]
    [MaxLength(100)]
    public string AgencyName { get; set; }  // NOM_AGENC

    [CobolField(PicClause = "9(4)", Length = 4)]
    public int RegionCode { get; set; }  // COD_REGIAO

    [CobolField(PicClause = "X(2)", Length = 2)]
    [MaxLength(2)]
    public string State { get; set; }  // COD_UF

    [CobolField(PicClause = "X(1)", Length = 1)]
    [MaxLength(1)]
    public string ChannelType { get; set; }  // TIP_CANAL ('A'=Agency, 'C'=Call Center, 'W'=Web, etc.)

    [CobolField(PicClause = "X(1)", Length = 1)]
    [MaxLength(1)]
    public string AgencyStatus { get; set; }  // IND_SITUACAO ('A'=Active, 'I'=Inactive)

    // Navigation Properties
    public ICollection<Policy> Policies { get; set; }
}
```

#### Validation Rules
1. `AgencyCode` must be unique per `CompanyCode`
2. `State` must be valid Brazilian UF code
3. `ChannelType` must be in `['A', 'C', 'W', 'P']` (Agency, Call Center, Web, Partner)
4. `AgencyStatus` must be in `['A', 'I']`

#### EF Core Configuration

```csharp
public class AgencyConfiguration : IEntityTypeConfiguration<Agency>
{
    public void Configure(EntityTypeBuilder<Agency> builder)
    {
        builder.ToView("V0AGENCIAS");
        builder.HasKey(a => a.AgencyCode);

        builder.HasIndex(a => new { a.CompanyCode, a.RegionCode })
            .HasDatabaseName("IX_V0AGENCIAS_Region");
    }
}
```

---

### 8. Producer (V0PRODUTOR)

**Purpose**: Insurance broker/producer information for commission tracking and distribution management.

**COBOL Source**: `V0PRODUTOR` view, accessed at R1200-00-SELECT-V0PRODUTOR

#### Properties

```csharp
public class Producer
{
    [Key]
    [CobolField(PicClause = "9(9)", Length = 9)]
    public int ProducerCode { get; set; }  // COD_PRODU

    [CobolField(PicClause = "9(9)", Length = 9)]
    public int CompanyCode { get; set; }  // COD_EMP

    [CobolField(PicClause = "X(100)", Length = 100)]
    [MaxLength(100)]
    public string ProducerName { get; set; }  // NOM_PRODU

    [CobolField(PicClause = "X(14)", Length = 14)]
    [MaxLength(14)]
    public string DocumentNumber { get; set; }  // NUM_CPF_CNPJ

    [CobolField(PicClause = "X(20)", Length = 20)]
    [MaxLength(20)]
    public string SusepRegistration { get; set; }  // NUM_REG_SUSEP

    [CobolField(PicClause = "9(4)V99", Length = 6, DecimalPlaces = 2, FieldType = CobolFieldType.PackedDecimal)]
    [Column(TypeName = "decimal(6,2)")]
    public decimal CommissionRate { get; set; }  // PCT_COMIS (percentage)

    [CobolField(PicClause = "X(1)", Length = 1)]
    [MaxLength(1)]
    public string ProducerType { get; set; }  // TIP_PRODU ('C'=Corretor, 'A'=Agenciador, 'I'=Indicador)

    [CobolField(PicClause = "X(1)", Length = 1)]
    [MaxLength(1)]
    public string ProducerStatus { get; set; }  // IND_SITUACAO ('A'=Active, 'I'=Inactive)

    // Navigation Properties
    public ICollection<Policy> Policies { get; set; }
}
```

#### Validation Rules
1. `ProducerCode` must be unique per `CompanyCode`
2. `DocumentNumber` must be valid CPF or CNPJ
3. `SusepRegistration` format must match SUSEP broker registration standards
4. `CommissionRate` must be between 0.00 and 100.00
5. `ProducerType` must be in `['C', 'A', 'I']` (Corretor, Agenciador, Indicador)

#### EF Core Configuration

```csharp
public class ProducerConfiguration : IEntityTypeConfiguration<Producer>
{
    public void Configure(EntityTypeBuilder<Producer> builder)
    {
        builder.ToView("V0PRODUTOR");
        builder.HasKey(p => p.ProducerCode);

        builder.HasIndex(p => p.SusepRegistration)
            .IsUnique()
            .HasDatabaseName("IX_V0PRODUTOR_SusepReg");
    }
}
```

---

### 9. Coverage (V0COBERAPOL)

**Purpose**: Policy coverage details including insured amounts, rates, and coverage-specific premiums.

**COBOL Source**: `V0COBERAPOL` view, accessed at sections R0850-00-SELECT-V0COBERAPOL, R1250-00-SELECT-V0COBERAPOL

#### Properties

```csharp
public class Coverage
{
    [Key]
    public long CoverageId { get; set; }

    [CobolField(PicClause = "9(13)", Length = 13, FieldType = CobolFieldType.PackedDecimal)]
    public long PolicyNumber { get; set; }  // NUM_APOLICE

    [CobolField(PicClause = "9(4)", Length = 4)]
    public int CoverageCode { get; set; }  // COD_COBER

    [CobolField(PicClause = "X(100)", Length = 100)]
    [MaxLength(100)]
    public string CoverageName { get; set; }  // NOM_COBER

    [CobolField(PicClause = "9(13)V99", Length = 15, DecimalPlaces = 2, FieldType = CobolFieldType.PackedDecimal)]
    [Column(TypeName = "decimal(15,2)")]
    public decimal InsuredAmount { get; set; }  // IMP_SEG

    [CobolField(PicClause = "9(4)V9999", Length = 8, DecimalPlaces = 4, FieldType = CobolFieldType.PackedDecimal)]
    [Column(TypeName = "decimal(8,4)")]
    public decimal Rate { get; set; }  // PCT_TAXA (per thousand or percentage)

    [CobolField(PicClause = "9(13)V99", Length = 15, DecimalPlaces = 2, FieldType = CobolFieldType.PackedDecimal)]
    [Column(TypeName = "decimal(15,2)")]
    public decimal TariffPremium { get; set; }  // VL_PRM_TAR

    [CobolField(PicClause = "X(1)", Length = 1)]
    [MaxLength(1)]
    public string CoverageType { get; set; }  // TIP_COBER ('B'=Basica, 'A'=Adicional)

    [CobolField(PicClause = "X(1)", Length = 1)]
    [MaxLength(1)]
    public string IsMandatory { get; set; }  // IND_OBRIGAT ('S'/'N')

    // Navigation Properties
    public Policy Policy { get; set; }
}
```

#### Validation Rules
1. `PolicyNumber` must exist in `Policy` entity
2. `InsuredAmount` must be > 0 for active coverages
3. `Rate` must be >= 0
4. `CoverageType` must be in `['B', 'A']` (Basica, Adicional)
5. `IsMandatory` must be 'S' or 'N'

#### EF Core Configuration

```csharp
public class CoverageConfiguration : IEntityTypeConfiguration<Coverage>
{
    public void Configure(EntityTypeBuilder<Coverage> builder)
    {
        builder.ToView("V0COBERAPOL");
        builder.HasKey(c => c.CoverageId);

        builder.HasIndex(c => new { c.PolicyNumber, c.CoverageCode })
            .IsUnique()
            .HasDatabaseName("IX_V0COBERAPOL_PolicyCoverage");

        builder.HasOne(c => c.Policy)
            .WithMany(p => p.Coverages)
            .HasForeignKey(c => c.PolicyNumber)
            .OnDelete(DeleteBehavior.Restrict);
    }
}
```

---

### 10. Invoice (V0FATURAS)

**Purpose**: Billing invoice information for premium collection tracking.

**COBOL Source**: `V0FATURAS` view, accessed at R1060-00-SELECT-V0FATURAS

#### Properties

```csharp
public class Invoice
{
    [Key]
    [CobolField(PicClause = "9(13)", Length = 13)]
    public long InvoiceNumber { get; set; }  // NUM_FATURA

    [CobolField(PicClause = "9(13)", Length = 13, FieldType = CobolFieldType.PackedDecimal)]
    public long PolicyNumber { get; set; }  // NUM_APOLICE

    [CobolField(PicClause = "9(9)", Length = 9)]
    public int EndorsementNumber { get; set; }  // NUM_ENDOS

    [CobolField(PicClause = "X(10)", Length = 10)]
    [MaxLength(10)]
    public string InvoiceDate { get; set; }  // DT_FATURA

    public DateTime InvoiceDateParsed => DateTime.ParseExact(InvoiceDate, "yyyy-MM-dd", CultureInfo.InvariantCulture);

    [CobolField(PicClause = "X(10)", Length = 10)]
    [MaxLength(10)]
    public string DueDate { get; set; }  // DT_VENCTO

    public DateTime DueDateParsed => DateTime.ParseExact(DueDate, "yyyy-MM-dd", CultureInfo.InvariantCulture);

    [CobolField(PicClause = "9(13)V99", Length = 15, DecimalPlaces = 2, FieldType = CobolFieldType.PackedDecimal)]
    [Column(TypeName = "decimal(15,2)")]
    public decimal InvoiceAmount { get; set; }  // VL_FATURA

    [CobolField(PicClause = "9(4)", Length = 4)]
    public int NumberOfInstallments { get; set; }  // QTD_PARCELAS

    [CobolField(PicClause = "X(1)", Length = 1)]
    [MaxLength(1)]
    public string PaymentStatus { get; set; }  // IND_SITUACAO ('A'=Aguardando, 'P'=Pago, 'V'=Vencido)

    // Navigation Properties
    public Policy Policy { get; set; }
    public ICollection<Installment> Installments { get; set; }
}
```

#### Validation Rules
1. `PolicyNumber` must exist in `Policy` entity
2. `DueDate` must be >= `InvoiceDate`
3. `InvoiceAmount` must be > 0
4. `NumberOfInstallments` must be >= 1
5. `PaymentStatus` must be in `['A', 'P', 'V', 'C']` (Aguardando, Pago, Vencido, Cancelado)

#### EF Core Configuration

```csharp
public class InvoiceConfiguration : IEntityTypeConfiguration<Invoice>
{
    public void Configure(EntityTypeBuilder<Invoice> builder)
    {
        builder.ToView("V0FATURAS");
        builder.HasKey(i => i.InvoiceNumber);

        builder.HasIndex(i => new { i.PolicyNumber, i.EndorsementNumber })
            .HasDatabaseName("IX_V0FATURAS_PolicyEndorsement");

        builder.HasOne(i => i.Policy)
            .WithMany()
            .HasForeignKey(i => i.PolicyNumber)
            .OnDelete(DeleteBehavior.Restrict);
    }
}
```

---

### 11. Installment (V0HISTOPARC)

**Purpose**: Premium installment payment history for tracking collection status.

**COBOL Source**: `V0HISTOPARC` view, accessed at R0800-00-SELECT-V0HISTOPARC

#### Properties

```csharp
public class Installment
{
    [Key]
    public long InstallmentId { get; set; }

    [CobolField(PicClause = "9(13)", Length = 13)]
    public long InvoiceNumber { get; set; }  // NUM_FATURA

    [CobolField(PicClause = "9(4)", Length = 4)]
    public int InstallmentNumber { get; set; }  // NUM_PARCELA

    [CobolField(PicClause = "X(10)", Length = 10)]
    [MaxLength(10)]
    public string DueDate { get; set; }  // DT_VENCTO

    public DateTime DueDateParsed => DateTime.ParseExact(DueDate, "yyyy-MM-dd", CultureInfo.InvariantCulture);

    [CobolField(PicClause = "X(10)", Length = 10)]
    [MaxLength(10)]
    public string PaymentDate { get; set; }  // DT_PAGTO

    public DateTime? PaymentDateParsed => string.IsNullOrWhiteSpace(PaymentDate)
        ? null
        : DateTime.ParseExact(PaymentDate, "yyyy-MM-dd", CultureInfo.InvariantCulture);

    [CobolField(PicClause = "9(13)V99", Length = 15, DecimalPlaces = 2, FieldType = CobolFieldType.PackedDecimal)]
    [Column(TypeName = "decimal(15,2)")]
    public decimal InstallmentAmount { get; set; }  // VL_PARCELA

    [CobolField(PicClause = "9(13)V99", Length = 15, DecimalPlaces = 2, FieldType = CobolFieldType.PackedDecimal)]
    [Column(TypeName = "decimal(15,2)")]
    public decimal AmountPaid { get; set; }  // VL_PAGO

    [CobolField(PicClause = "X(1)", Length = 1)]
    [MaxLength(1)]
    public string PaymentStatus { get; set; }  // IND_SITUACAO ('P'=Pago, 'A'=Aguardando, 'V'=Vencido)

    // Navigation Properties
    public Invoice Invoice { get; set; }
}
```

#### Validation Rules
1. `InvoiceNumber` must exist in `Invoice` entity
2. `InstallmentNumber` must be > 0 and <= `Invoice.NumberOfInstallments`
3. If `PaymentStatus` = 'P', `PaymentDate` must not be null
4. `AmountPaid` must be <= `InstallmentAmount`
5. `PaymentStatus` must be in `['P', 'A', 'V', 'C']`

#### EF Core Configuration

```csharp
public class InstallmentConfiguration : IEntityTypeConfiguration<Installment>
{
    public void Configure(EntityTypeBuilder<Installment> builder)
    {
        builder.ToView("V0HISTOPARC");
        builder.HasKey(i => i.InstallmentId);

        builder.HasIndex(i => new { i.InvoiceNumber, i.InstallmentNumber })
            .IsUnique()
            .HasDatabaseName("IX_V0HISTOPARC_InvoiceInstallment");

        builder.HasOne(i => i.Invoice)
            .WithMany(inv => inv.Installments)
            .HasForeignKey(i => i.InvoiceNumber)
            .OnDelete(DeleteBehavior.Restrict);
    }
}
```

---

### 12. CossuredPolicy (V0APOLCOSCED)

**Purpose**: Cossurance and ceded reinsurance policy arrangements where risk is shared among multiple insurers.

**COBOL Source**: `V0APOLCOSCED` view, cursor declared at R4900-00-DECLARE-V0APOLCOSCED, fetched at R5000-00-FETCH-V0APOLCOSCED

#### Properties

```csharp
public class CossuredPolicy
{
    [Key]
    public long CossuranceId { get; set; }

    [CobolField(PicClause = "9(13)", Length = 13, FieldType = CobolFieldType.PackedDecimal)]
    public long PolicyNumber { get; set; }  // NUM_APOLICE

    [CobolField(PicClause = "9(4)", Length = 4)]
    public int CossuranceCode { get; set; }  // COD_COSSG

    [CobolField(PicClause = "X(1)", Length = 1)]
    [MaxLength(1)]
    public string CossuranceType { get; set; }  // TIP_COSSG ('C'=Cosseguro, 'R'=Resseguro, 'E'=Retrocessao)

    [CobolField(PicClause = "9(9)", Length = 9)]
    public int CedingCompanyCode { get; set; }  // COD_CIA_CEDENTE

    [CobolField(PicClause = "9(9)", Length = 9)]
    public int AcquiringCompanyCode { get; set; }  // COD_CIA_CESSIONARIA

    [CobolField(PicClause = "9(4)V9(9)", Length = 14, DecimalPlaces = 9, FieldType = CobolFieldType.PackedDecimal)]
    [Column(TypeName = "decimal(13,9)")]
    public decimal PercentageShare { get; set; }  // PCT_PARTICIPACAO (0.000000001 to 1.000000000)

    [CobolField(PicClause = "9(13)V99", Length = 15, DecimalPlaces = 2, FieldType = CobolFieldType.PackedDecimal)]
    [Column(TypeName = "decimal(15,2)")]
    public decimal CededInsuredAmount { get; set; }  // IMP_SEG_CEDIDO

    [CobolField(PicClause = "9(13)V99", Length = 15, DecimalPlaces = 2, FieldType = CobolFieldType.PackedDecimal)]
    [Column(TypeName = "decimal(15,2)")]
    public decimal CededPremium { get; set; }  // VL_PRM_CEDIDO

    [CobolField(PicClause = "X(1)", Length = 1)]
    [MaxLength(1)]
    public string IsLeader { get; set; }  // IND_LIDER ('S'/'N' - for cossurance)

    // Navigation Properties
    public Policy Policy { get; set; }
}
```

#### Validation Rules
1. `PolicyNumber` must exist in `Policy` entity
2. `CossuranceType` must be in `['C', 'R', 'E']` (Cosseguro, Resseguro, Retrocessao)
3. `PercentageShare` must be > 0 and <= 1.0
4. `CededPremium` must be >= 0
5. `IsLeader` must be 'S' or 'N'

#### EF Core Configuration

```csharp
public class CossuredPolicyConfiguration : IEntityTypeConfiguration<CossuredPolicy>
{
    public void Configure(EntityTypeBuilder<CossuredPolicy> builder)
    {
        builder.ToView("V0APOLCOSCED");
        builder.HasKey(c => c.CossuranceId);

        builder.HasIndex(c => new { c.PolicyNumber, c.CossuranceCode })
            .HasDatabaseName("IX_V0APOLCOSCED_PolicyCossurance");

        builder.HasIndex(c => c.CossuranceType)
            .HasDatabaseName("IX_V0APOLCOSCED_Type");

        builder.HasOne(c => c.Policy)
            .WithMany()
            .HasForeignKey(c => c.PolicyNumber)
            .OnDelete(DeleteBehavior.Restrict);
    }
}
```

---

### 13. CossuranceCalculation (GE399)

**Purpose**: Detailed cossurance calculation data for quota distribution among cossurers.

**COBOL Source**: `GE399` table, cursor declared at R5300-00-DECLARE-GE399, fetched at R5400-00-FETCH-GE399

#### Properties

```csharp
public class CossuranceCalculation
{
    [Key]
    public long CalculationId { get; set; }

    [CobolField(PicClause = "9(13)", Length = 13, FieldType = CobolFieldType.PackedDecimal)]
    public long PolicyNumber { get; set; }  // NUM_APOLICE

    [CobolField(PicClause = "9(4)", Length = 4)]
    public int CossuranceCode { get; set; }  // COD_COSSG

    [CobolField(PicClause = "9(4)V9(9)", Length = 14, DecimalPlaces = 9, FieldType = CobolFieldType.PackedDecimal)]
    [Column(TypeName = "decimal(13,9)")]
    public decimal QuotaPercentage { get; set; }  // PCT_QUOTA

    [CobolField(PicClause = "9(13)V99", Length = 15, DecimalPlaces = 2, FieldType = CobolFieldType.PackedDecimal)]
    [Column(TypeName = "decimal(15,2)")]
    public decimal RetainedPremium { get; set; }  // VL_PRM_RETIDO

    [CobolField(PicClause = "9(13)V99", Length = 15, DecimalPlaces = 2, FieldType = CobolFieldType.PackedDecimal)]
    [Column(TypeName = "decimal(15,2)")]
    public decimal CededPremium { get; set; }  // VL_PRM_CEDIDO

    [CobolField(PicClause = "9(13)V99", Length = 15, DecimalPlaces = 2, FieldType = CobolFieldType.PackedDecimal)]
    [Column(TypeName = "decimal(15,2)")]
    public decimal CededCommission { get; set; }  // VL_COMIS_CEDIDA

    // Navigation Properties
    public Policy Policy { get; set; }
}
```

#### Validation Rules
1. `PolicyNumber` must exist in `Policy` entity
2. `QuotaPercentage` must be > 0 and <= 1.0
3. `RetainedPremium` + `CededPremium` should equal total premium (within tolerance)
4. All financial values must be >= 0

#### EF Core Configuration

```csharp
public class CossuranceCalculationConfiguration : IEntityTypeConfiguration<CossuranceCalculation>
{
    public void Configure(EntityTypeBuilder<CossuranceCalculation> builder)
    {
        builder.ToTable("GE399");
        builder.HasKey(c => c.CalculationId);

        builder.HasIndex(c => new { c.PolicyNumber, c.CossuranceCode })
            .HasDatabaseName("IX_GE399_PolicyCossurance");

        builder.HasOne(c => c.Policy)
            .WithMany()
            .HasForeignKey(c => c.PolicyNumber)
            .OnDelete(DeleteBehavior.Restrict);
    }
}
```

---

### 14. SystemConfiguration (V0SISTEMA)

**Purpose**: System configuration parameters including processing dates and system identifiers.

**COBOL Source**: `V0SISTEMA` view, accessed at R0100-00-SELECT-SISTEMAS

#### Properties

```csharp
public class SystemConfiguration
{
    [Key]
    [CobolField(PicClause = "X(2)", Length = 2)]
    [MaxLength(2)]
    public string SystemId { get; set; }  // IDE_SISTEMA (e.g., 'GL', 'RG')

    [CobolField(PicClause = "X(10)", Length = 10)]
    [MaxLength(10)]
    public string ProcessingDate { get; set; }  // DT_MOVABE (YYYY-MM-DD)

    public DateTime ProcessingDateParsed => DateTime.ParseExact(ProcessingDate, "yyyy-MM-dd", CultureInfo.InvariantCulture);

    [CobolField(PicClause = "X(100)", Length = 100)]
    [MaxLength(100)]
    public string SystemName { get; set; }  // NOM_SISTEMA

    [CobolField(PicClause = "X(1)", Length = 1)]
    [MaxLength(1)]
    public string SystemStatus { get; set; }  // IND_SITUACAO ('A'=Active, 'I'=Inactive)

    [CobolField(PicClause = "9(9)", Length = 9)]
    public int CompanyCode { get; set; }  // COD_EMP
}
```

#### Validation Rules
1. `SystemId` must be unique
2. `ProcessingDate` must be valid date
3. `SystemStatus` must be in `['A', 'I']`

#### EF Core Configuration

```csharp
public class SystemConfigurationConfiguration : IEntityTypeConfiguration<SystemConfiguration>
{
    public void Configure(EntityTypeBuilder<SystemConfiguration> builder)
    {
        builder.ToView("V0SISTEMA");
        builder.HasKey(s => s.SystemId);
    }
}
```

---

### 15. ReportDefinition (V0RELATORIOS)

**Purpose**: Report execution metadata including user, date range, and status tracking.

**COBOL Source**: `V0RELATORIOS` view, accessed at R0200-00-SELECT-V0RELATORIO, R0300-00-DELETE-V0RELATORIO

#### Properties

```csharp
public class ReportDefinition
{
    [Key]
    public long ReportId { get; set; }

    [CobolField(PicClause = "X(8)", Length = 8)]
    [MaxLength(8)]
    public string UserCode { get; set; }  // COD_USUARIO

    [CobolField(PicClause = "X(10)", Length = 10)]
    [MaxLength(10)]
    public string RequestDate { get; set; }  // DTA_SOLICTA

    public DateTime RequestDateParsed => DateTime.ParseExact(RequestDate, "yyyy-MM-dd", CultureInfo.InvariantCulture);

    [CobolField(PicClause = "X(2)", Length = 2)]
    [MaxLength(2)]
    public string SystemId { get; set; }  // IDE_SISTEMA

    [CobolField(PicClause = "X(8)", Length = 8)]
    [MaxLength(8)]
    public string ReportCode { get; set; }  // COD_RELAT

    [CobolField(PicClause = "X(10)", Length = 10)]
    [MaxLength(10)]
    public string PeriodStart { get; set; }  // PERI_INICIAL

    [CobolField(PicClause = "X(10)", Length = 10)]
    [MaxLength(10)]
    public string PeriodEnd { get; set; }  // PERI_FINAL

    [CobolField(PicClause = "9(4)", Length = 4)]
    public int ReferenceYear { get; set; }  // ANO_REFER

    [CobolField(PicClause = "9(4)", Length = 4)]
    public int ReferenceMonth { get; set; }  // MES_REFER

    [CobolField(PicClause = "X(10)", Length = 10)]
    [MaxLength(10)]
    public string ReferenceDate { get; set; }  // DATA_REFR
}
```

#### Validation Rules
1. `RequestDate` must be valid date
2. `PeriodStart` must be <= `PeriodEnd`
3. `ReferenceMonth` must be 1-12
4. `ReferenceYear` must be >= 2000

#### EF Core Configuration

```csharp
public class ReportDefinitionConfiguration : IEntityTypeConfiguration<ReportDefinition>
{
    public void Configure(EntityTypeBuilder<ReportDefinition> builder)
    {
        builder.ToView("V0RELATORIOS");
        builder.HasKey(r => r.ReportId);

        builder.HasIndex(r => new { r.SystemId, r.ReportCode, r.RequestDate })
            .HasDatabaseName("IX_V0RELATORIOS_Request");
    }
}
```

---

## Supporting Infrastructure

### Custom Attribute for COBOL Field Metadata

```csharp
[AttributeUsage(AttributeTargets.Property)]
public class CobolFieldAttribute : Attribute
{
    public string PicClause { get; set; }
    public int Length { get; set; }
    public int DecimalPlaces { get; set; }
    public CobolFieldType FieldType { get; set; } = CobolFieldType.Display;
}

public enum CobolFieldType
{
    Display,          // PIC X(n) or PIC 9(n) - standard display
    Numeric,          // PIC 9(n) COMP - binary integer
    PackedDecimal,    // PIC 9(n) COMP-3 - packed decimal
    SignedNumeric     // PIC S9(n) COMP - signed binary
}
```

### DbContext Configuration

```csharp
public class PremiumReportingDbContext : DbContext
{
    public DbSet<PremiumRecord> PremiumRecords { get; set; }
    public DbSet<Policy> Policies { get; set; }
    public DbSet<Endorsement> Endorsements { get; set; }
    public DbSet<Product> Products { get; set; }
    public DbSet<Client> Clients { get; set; }
    public DbSet<Address> Addresses { get; set; }
    public DbSet<Agency> Agencies { get; set; }
    public DbSet<Producer> Producers { get; set; }
    public DbSet<Coverage> Coverages { get; set; }
    public DbSet<Invoice> Invoices { get; set; }
    public DbSet<Installment> Installments { get; set; }
    public DbSet<CossuredPolicy> CossuredPolicies { get; set; }
    public DbSet<CossuranceCalculation> CossuranceCalculations { get; set; }
    public DbSet<SystemConfiguration> SystemConfigurations { get; set; }
    public DbSet<ReportDefinition> ReportDefinitions { get; set; }

    protected override void OnModelCreating(ModelBuilder modelBuilder)
    {
        modelBuilder.ApplyConfiguration(new PremiumRecordConfiguration());
        modelBuilder.ApplyConfiguration(new PolicyConfiguration());
        modelBuilder.ApplyConfiguration(new EndorsementConfiguration());
        modelBuilder.ApplyConfiguration(new ProductConfiguration());
        modelBuilder.ApplyConfiguration(new ClientConfiguration());
        modelBuilder.ApplyConfiguration(new AddressConfiguration());
        modelBuilder.ApplyConfiguration(new AgencyConfiguration());
        modelBuilder.ApplyConfiguration(new ProducerConfiguration());
        modelBuilder.ApplyConfiguration(new CoverageConfiguration());
        modelBuilder.ApplyConfiguration(new InvoiceConfiguration());
        modelBuilder.ApplyConfiguration(new InstallmentConfiguration());
        modelBuilder.ApplyConfiguration(new CossuredPolicyConfiguration());
        modelBuilder.ApplyConfiguration(new CossuranceCalculationConfiguration());
        modelBuilder.ApplyConfiguration(new SystemConfigurationConfiguration());
        modelBuilder.ApplyConfiguration(new ReportDefinitionConfiguration());
    }

    protected override void OnConfiguring(DbContextOptionsBuilder optionsBuilder)
    {
        if (!optionsBuilder.IsConfigured)
        {
            optionsBuilder.UseSqlite("Data Source=premium_reporting.db");
        }
    }
}
```

---

## Data Model Traceability Matrix

| Entity | COBOL View/Table | Cursor Processing | Primary COBOL Section | Key Relationships |
|--------|------------------|-------------------|----------------------|-------------------|
| PremiumRecord | V0PREMIOS | Yes (R0500, R0600) | R0700-00-PROCESSA-REGISTRO | Policy, Product, Client, Endorsement |
| Policy | V0APOLICE | No | R0980-00-SELECT-V0APOLICE | Product, Client, Agency, Producer |
| Endorsement | V0ENDOSSO | No | R0760-00-SELECT-V0ENDOSSO | Policy |
| Product | V0PRODUTO | No | R0740-00-SELECT-V0PRODUTO | None |
| Client | V0CLIENTE | No | R0960-00-SELECT-V0CLIENTE | Address |
| Address | V0ENDERECOS | Yes (R1230, R1240) | R1220-00-PROCESSA-UF-VIDA | Client |
| Agency | V0AGENCIAS | No | R1180-00-SELECT-V0AGENCIAS | None |
| Producer | V0PRODUTOR | No | R1200-00-SELECT-V0PRODUTOR | None |
| Coverage | V0COBERAPOL | No | R0850-00-SELECT-V0COBERAPOL | Policy |
| Invoice | V0FATURAS | No | R1060-00-SELECT-V0FATURAS | Policy, Installment |
| Installment | V0HISTOPARC | No | R0800-00-SELECT-V0HISTOPARC | Invoice |
| CossuredPolicy | V0APOLCOSCED | Yes (R4900, R5000) | R4700-00-PROCESSA-APOL-COSG | Policy |
| CossuranceCalculation | GE399 | Yes (R5300, R5400) | R5500-00-CALCULA-COSG-CED | Policy |
| SystemConfiguration | V0SISTEMA | No | R0100-00-SELECT-SISTEMAS | None |
| ReportDefinition | V0RELATORIOS | No | R0200-00-SELECT-V0RELATORIO | None |

---

## Next Steps

With the data model design complete, the next phase involves:

1. **Phase 1.2**: Generate API contracts (`/contracts/openapi.yaml`) with RESTful endpoints for report generation, query, and data management
2. **Phase 1.3**: Create `quickstart.md` developer onboarding guide
3. **Phase 1.4**: Update agent context with data model documentation

**Document Version**: 1.0
**Status**: ✅ Complete - Ready for Phase 1.2 (API Contract Design)
**Created**: October 22, 2025



### QUICKSTART.MD (Execution Scenarios)

# Developer Quickstart Guide: COBOL RG1866B to .NET 9 Migration

**Feature Branch**: `001-vamos-migrar-sistema`
**Created**: October 22, 2025
**Status**: Phase 1.3 - Developer Onboarding
**Version**: 1.0

## Table of Contents

1. [Introduction](#introduction)
2. [Prerequisites](#prerequisites)
3. [Project Structure](#project-structure)
4. [Getting Started](#getting-started)
5. [Development Workflow](#development-workflow)
6. [Running Tests](#running-tests)
7. [Database Management](#database-management)
8. [API Documentation](#api-documentation)
9. [Frontend Development](#frontend-development)
10. [Troubleshooting](#troubleshooting)
11. [Additional Resources](#additional-resources)

---

## Introduction

Welcome to the SUSEP Circular 360 Premium Reporting System migration project! This guide will help you get up and running quickly with the development environment.

### What We're Building

A modern full-stack application that replaces the legacy COBOL RG1866B batch program with:

- **.NET 9 Web API**: RESTful backend with Clean Architecture
- **React Frontend**: Interactive dashboard and report generation UI
- **SQLite Database**: Local development database mimicking DB2 structure
- **Byte-Level Compatibility**: Exact output matching for regulatory compliance

### Project Goals

1. **Functional Parity**: Replicate all COBOL business logic exactly
2. **Modern UX**: Replace batch processing with interactive web interface
3. **Regulatory Compliance**: Maintain SUSEP Circular 360 report format compatibility
4. **Developer Experience**: Clean architecture, comprehensive tests, clear documentation

---

## Prerequisites

### Required Software

| Software | Version | Purpose | Download |
|----------|---------|---------|----------|
| **.NET SDK** | 9.0+ | Backend development | https://dotnet.microsoft.com/download |
| **Node.js** | 20+ LTS | Frontend development | https://nodejs.org/ |
| **Git** | 2.40+ | Version control | https://git-scm.com/ |
| **VS Code** | Latest | Code editor (recommended) | https://code.visualstudio.com/ |

### Optional but Recommended

| Software | Version | Purpose | Download |
|----------|---------|---------|----------|
| **Docker Desktop** | Latest | Containerization | https://www.docker.com/products/docker-desktop |
| **Postman** | Latest | API testing | https://www.postman.com/ |
| **DB Browser for SQLite** | Latest | Database inspection | https://sqlitebrowser.org/ |

### VS Code Extensions

Install these extensions for optimal development experience:

```bash
# C# Development
code --install-extension ms-dotnettools.csharp
code --install-extension ms-dotnettools.csdevkit

# React/TypeScript Development
code --install-extension dbaeumer.vscode-eslint
code --install-extension esbenp.prettier-vscode
code --install-extension bradlc.vscode-tailwindcss

# REST API Testing
code --install-extension humao.rest-client

# Git Integration
code --install-extension eamodio.gitlens
```

### Verify Prerequisites

Run these commands to verify your environment:

```bash
# .NET SDK
dotnet --version
# Expected: 9.0.0 or higher

# Node.js
node --version
# Expected: v20.0.0 or higher

# npm
npm --version
# Expected: 10.0.0 or higher

# Git
git --version
# Expected: 2.40.0 or higher
```

---

## Project Structure

The repository follows Clean Architecture principles with clear separation between backend, frontend, and specifications:

```
POC Cobol/
├── specs/                                  # Feature specifications (SpecKit)
│   └── 001-vamos-migrar-sistema/
│       ├── spec.md                         # Feature specification
│       ├── plan.md                         # Implementation plan
│       ├── research.md                     # Technical research
│       ├── data-model.md                   # Entity definitions
│       ├── quickstart.md                   # This file
│       ├── tasks.md                        # Implementation tasks (generated)
│       ├── contracts/
│       │   ├── openapi.yaml               # API specification
│       │   └── schemas/README.md          # API documentation
│       └── checklists/
│           └── requirements.md            # Quality validation
│
├── backend/                               # .NET 9 Backend
│   ├── CaixaSeguradora.sln               # Solution file
│   ├── src/
│   │   ├── CaixaSeguradora.Api/          # Web API layer
│   │   │   ├── Controllers/              # REST API controllers
│   │   │   ├── Program.cs                # Application entry point
│   │   │   ├── appsettings.json          # Configuration
│   │   │   └── appsettings.Development.json
│   │   │
│   │   ├── CaixaSeguradora.Core/         # Domain layer (Clean Architecture)
│   │   │   ├── Entities/                 # Domain entities
│   │   │   ├── Interfaces/               # Repository & service contracts
│   │   │   ├── Services/                 # Domain services
│   │   │   └── Attributes/               # CobolFieldAttribute, etc.
│   │   │
│   │   └── CaixaSeguradora.Infrastructure/ # Infrastructure layer
│   │       ├── Data/                     # EF Core DbContext
│   │       ├── Repositories/             # Repository implementations
│   │       ├── Services/                 # External service adapters
│   │       └── Formatters/               # FixedWidthFormatter, etc.
│   │
│   └── tests/
│       ├── CaixaSeguradora.UnitTests/    # Unit tests
│       ├── CaixaSeguradora.IntegrationTests/ # Integration tests
│       └── CaixaSeguradora.ComparisonTests/  # COBOL vs .NET validation
│
├── frontend/                              # React Frontend
│   ├── package.json                      # npm dependencies
│   ├── vite.config.ts                    # Vite configuration
│   ├── tailwind.config.js                # TailwindCSS config (Caixa branding)
│   ├── src/
│   │   ├── components/                   # React components
│   │   │   ├── dashboard/               # Dashboard components
│   │   │   ├── reports/                 # Report generation UI
│   │   │   └── query/                   # Data query UI
│   │   ├── pages/                       # Page components
│   │   ├── services/                    # API client layer
│   │   ├── styles/                      # Global styles
│   │   └── App.tsx                      # Root component
│   │
│   └── public/                          # Static assets
│
├── docs/                                 # Documentation
│   └── parser/                          # COBOL parser analysis
│       ├── FINAL-ANALYSIS-REPORT.md     # Complete program analysis
│       ├── INDEX.md                     # Documentation index
│       └── copybooks/
│           └── RG1866B_unix.cbl         # COBOL source code
│
└── CLAUDE.md                            # Project guide for Claude Code

```

### Key Directories

- **`specs/`**: Feature specifications following SpecKit methodology
- **`backend/src/`**: .NET 9 backend with Clean Architecture (Api → Core → Infrastructure)
- **`frontend/src/`**: React 18+ frontend with TypeScript and TailwindCSS
- **`docs/parser/`**: COBOL program analysis and legacy source code
- **`tests/`**: Comprehensive test suite (unit, integration, comparison)

---

## Getting Started

### 1. Clone the Repository

```bash
# Clone the repository
git clone <repository-url>
cd "POC Cobol"

# Checkout the feature branch
git checkout 001-vamos-migrar-sistema
```

### 2. Backend Setup

#### Install Dependencies

```bash
cd backend

# Restore NuGet packages
dotnet restore

# Verify build
dotnet build --configuration Debug
```

#### Configure Database

The application uses SQLite for local development. The database file will be created automatically on first run.

```bash
# Navigate to API project
cd src/CaixaSeguradora.Api

# Apply migrations (creates database schema)
dotnet ef database update

# Load sample mock data (optional)
dotnet run --seed-data
```

#### Run Backend API

```bash
# From backend/src/CaixaSeguradora.Api/
dotnet run

# Or with hot reload
dotnet watch run
```

**Expected Output**:
```
info: Microsoft.Hosting.Lifetime[14]
      Now listening on: https://localhost:5001
info: Microsoft.Hosting.Lifetime[14]
      Now listening on: http://localhost:5000
info: Microsoft.Hosting.Lifetime[0]
      Application started. Press Ctrl+C to shut down.
```

**Swagger UI**: Open https://localhost:5001/swagger in your browser

### 3. Frontend Setup

#### Install Dependencies

```bash
# From project root
cd frontend

# Install npm packages
npm install
```

#### Configure Environment

Create `.env.local` file for local development:

```bash
# frontend/.env.local
VITE_API_BASE_URL=https://localhost:5001/api/v1
VITE_APP_NAME="SUSEP Premium Reporting"
VITE_ENABLE_MOCK_DATA=true
```

#### Run Frontend Development Server

```bash
# From frontend/
npm run dev
```

**Expected Output**:
```
VITE v5.0.0  ready in 423 ms

➜  Local:   http://localhost:5173/
➜  Network: use --host to expose
➜  press h + enter to show help
```

**Dashboard**: Open http://localhost:5173 in your browser

### 4. Verify Setup

#### Test Backend API

```bash
# Health check
curl https://localhost:5001/api/v1/system/health

# Expected: {"status":"healthy","timestamp":"..."}

# Get dashboard metrics
curl https://localhost:5001/api/v1/dashboard/metrics

# Expected: JSON with program info, data structure, complexity metrics
```

#### Test Frontend

1. Navigate to http://localhost:5173
2. Verify dashboard loads with migration metrics
3. Check that all sections display data (Program Info, Data Structure, Complexity)

---

## Development Workflow

### Daily Development Cycle

```bash
# 1. Pull latest changes
git pull origin 001-vamos-migrar-sistema

# 2. Start backend (Terminal 1)
cd backend/src/CaixaSeguradora.Api
dotnet watch run

# 3. Start frontend (Terminal 2)
cd frontend
npm run dev

# 4. Make code changes
# Edit files in VS Code

# 5. Run tests
dotnet test                    # Backend tests
npm run test                   # Frontend tests

# 6. Commit changes
git add .
git commit -m "feat: add premium query filtering"
git push origin 001-vamos-migrar-sistema
```

### Git Workflow

We follow **trunk-based development** with short-lived feature branches:

```bash
# Create feature branch from main feature branch
git checkout 001-vamos-migrar-sistema
git checkout -b feature/premium-statistics

# Make changes and commit
git add .
git commit -m "feat: implement premium statistics endpoint"

# Push and create pull request
git push origin feature/premium-statistics
```

#### Commit Message Convention

Follow [Conventional Commits](https://www.conventionalcommits.org/):

```
feat: add new feature
fix: bug fix
docs: documentation changes
style: code formatting (no logic change)
refactor: code refactoring
test: add or update tests
chore: build/config changes
```

**Examples**:
```bash
git commit -m "feat: add PREMIT report generation endpoint"
git commit -m "fix: correct decimal precision in premium calculations"
git commit -m "test: add comparison tests for COBOL output validation"
git commit -m "docs: update API documentation with cossurance examples"
```

### Code Style

#### Backend (C#)

- **Naming**: PascalCase for classes/methods, camelCase for variables
- **Formatting**: Use `dotnet format` (configured in `.editorconfig`)
- **Architecture**: Follow Clean Architecture - no business logic in controllers
- **Error Handling**: Always log errors with Serilog before throwing

```csharp
// Good: Clean Architecture separation
public class PremiumController : ControllerBase
{
    private readonly IPremiumService _premiumService;

    [HttpGet("{id}")]
    public async Task<ActionResult<PremiumRecord>> GetPremium(long id)
    {
        var premium = await _premiumService.GetByIdAsync(id);
        if (premium == null)
            return NotFound();
        return Ok(premium);
    }
}

// Good: Decimal precision for financial calculations
[CobolField(PicClause = "9(13)V99", DecimalPlaces = 2)]
public decimal TotalPremiumAmount { get; set; }  // Use decimal, not double!

// Bad: Business logic in controller
public ActionResult Calculate()
{
    var result = premium * rate;  // ❌ Move to service layer
    return Ok(result);
}
```

#### Frontend (TypeScript/React)

- **Naming**: PascalCase for components, camelCase for functions/variables
- **Formatting**: Use Prettier (configured in `.prettierrc`)
- **Components**: Functional components with hooks
- **Styling**: TailwindCSS utility classes (avoid inline styles)

```tsx
// Good: Functional component with TypeScript
interface PremiumCardProps {
  premium: PremiumRecord;
  onSelect: (id: number) => void;
}

export const PremiumCard: React.FC<PremiumCardProps> = ({ premium, onSelect }) => {
  return (
    <div className="rounded-lg border border-gray-200 p-4 hover:shadow-md">
      <h3 className="text-lg font-semibold text-caixa-blue">
        Apólice {premium.policyNumber}
      </h3>
      <p className="text-gray-600">
        Prêmio: R$ {premium.totalPremiumAmount.toFixed(2)}
      </p>
      <button
        onClick={() => onSelect(premium.premiumId)}
        className="mt-2 rounded bg-caixa-blue px-4 py-2 text-white hover:bg-caixa-blue-dark"
      >
        Ver Detalhes
      </button>
    </div>
  );
};

// Good: Use TypeScript interfaces for API responses
interface ApiResponse<T> {
  data: T;
  pagination?: PaginationInfo;
}
```

---

## Running Tests

### Backend Tests

```bash
# Run all tests
cd backend
dotnet test

# Run with detailed output
dotnet test --logger "console;verbosity=detailed"

# Run specific test project
dotnet test tests/CaixaSeguradora.UnitTests/

# Run with coverage
dotnet test /p:CollectCoverage=true /p:CoverageReportFormat=html
# Coverage report: tests/*/coverage/index.html
```

#### Test Categories

**Unit Tests**: Test individual components in isolation
```bash
dotnet test --filter Category=Unit
```

**Integration Tests**: Test database and external dependencies
```bash
dotnet test --filter Category=Integration
```

**Comparison Tests**: Validate COBOL vs .NET output
```bash
dotnet test --filter Category=Comparison
```

### Frontend Tests

```bash
cd frontend

# Run unit tests (Vitest)
npm run test

# Run with watch mode
npm run test:watch

# Run with coverage
npm run test:coverage

# Run E2E tests (Playwright)
npm run test:e2e

# Run E2E in UI mode
npm run test:e2e:ui
```

### Test Data

Use mock data for development and testing:

```bash
# Load mock premium data
curl -X POST https://localhost:5001/api/v1/mock-data/load \
  -F "file=@test-data/premiums.csv" \
  -F "entityType=premiums"

# Validate loaded data
curl -X POST https://localhost:5001/api/v1/mock-data/validate

# Reset database to clean state
curl -X POST https://localhost:5001/api/v1/mock-data/reset
```

---

## Database Management

### Entity Framework Core Migrations

#### Create Migration

```bash
cd backend/src/CaixaSeguradora.Api

# Create new migration
dotnet ef migrations add AddPremiumIndexes

# Review generated migration in Migrations/ folder
```

#### Apply Migrations

```bash
# Update database to latest migration
dotnet ef database update

# Update to specific migration
dotnet ef database update AddPremiumIndexes

# Rollback to previous migration
dotnet ef database update PreviousMigrationName
```

#### View Migration SQL

```bash
# Generate SQL script
dotnet ef migrations script > migration.sql

# Generate SQL for specific range
dotnet ef migrations script FromMigration ToMigration > migration.sql
```

### Inspect Database

Use DB Browser for SQLite to inspect the database:

```bash
# Database location
backend/src/CaixaSeguradora.Api/premium_reporting.db
```

**Useful Queries**:

```sql
-- Count premium records
SELECT COUNT(*) FROM V0PREMIOS;

-- Check data distribution by month
SELECT ReferenceYear, ReferenceMonth, COUNT(*) as RecordCount
FROM V0PREMIOS
GROUP BY ReferenceYear, ReferenceMonth
ORDER BY ReferenceYear DESC, ReferenceMonth DESC;

-- Verify foreign key integrity
SELECT COUNT(*) FROM V0PREMIOS p
LEFT JOIN V0APOLICE a ON p.PolicyNumber = a.PolicyNumber
WHERE a.PolicyNumber IS NULL;
```

---

## API Documentation

### Swagger/OpenAPI

When the backend is running, access interactive API documentation at:

**Swagger UI**: https://localhost:5001/swagger

Features:
- Browse all endpoints
- View request/response schemas
- Execute API calls directly from browser
- Download OpenAPI spec

### Testing API with Postman

1. Import OpenAPI spec into Postman:
   - File → Import → `specs/001-vamos-migrar-sistema/contracts/openapi.yaml`

2. Set environment variables:
   - `baseUrl`: `https://localhost:5001/api/v1`
   - `bearerToken`: (JWT token from authentication)

3. Test common workflows:
   - Generate report
   - Query premiums
   - View policy details

### Testing API with curl

```bash
# Generate report
curl -X POST https://localhost:5001/api/v1/reports/generate \
  -H "Content-Type: application/json" \
  -d '{
    "startDate": "2025-10-01",
    "endDate": "2025-10-31",
    "reportTypes": ["PREMIT"],
    "systemId": "GL",
    "processingMode": "MONTHLY"
  }'

# Get report status
curl https://localhost:5001/api/v1/reports/{reportId}

# Query premiums
curl "https://localhost:5001/api/v1/premiums?page=1&pageSize=20&startDate=2025-10-01"

# Get dashboard metrics
curl https://localhost:5001/api/v1/dashboard/metrics
```

---

## Frontend Development

### Project Structure

```
frontend/src/
├── components/           # Reusable components
│   ├── dashboard/       # Dashboard-specific components
│   ├── reports/         # Report generation components
│   ├── query/           # Query builder components
│   └── common/          # Shared UI components
├── pages/               # Page components (routes)
│   ├── DashboardPage.tsx
│   ├── ReportPage.tsx
│   └── QueryPage.tsx
├── services/            # API client layer
│   ├── apiClient.ts     # Axios instance
│   ├── premiumService.ts
│   ├── reportService.ts
│   └── types.ts         # TypeScript interfaces
├── hooks/               # Custom React hooks
├── utils/               # Utility functions
└── App.tsx              # Root component
```

### TailwindCSS with Caixa Branding

Custom color palette configured in `tailwind.config.js`:

```javascript
module.exports = {
  theme: {
    extend: {
      colors: {
        caixa: {
          blue: {
            DEFAULT: '#0047BB',
            dark: '#003380',
            light: '#E6F0FF',
          },
          yellow: {
            DEFAULT: '#FFB81C',
            dark: '#E6A519',
          },
        },
      },
    },
  },
};
```

**Usage in components**:

```tsx
<div className="bg-caixa-blue text-white">Caixa Seguradora</div>
<button className="bg-caixa-yellow hover:bg-caixa-yellow-dark">Gerar Relatório</button>
```

### API Integration

Use generated TypeScript client from OpenAPI spec:

```bash
# Generate client (run once, or after API changes)
cd frontend
npm run generate-api-client
```

**Example usage**:

```tsx
import { premiumService } from '@/services/premiumService';

// Query premiums
const { data } = await premiumService.queryPremiums({
  startDate: '2025-10-01',
  endDate: '2025-10-31',
  page: 1,
  pageSize: 20,
});

console.log(data.premiums);
console.log(data.pagination.totalRecords);
```

### State Management

Use React hooks for local state, React Query for server state:

```tsx
import { useQuery } from '@tanstack/react-query';
import { premiumService } from '@/services/premiumService';

export const PremiumList = () => {
  const { data, isLoading, error } = useQuery({
    queryKey: ['premiums', { page: 1 }],
    queryFn: () => premiumService.queryPremiums({ page: 1, pageSize: 20 }),
  });

  if (isLoading) return <Spinner />;
  if (error) return <ErrorMessage error={error} />;

  return (
    <div>
      {data.premiums.map(premium => (
        <PremiumCard key={premium.premiumId} premium={premium} />
      ))}
    </div>
  );
};
```

---

## Troubleshooting

### Common Issues

#### Backend Won't Start

**Error**: `Unable to bind to https://localhost:5001`

**Solution**: Port already in use
```bash
# Find process using port
lsof -i :5001

# Kill process
kill -9 <PID>

# Or use different port
dotnet run --urls "https://localhost:5002"
```

**Error**: `No such file or directory: premium_reporting.db`

**Solution**: Run migrations
```bash
cd backend/src/CaixaSeguradora.Api
dotnet ef database update
```

#### Frontend Build Errors

**Error**: `Module not found: Can't resolve '@/services/...'`

**Solution**: Path alias issue
```bash
# Verify tsconfig.json has path mappings
{
  "compilerOptions": {
    "paths": {
      "@/*": ["./src/*"]
    }
  }
}

# Restart dev server
npm run dev
```

**Error**: `PostCSS plugin tailwindcss requires PostCSS 8`

**Solution**: Reinstall dependencies
```bash
rm -rf node_modules package-lock.json
npm install
```

#### Database Issues

**Error**: `SqliteException: database is locked`

**Solution**: Close other connections
```bash
# Close DB Browser for SQLite
# Restart backend API
```

**Error**: `Foreign key constraint failed`

**Solution**: Load data in correct order
```bash
# Load in dependency order:
# 1. Products, Clients, Agencies, Producers
# 2. Policies
# 3. Endorsements, Coverages
# 4. Premiums
```

### Debug Mode

#### Backend Debugging (VS Code)

Create `.vscode/launch.json`:

```json
{
  "version": "0.2.0",
  "configurations": [
    {
      "name": ".NET Core Launch (web)",
      "type": "coreclr",
      "request": "launch",
      "preLaunchTask": "build",
      "program": "${workspaceFolder}/backend/src/CaixaSeguradora.Api/bin/Debug/net9.0/CaixaSeguradora.Api.dll",
      "args": [],
      "cwd": "${workspaceFolder}/backend/src/CaixaSeguradora.Api",
      "env": {
        "ASPNETCORE_ENVIRONMENT": "Development"
      }
    }
  ]
}
```

Set breakpoints and press F5 to debug.

#### Frontend Debugging

Use browser DevTools:
- Chrome: F12 → Sources tab
- Set breakpoints in TypeScript files
- Use `debugger;` statement to break

### Logging

#### Backend Logs

Serilog configured in `appsettings.json`:

```json
{
  "Serilog": {
    "MinimumLevel": {
      "Default": "Information",
      "Override": {
        "Microsoft": "Warning",
        "System": "Warning"
      }
    }
  }
}
```

**View logs**:
```bash
# Console output during development
dotnet watch run

# Production logs (if using Seq)
# Open http://localhost:5341
```

#### Frontend Logs

Console logging with levels:

```typescript
console.log('Info message');
console.warn('Warning message');
console.error('Error message');

// Production: Logs sent to monitoring service
```

---

## Additional Resources

### Documentation

- **Feature Specification**: `specs/001-vamos-migrar-sistema/spec.md`
- **Implementation Plan**: `specs/001-vamos-migrar-sistema/plan.md`
- **Technical Research**: `specs/001-vamos-migrar-sistema/research.md`
- **Data Model**: `specs/001-vamos-migrar-sistema/data-model.md`
- **API Documentation**: `specs/001-vamos-migrar-sistema/contracts/schemas/README.md`
- **COBOL Analysis**: `docs/parser/FINAL-ANALYSIS-REPORT.md`

### External Resources

#### .NET 9

- [ASP.NET Core Documentation](https://learn.microsoft.com/en-us/aspnet/core/)
- [Entity Framework Core](https://learn.microsoft.com/en-us/ef/core/)
- [Clean Architecture Guide](https://learn.microsoft.com/en-us/dotnet/architecture/modern-web-apps-azure/)

#### React

- [React Documentation](https://react.dev/)
- [TypeScript Handbook](https://www.typescriptlang.org/docs/)
- [TailwindCSS Documentation](https://tailwindcss.com/docs)
- [React Query (TanStack Query)](https://tanstack.com/query/latest)

#### Tools

- [Postman Learning Center](https://learning.postman.com/)
- [Git Documentation](https://git-scm.com/doc)
- [VS Code Tips](https://code.visualstudio.com/docs/getstarted/tips-and-tricks)

### Team Communication

- **Slack Channel**: #susep-migration
- **Stand-up**: Daily at 9:30 AM
- **Sprint Planning**: Every 2 weeks on Monday
- **Code Review**: All PRs require 1 approval

### Getting Help

1. **Check Documentation**: Start with this quickstart and referenced docs
2. **Search Issues**: Check GitHub issues for similar problems
3. **Ask Team**: Post in #susep-migration Slack channel
4. **Create Issue**: If bug or feature request, create GitHub issue with:
   - Clear description
   - Steps to reproduce (for bugs)
   - Expected vs actual behavior
   - Environment details (OS, .NET version, etc.)

---

## Quick Reference Commands

### Backend

```bash
# Build
dotnet build

# Run
dotnet run
dotnet watch run    # with hot reload

# Test
dotnet test
dotnet test --filter Category=Unit

# Format
dotnet format

# Migrations
dotnet ef migrations add MigrationName
dotnet ef database update
```

### Frontend

```bash
# Install
npm install

# Run
npm run dev

# Test
npm run test
npm run test:e2e

# Build
npm run build
npm run preview     # preview production build

# Lint
npm run lint
npm run lint:fix
```

### Git

```bash
# Status
git status

# Commit
git add .
git commit -m "feat: description"

# Push
git push origin 001-vamos-migrar-sistema

# Pull latest
git pull origin 001-vamos-migrar-sistema

# Create feature branch
git checkout -b feature/branch-name
```

---

## Next Steps

Now that your environment is set up:

1. ✅ **Familiarize with Codebase**: Browse `specs/` documentation
2. ✅ **Run Application**: Start backend and frontend, verify dashboard loads
3. ✅ **Review Tasks**: Check `specs/001-vamos-migrar-sistema/tasks.md` (after Phase 2)
4. ✅ **Pick First Task**: Start with smallest, well-defined task
5. ✅ **Create Feature Branch**: Branch from `001-vamos-migrar-sistema`
6. ✅ **Implement, Test, Commit**: Follow development workflow
7. ✅ **Create Pull Request**: Request code review

**Welcome to the team! Happy coding! 🚀**

---

**Document Version**: 1.0
**Status**: ✅ Complete - Ready for Phase 1.4 (Agent Context Update)
**Created**: October 22, 2025



### TASKS.MD (Execution Plan)

# Tasks: COBOL RG1866B to .NET 9 React Migration

**Input**: Design documents from `/specs/001-vamos-migrar-sistema/`
**Prerequisites**: plan.md, spec.md, research.md, data-model.md, contracts/openapi.yaml, quickstart.md

**Tests**: NOT requested in specification - following FR-030 which requires unit tests for critical calculation logic only

**Organization**: Tasks are grouped by user story to enable independent implementation and testing of each story.

## Format: `[ID] [P?] [Story] Description`

- **[P]**: Can run in parallel (different files, no dependencies)
- **[Story]**: Which user story this task belongs to (e.g., US1, US2, US3, US4, US5)
- Include exact file paths in descriptions

## Path Conventions

- **Backend**: `backend/src/` (ASP.NET Core Web API structure)
- **Frontend**: `frontend/src/` (React + Vite structure)
- **Tests**: `backend/tests/` and `frontend/tests/`

---

## Phase 1: Setup (Shared Infrastructure)

**Purpose**: Project initialization and basic structure per plan.md

- [x] T001 Create .NET solution structure at `backend/CaixaSeguradora.sln` with three projects (Api, Core, Infrastructure)
- [x] T002 [P] Initialize CaixaSeguradora.Api project with ASP.NET Core Web API 9.0 in `backend/src/CaixaSeguradora.Api/`
- [x] T003 [P] Initialize CaixaSeguradora.Core project (class library) in `backend/src/CaixaSeguradora.Core/`
- [x] T004 [P] Initialize CaixaSeguradora.Infrastructure project (class library) in `backend/src/CaixaSeguradora.Infrastructure/`
- [x] T005 [P] Initialize test project CaixaSeguradora.UnitTests in `backend/tests/CaixaSeguradora.UnitTests/`
- [x] T006 [P] Initialize test project CaixaSeguradora.IntegrationTests in `backend/tests/CaixaSeguradora.IntegrationTests/`
- [x] T007 [P] Initialize test project CaixaSeguradora.ComparisonTests in `backend/tests/CaixaSeguradora.ComparisonTests/`
- [x] T008 Add NuGet packages to Api project (Swashbuckle, Serilog, AutoMapper)
- [ ] T009 [P] Add NuGet packages to Core project (no external dependencies per Clean Architecture)
- [ ] T010 [P] Add NuGet packages to Infrastructure project (EF Core 9.0, SQLite provider, System.Text.Json)
- [ ] T011 [P] Add NuGet packages to test projects (xUnit, FluentAssertions, Moq, Microsoft.AspNetCore.Mvc.Testing)
- [ ] T012 Create React + Vite + TypeScript project structure in `frontend/` using `npm create vite@latest`
- [ ] T013 [P] Install frontend dependencies (React Router 6+, Axios, Recharts, TailwindCSS) in `frontend/package.json`
- [ ] T014 [P] Configure TailwindCSS with Caixa Seguradora branding in `frontend/tailwind.config.js` (colors from research.md R6)
- [ ] T015 [P] Configure ESLint and Prettier for frontend in `frontend/.eslintrc.json` and `frontend/.prettierrc`
- [ ] T016 [P] Configure .NET code formatting (.editorconfig) in `backend/` per quickstart.md guidelines
- [ ] T017 [P] Create `backend/.gitignore` for .NET projects (bin/, obj/, *.db)
- [ ] T018 [P] Create `frontend/.gitignore` for Node projects (node_modules/, dist/)
- [ ] T019 [P] Create Docker Compose file in `docker-compose.yml` for development environment
- [ ] T020 Verify all projects build successfully (dotnet build, npm run build)

---

## Phase 2: Foundational (Blocking Prerequisites)

**Purpose**: Core infrastructure that MUST be complete before ANY user story can be implemented

**⚠️ CRITICAL**: No user story work can begin until this phase is complete

### Database Foundation

- [ ] T021 Create CobolFieldAttribute in `backend/src/CaixaSeguradora.Core/Attributes/CobolFieldAttribute.cs` (from research.md R1)
- [ ] T022 Create CobolFieldType enum in `backend/src/CaixaSeguradora.Core/Attributes/CobolFieldType.cs`
- [ ] T023 Create PremiumReportingDbContext in `backend/src/CaixaSeguradora.Infrastructure/Data/PremiumReportingDbContext.cs`
- [ ] T024 Configure SQLite connection string in `backend/src/CaixaSeguradora.Api/appsettings.json`
- [ ] T025 Configure SQLite connection string for development in `backend/src/CaixaSeguradora.Api/appsettings.Development.json`
- [ ] T026 Add EF Core design-time services in `backend/src/CaixaSeguradora.Api/Program.cs`
- [ ] T027 Create initial EF Core migration for database schema in `backend/src/CaixaSeguradora.Infrastructure/Migrations/`

### Core Domain Entities (from data-model.md)

- [ ] T028 [P] Create PremiumRecord entity in `backend/src/CaixaSeguradora.Core/Entities/PremiumRecord.cs` with all 687 COBOL data items mapped
- [ ] T029 [P] Create Policy entity in `backend/src/CaixaSeguradora.Core/Entities/Policy.cs`
- [ ] T030 [P] Create Endorsement entity in `backend/src/CaixaSeguradora.Core/Entities/Endorsement.cs`
- [ ] T031 [P] Create Product entity in `backend/src/CaixaSeguradora.Core/Entities/Product.cs`
- [ ] T032 [P] Create Client entity in `backend/src/CaixaSeguradora.Core/Entities/Client.cs`
- [ ] T033 [P] Create Address entity in `backend/src/CaixaSeguradora.Core/Entities/Address.cs`
- [ ] T034 [P] Create Agency entity in `backend/src/CaixaSeguradora.Core/Entities/Agency.cs`
- [ ] T035 [P] Create Producer entity in `backend/src/CaixaSeguradora.Core/Entities/Producer.cs`
- [ ] T036 [P] Create Coverage entity in `backend/src/CaixaSeguradora.Core/Entities/Coverage.cs`
- [ ] T037 [P] Create Invoice entity in `backend/src/CaixaSeguradora.Core/Entities/Invoice.cs`
- [ ] T038 [P] Create Installment entity in `backend/src/CaixaSeguradora.Core/Entities/Installment.cs`
- [ ] T039 [P] Create CossuredPolicy entity in `backend/src/CaixaSeguradora.Core/Entities/CossuredPolicy.cs`
- [ ] T040 [P] Create CossuranceCalculation entity in `backend/src/CaixaSeguradora.Core/Entities/CossuranceCalculation.cs`
- [ ] T041 [P] Create SystemConfiguration entity in `backend/src/CaixaSeguradora.Core/Entities/SystemConfiguration.cs`
- [ ] T042 [P] Create ReportDefinition entity in `backend/src/CaixaSeguradora.Core/Entities/ReportDefinition.cs`

### Entity Configurations (EF Core Fluent API)

- [ ] T043 [P] Create PremiumRecordConfiguration in `backend/src/CaixaSeguradora.Infrastructure/Data/Configurations/PremiumRecordConfiguration.cs`
- [ ] T044 [P] Create PolicyConfiguration in `backend/src/CaixaSeguradora.Infrastructure/Data/Configurations/PolicyConfiguration.cs`
- [ ] T045 [P] Create EndorsementConfiguration in `backend/src/CaixaSeguradora.Infrastructure/Data/Configurations/EndorsementConfiguration.cs`
- [ ] T046 [P] Create ProductConfiguration in `backend/src/CaixaSeguradora.Infrastructure/Data/Configurations/ProductConfiguration.cs`
- [ ] T047 [P] Create ClientConfiguration in `backend/src/CaixaSeguradora.Infrastructure/Data/Configurations/ClientConfiguration.cs`
- [ ] T048 [P] Create AddressConfiguration in `backend/src/CaixaSeguradora.Infrastructure/Data/Configurations/AddressConfiguration.cs`
- [ ] T049 [P] Create AgencyConfiguration in `backend/src/CaixaSeguradora.Infrastructure/Data/Configurations/AgencyConfiguration.cs`
- [ ] T050 [P] Create ProducerConfiguration in `backend/src/CaixaSeguradora.Infrastructure/Data/Configurations/ProducerConfiguration.cs`
- [ ] T051 [P] Create CoverageConfiguration in `backend/src/CaixaSeguradora.Infrastructure/Data/Configurations/CoverageConfiguration.cs`
- [ ] T052 [P] Create InvoiceConfiguration in `backend/src/CaixaSeguradora.Infrastructure/Data/Configurations/InvoiceConfiguration.cs`
- [ ] T053 [P] Create InstallmentConfiguration in `backend/src/CaixaSeguradora.Infrastructure/Data/Configurations/InstallmentConfiguration.cs`
- [ ] T054 [P] Create CossuredPolicyConfiguration in `backend/src/CaixaSeguradora.Infrastructure/Data/Configurations/CossuredPolicyConfiguration.cs`
- [ ] T055 [P] Create CossuranceCalculationConfiguration in `backend/src/CaixaSeguradora.Infrastructure/Data/Configurations/CossuranceCalculationConfiguration.cs`
- [ ] T056 [P] Create SystemConfigurationConfiguration in `backend/src/CaixaSeguradora.Infrastructure/Data/Configurations/SystemConfigurationConfiguration.cs`
- [ ] T057 [P] Create ReportDefinitionConfiguration in `backend/src/CaixaSeguradora.Infrastructure/Data/Configurations/ReportDefinitionConfiguration.cs`
- [ ] T058 Apply all entity configurations to DbContext in `backend/src/CaixaSeguradora.Infrastructure/Data/PremiumReportingDbContext.cs`
- [ ] T059 Generate and apply EF Core migration for all entities to create database schema

### Core Infrastructure Services

- [ ] T060 Create FixedWidthFormatter in `backend/src/CaixaSeguradora.Infrastructure/Formatters/FixedWidthFormatter.cs` (from research.md R2)
- [ ] T061 Create CobolMath utility class in `backend/src/CaixaSeguradora.Core/Utilities/CobolMath.cs` with rounding methods (from research.md R1)
- [ ] T062 Create base repository interface IRepository<T> in `backend/src/CaixaSeguradora.Core/Interfaces/IRepository.cs`
- [ ] T063 Create base repository implementation Repository<T> in `backend/src/CaixaSeguradora.Infrastructure/Repositories/Repository.cs`
- [ ] T064 Configure Serilog in `backend/src/CaixaSeguradora.Api/Program.cs` with structured logging
- [ ] T065 Configure Swagger/OpenAPI in `backend/src/CaixaSeguradora.Api/Program.cs` per contracts/openapi.yaml
- [ ] T066 Configure CORS policy in `backend/src/CaixaSeguradora.Api/Program.cs` for frontend origin
- [ ] T067 Configure dependency injection container in `backend/src/CaixaSeguradora.Api/Program.cs` for all services
- [ ] T068 Create global exception handler middleware in `backend/src/CaixaSeguradora.Api/Middleware/ExceptionHandlerMiddleware.cs`
- [ ] T069 Create error response DTO in `backend/src/CaixaSeguradora.Core/DTOs/ErrorResponse.cs`

### Frontend Foundation

- [ ] T070 Create frontend folder structure (`components/`, `pages/`, `services/`, `hooks/`, `utils/`) in `frontend/src/`
- [ ] T071 Create Axios API client instance in `frontend/src/services/apiClient.ts` with base URL configuration
- [ ] T072 Create API service interfaces in `frontend/src/services/types.ts` matching OpenAPI schemas
- [ ] T073 [P] Create common UI components (Button, Card, Spinner, ErrorMessage) in `frontend/src/components/common/`
- [ ] T074 [P] Configure React Router in `frontend/src/App.tsx` with routes for all pages
- [ ] T075 [P] Create global styles with Caixa branding in `frontend/src/styles/globals.css`
- [ ] T076 [P] Create layout component with header/navigation in `frontend/src/components/Layout.tsx`

**Checkpoint**: Foundation ready - user story implementation can now begin in parallel

---

## Phase 3: User Story 1 - View Migration Dashboard (Priority: P1) 🎯 MVP

**Goal**: Provide interactive dashboard showing COBOL program analysis, migration metrics, and project complexity

**Independent Test**: Launch React application at http://localhost:5173, navigate to dashboard, verify all metrics display correctly (program info shows RG1866B with 687 data items, 63 sections, 26+ tables), function points breakdown visible, database dependencies visualized

### Backend Implementation for US1

- [ ] T077 [P] [US1] Create DashboardMetricsDto in `backend/src/CaixaSeguradora.Core/DTOs/DashboardMetricsDto.cs`
- [ ] T078 [P] [US1] Create FunctionPointsDto in `backend/src/CaixaSeguradora.Core/DTOs/FunctionPointsDto.cs`
- [ ] T079 [P] [US1] Create DatabaseDependenciesDto in `backend/src/CaixaSeguradora.Core/DTOs/DatabaseDependenciesDto.cs`
- [ ] T080 [US1] Create IDashboardService interface in `backend/src/CaixaSeguradora.Core/Interfaces/IDashboardService.cs`
- [ ] T081 [US1] Implement DashboardService in `backend/src/CaixaSeguradora.Infrastructure/Services/DashboardService.cs` with hardcoded metrics from parser analysis
- [ ] T082 [US1] Create DashboardController in `backend/src/CaixaSeguradora.Api/Controllers/DashboardController.cs` with three endpoints (metrics, function-points, database-dependencies)
- [ ] T083 [US1] Register DashboardService in dependency injection container in `backend/src/CaixaSeguradora.Api/Program.cs`
- [ ] T084 [US1] Test dashboard endpoints with Swagger UI - verify metrics match FINAL-ANALYSIS-REPORT.md

### Frontend Implementation for US1

- [ ] T085 [P] [US1] Create dashboardService.ts in `frontend/src/services/dashboardService.ts` with API calls
- [ ] T086 [P] [US1] Create ProgramInfoCard component in `frontend/src/components/dashboard/ProgramInfoCard.tsx`
- [ ] T087 [P] [US1] Create DataStructureCard component in `frontend/src/components/dashboard/DataStructureCard.tsx`
- [ ] T088 [P] [US1] Create ComplexityMetricsCard component in `frontend/src/components/dashboard/ComplexityMetricsCard.tsx`
- [ ] T089 [P] [US1] Create DatabaseDependenciesChart component in `frontend/src/components/dashboard/DatabaseDependenciesChart.tsx` using Recharts
- [ ] T090 [P] [US1] Create FunctionPointsChart component in `frontend/src/components/dashboard/FunctionPointsChart.tsx`
- [ ] T091 [P] [US1] Create MigrationProgressCard component in `frontend/src/components/dashboard/MigrationProgressCard.tsx`
- [ ] T092 [US1] Create DashboardPage in `frontend/src/pages/DashboardPage.tsx` composing all dashboard components
- [ ] T093 [US1] Add dashboard route to React Router in `frontend/src/App.tsx` (default route `/`)
- [ ] T094 [US1] Test dashboard page loads with all metrics, charts render correctly, responsive layout works on mobile/tablet/desktop

**Checkpoint**: At this point, User Story 1 (Dashboard) should be fully functional and testable independently. Deploy as MVP.

---

## Phase 4: User Story 2 - Generate Premium Reports (Interactive) (Priority: P2)

**Goal**: Enable interactive PREMIT/PREMCED report generation through web interface, replacing COBOL batch processing

**Independent Test**: Configure report parameters (date range 2025-10-01 to 2025-10-31, system GL, report type PREMIT), click generate, verify processing status updates, download generated file, compare byte-for-byte with COBOL sample output

### Backend Repositories for US2

- [ ] T095 [P] [US2] Create IPremiumRepository interface in `backend/src/CaixaSeguradora.Core/Interfaces/IPremiumRepository.cs` with cursor methods
- [ ] T096 [P] [US2] Create IPolicyRepository interface in `backend/src/CaixaSeguradora.Core/Interfaces/IPolicyRepository.cs`
- [ ] T097 [P] [US2] Create IEndorsementRepository interface in `backend/src/CaixaSeguradora.Core/Interfaces/IEndorsementRepository.cs`
- [ ] T098 [P] [US2] Create IProductRepository interface in `backend/src/CaixaSeguradora.Core/Interfaces/IProductRepository.cs`
- [ ] T099 [P] [US2] Create ICoverageRepository interface in `backend/src/CaixaSeguradora.Core/Interfaces/ICoverageRepository.cs`
- [ ] T100 [P] [US2] Create IClientRepository interface in `backend/src/CaixaSeguradora.Core/Interfaces/IClientRepository.cs`
- [ ] T101 [P] [US2] Create IAddressRepository interface in `backend/src/CaixaSeguradora.Core/Interfaces/IAddressRepository.cs`
- [ ] T102 [P] [US2] Create ICossuredPolicyRepository interface in `backend/src/CaixaSeguradora.Core/Interfaces/ICossuredPolicyRepository.cs`
- [ ] T103 [P] [US2] Create ICossuranceCalculationRepository interface in `backend/src/CaixaSeguradora.Core/Interfaces/ICossuranceCalculationRepository.cs`
- [X] T104 [P] [US2] Implement PremiumRepository in `backend/src/CaixaSeguradora.Infrastructure/Repositories/PremiumRepository.cs` with IAsyncEnumerable (research.md R3)
- [X] T105 [P] [US2] Implement PolicyRepository in `backend/src/CaixaSeguradora.Infrastructure/Repositories/PolicyRepository.cs`
- [X] T106 [P] [US2] Implement EndorsementRepository in `backend/src/CaixaSeguradora.Infrastructure/Repositories/EndorsementRepository.cs`
- [X] T107 [P] [US2] Implement ProductRepository in `backend/src/CaixaSeguradora.Infrastructure/Repositories/ProductRepository.cs`
- [X] T108 [P] [US2] Implement CoverageRepository in `backend/src/CaixaSeguradora.Infrastructure/Repositories/CoverageRepository.cs`
- [X] T109 [P] [US2] Implement ClientRepository in `backend/src/CaixaSeguradora.Infrastructure/Repositories/ClientRepository.cs`
- [X] T110 [P] [US2] Implement AddressRepository in `backend/src/CaixaSeguradora.Infrastructure/Repositories/AddressRepository.cs`
- [X] T111 [P] [US2] Implement CossuredPolicyRepository in `backend/src/CaixaSeguradora.Infrastructure/Repositories/CossuredPolicyRepository.cs`
- [X] T112 [P] [US2] Implement CossuranceCalculationRepository in `backend/src/CaixaSeguradora.Infrastructure/Repositories/CossuranceCalculationRepository.cs`

### Business Logic Services for US2 (COBOL Sections R0500-R5500)

- [ ] T113 [US2] Create IPremiumCalculationService interface in `backend/src/CaixaSeguradora.Core/Interfaces/IPremiumCalculationService.cs`
- [ ] T114 [US2] Create ICossuranceService interface in `backend/src/CaixaSeguradora.Core/Interfaces/ICossuranceService.cs`
- [ ] T115 [US2] Create IExternalModuleService interface in `backend/src/CaixaSeguradora.Core/Interfaces/IExternalModuleService.cs` (for RE0001S, GE0009S, GE0010S mocks)
- [ ] T116 [US2] Implement PremiumCalculationService in `backend/src/CaixaSeguradora.Core/Services/PremiumCalculationService.cs` (COBOL sections R0700-R1300)
- [ ] T117 [US2] Implement CossuranceService in `backend/src/CaixaSeguradora.Core/Services/CossuranceService.cs` (COBOL sections R3000-R5500)
- [ ] T118 [US2] Implement ExternalModuleService mock in `backend/src/CaixaSeguradora.Infrastructure/Services/ExternalModuleService.cs` (research.md R4)
- [ ] T119 [US2] Create unit tests for PremiumCalculationService in `backend/tests/CaixaSeguradora.UnitTests/Services/PremiumCalculationServiceTests.cs` (90%+ coverage per constitution)
- [ ] T120 [US2] Create unit tests for CossuranceService in `backend/tests/CaixaSeguradora.UnitTests/Services/CossuranceServiceTests.cs`

### Report Generation Service for US2

- [ ] T121 [US2] Create IReportGenerationService interface in `backend/src/CaixaSeguradora.Core/Interfaces/IReportGenerationService.cs`
- [ ] T122 [US2] Create ReportGenerationRequest DTO in `backend/src/CaixaSeguradora.Core/DTOs/ReportGenerationRequest.cs`
- [ ] T123 [US2] Create ReportGenerationResponse DTO in `backend/src/CaixaSeguradora.Core/DTOs/ReportGenerationResponse.cs`
- [ ] T124 [US2] Create ReportStatusResponse DTO in `backend/src/CaixaSeguradora.Core/DTOs/ReportStatusResponse.cs`
- [ ] T125 [US2] Implement ReportGenerationService in `backend/src/CaixaSeguradora.Infrastructure/Services/ReportGenerationService.cs` with async processing
- [ ] T126 [US2] Implement PREMIT file generation logic in `backend/src/CaixaSeguradora.Infrastructure/Services/PremitFileGenerator.cs` using FixedWidthFormatter
- [ ] T127 [US2] Implement PREMCED file generation logic in `backend/src/CaixaSeguradora.Infrastructure/Services/PremcedFileGenerator.cs`
- [ ] T128 [US2] Add transaction scope handling in report generation service per research.md R5
- [ ] T129 [US2] Create ReportsController in `backend/src/CaixaSeguradora.Api/Controllers/ReportsController.cs` with five endpoints (generate, status, download, history, compare)
- [ ] T130 [US2] Register all report services in dependency injection in `backend/src/CaixaSeguradora.Api/Program.cs`
- [ ] T131 [US2] Test report generation endpoint with Swagger - verify async 202 response, poll status, download file

### COBOL Comparison Testing for US2

- [ ] T132 [US2] Create OutputValidator class in `backend/tests/CaixaSeguradora.ComparisonTests/OutputValidator.cs` for byte-level comparison (research.md R2)
- [ ] T133 [US2] Create comparison test with sample COBOL output in `backend/tests/CaixaSeguradora.ComparisonTests/PremitOutputComparisonTests.cs`
- [ ] T134 [US2] Create comparison test for PREMCED in `backend/tests/CaixaSeguradora.ComparisonTests/PremcedOutputComparisonTests.cs`
- [ ] T135 [US2] Add 10 sample COBOL output files to `backend/tests/CaixaSeguradora.ComparisonTests/TestData/`
- [ ] T136 [US2] Run comparison tests and verify 100% byte match for all samples (constitution requirement III)

### Error Handling & Database Safeguards for US2

- [ ] T241 [US2] Implement SqlErrorTranslator in `backend/src/CaixaSeguradora.Infrastructure/Services/SqlErrorTranslator.cs` mapping SQLCODE values to domain errors.
- [ ] T242 [US2] Create SQL error handling regression tests in `backend/tests/CaixaSeguradora.IntegrationTests/Reports/SqlErrorHandlingTests.cs`.
- [ ] T243 [US2] Add read-only DB command interceptor in `backend/src/CaixaSeguradora.Infrastructure/Data/ReadOnlyDbCommandInterceptor.cs` to block write operations.
- [ ] T244 [US2] Verify read-only enforcement with integration tests in `backend/tests/CaixaSeguradora.IntegrationTests/Data/ReadOnlyGuardTests.cs`.

### Frontend Implementation for US2

- [ ] T137 [P] [US2] Create reportService.ts in `frontend/src/services/reportService.ts` with API calls
- [ ] T138 [P] [US2] Create ReportParametersForm component in `frontend/src/components/reports/ReportParametersForm.tsx`
- [ ] T139 [P] [US2] Create ReportProgressIndicator component in `frontend/src/components/reports/ReportProgressIndicator.tsx`
- [ ] T140 [P] [US2] Create ReportResultsCard component in `frontend/src/components/reports/ReportResultsCard.tsx`
- [ ] T141 [P] [US2] Create ReportHistoryTable component in `frontend/src/components/reports/ReportHistoryTable.tsx`
- [ ] T142 [US2] Create ReportGenerationPage in `frontend/src/pages/ReportGenerationPage.tsx` with form, status polling, download functionality
- [ ] T143 [US2] Add report generation route `/reports` to React Router in `frontend/src/App.tsx`
- [ ] T144 [US2] Test full report generation flow: fill form, submit, see progress, download file, verify file contents

**Checkpoint**: At this point, User Stories 1 AND 2 should both work independently. Core migration functionality complete.

---

## Phase 5: User Story 3 - Query and Visualize Premium Data (Priority: P3)

**Goal**: Enable interactive querying and visualization of premium data with export capabilities

**Independent Test**: Navigate to query page, build filter (policy number range, date range), execute query, verify results table shows data, create chart visualization, export to CSV, verify exported data accuracy

### Backend Implementation for US3

- [ ] T145 [P] [US3] Create PremiumQueryRequest DTO in `backend/src/CaixaSeguradora.Core/DTOs/PremiumQueryRequest.cs`
- [ ] T146 [P] [US3] Create PremiumQueryResponse DTO in `backend/src/CaixaSeguradora.Core/DTOs/PremiumQueryResponse.cs`
- [ ] T147 [P] [US3] Create PremiumStatisticsRequest DTO in `backend/src/CaixaSeguradora.Core/DTOs/PremiumStatisticsRequest.cs`
- [ ] T148 [P] [US3] Create PremiumStatisticsResponse DTO in `backend/src/CaixaSeguradora.Core/DTOs/PremiumStatisticsResponse.cs`
- [ ] T149 [US3] Create IQueryService interface in `backend/src/CaixaSeguradora.Core/Interfaces/IQueryService.cs`
- [ ] T150 [US3] Implement QueryService in `backend/src/CaixaSeguradora.Infrastructure/Services/QueryService.cs` with dynamic LINQ queries
- [ ] T151 [US3] Create IExportService interface in `backend/src/CaixaSeguradora.Core/Interfaces/IExportService.cs`
- [ ] T152 [US3] Implement CsvExportService in `backend/src/CaixaSeguradora.Infrastructure/Services/CsvExportService.cs`
- [ ] T153 [US3] Implement ExcelExportService in `backend/src/CaixaSeguradora.Infrastructure/Services/ExcelExportService.cs` using EPPlus or ClosedXML
- [ ] T154 [US3] Implement PdfExportService in `backend/src/CaixaSeguradora.Infrastructure/Services/PdfExportService.cs` using iText7 or QuestPDF
- [ ] T155 [US3] Create PremiumsController in `backend/src/CaixaSeguradora.Api/Controllers/PremiumsController.cs` with query and statistics endpoints
- [ ] T156 [US3] Create ExportController in `backend/src/CaixaSeguradora.Api/Controllers/ExportController.cs` with export endpoints
- [ ] T157 [US3] Register query and export services in dependency injection in `backend/src/CaixaSeguradora.Api/Program.cs`
- [ ] T158 [US3] Test query endpoint with Swagger - verify filtering, sorting, pagination work correctly

### Frontend Implementation for US3

- [ ] T159 [P] [US3] Create queryService.ts in `frontend/src/services/queryService.ts`
- [ ] T160 [P] [US3] Create QueryFilterForm component in `frontend/src/components/query/QueryFilterForm.tsx` with date pickers, dropdowns
- [ ] T161 [P] [US3] Create QueryResultsTable component in `frontend/src/components/query/QueryResultsTable.tsx` with pagination, sorting
- [ ] T162 [P] [US3] Create QueryStatisticsCard component in `frontend/src/components/query/QueryStatisticsCard.tsx` showing aggregations
- [ ] T163 [P] [US3] Create QueryVisualizationPanel component in `frontend/src/components/query/QueryVisualizationPanel.tsx` with chart type selector
- [ ] T164 [P] [US3] Create ExportButtonGroup component in `frontend/src/components/query/ExportButtonGroup.tsx` (CSV, Excel, PDF buttons)
- [ ] T165 [US3] Create QueryPage in `frontend/src/pages/QueryPage.tsx` composing all query components
- [ ] T166 [US3] Add query route `/query` to React Router in `frontend/src/App.tsx`
- [ ] T167 [US3] Test query page: build filters, execute query, see results, create charts, export files

**Checkpoint**: User Stories 1, 2, and 3 all work independently. Dashboard, reports, and query capabilities complete.

---

## Phase 6: User Story 4 - Monitor Batch Processing Jobs (Priority: P4)

**Goal**: Enable scheduling and monitoring of automated report generation jobs

**Independent Test**: Create scheduled job (monthly reports on 1st at 2 AM), verify job appears in list, manually trigger job execution, monitor status, verify completion notification sent

### Backend Implementation for US4

- [ ] T168 [P] [US4] Create BatchJobCreateRequest DTO in `backend/src/CaixaSeguradora.Core/DTOs/BatchJobCreateRequest.cs`
- [ ] T169 [P] [US4] Create BatchJob entity in `backend/src/CaixaSeguradora.Core/Entities/BatchJob.cs`
- [ ] T170 [P] [US4] Create JobExecution entity in `backend/src/CaixaSeguradora.Core/Entities/JobExecution.cs`
- [ ] T171 [US4] Create BatchJobConfiguration in `backend/src/CaixaSeguradora.Infrastructure/Data/Configurations/BatchJobConfiguration.cs`
- [ ] T172 [US4] Create JobExecutionConfiguration in `backend/src/CaixaSeguradora.Infrastructure/Data/Configurations/JobExecutionConfiguration.cs`
- [ ] T173 [US4] Generate and apply EF Core migration for batch job tables
- [ ] T174 [US4] Create IBatchJobRepository interface in `backend/src/CaixaSeguradora.Core/Interfaces/IBatchJobRepository.cs`
- [ ] T175 [US4] Implement BatchJobRepository in `backend/src/CaixaSeguradora.Infrastructure/Repositories/BatchJobRepository.cs`
- [ ] T176 [US4] Create IBatchSchedulingService interface in `backend/src/CaixaSeguradora.Core/Interfaces/IBatchSchedulingService.cs`
- [ ] T177 [US4] Implement BatchSchedulingService in `backend/src/CaixaSeguradora.Infrastructure/Services/BatchSchedulingService.cs` using Hangfire or Quartz.NET
- [ ] T178 [US4] Create INotificationService interface in `backend/src/CaixaSeguradora.Core/Interfaces/INotificationService.cs`
- [ ] T179 [US4] Implement EmailNotificationService in `backend/src/CaixaSeguradora.Infrastructure/Services/EmailNotificationService.cs` using MailKit
- [ ] T180 [US4] Create BatchJobsController in `backend/src/CaixaSeguradora.Api/Controllers/BatchJobsController.cs` with CRUD and execution endpoints
- [ ] T181 [US4] Register batch job services and Hangfire in dependency injection in `backend/src/CaixaSeguradora.Api/Program.cs`
- [ ] T182 [US4] Configure Hangfire dashboard in `backend/src/CaixaSeguradora.Api/Program.cs` at `/hangfire`
- [ ] T183 [US4] Test batch job creation, scheduling, and manual execution via Swagger and Hangfire dashboard

### Frontend Implementation for US4

- [ ] T184 [P] [US4] Create batchJobService.ts in `frontend/src/services/batchJobService.ts`
- [ ] T185 [P] [US4] Create BatchJobForm component in `frontend/src/components/batch/BatchJobForm.tsx` with cron expression builder
- [ ] T186 [P] [US4] Create BatchJobsTable component in `frontend/src/components/batch/BatchJobsTable.tsx` showing all jobs
- [ ] T187 [P] [US4] Create JobExecutionHistoryTable component in `frontend/src/components/batch/JobExecutionHistoryTable.tsx`
- [ ] T188 [P] [US4] Create JobStatusBadge component in `frontend/src/components/batch/JobStatusBadge.tsx` (Running, Completed, Failed)
- [ ] T189 [US4] Create BatchJobsPage in `frontend/src/pages/BatchJobsPage.tsx` with create, list, monitor functionality
- [ ] T190 [US4] Add batch jobs route `/batch-jobs` to React Router in `frontend/src/App.tsx`
- [ ] T191 [US4] Test batch jobs page: create job, view list, see execution history, verify notifications work

**Checkpoint**: User Stories 1-4 complete. All operational features working.

---

## Phase 7: User Story 5 - Manage Database Mock Data (Priority: P4)

**Goal**: Enable loading, validating, and managing SQLite mock data for testing

**Independent Test**: Upload CSV file with premium data, verify loading succeeds, check record count, run validation, see any data quality issues, run COBOL vs .NET comparison, export diff report

### Backend Implementation for US5

- [ ] T192 [P] [US5] Create MockDataLoadRequest DTO in `backend/src/CaixaSeguradora.Core/DTOs/MockDataLoadRequest.cs`
- [ ] T193 [P] [US5] Create MockDataLoadResponse DTO in `backend/src/CaixaSeguradora.Core/DTOs/MockDataLoadResponse.cs`
- [ ] T194 [P] [US5] Create DataValidationResponse DTO in `backend/src/CaixaSeguradora.Core/DTOs/DataValidationResponse.cs`
- [ ] T195 [US5] Create IMockDataService interface in `backend/src/CaixaSeguradora.Core/Interfaces/IMockDataService.cs`
- [ ] T196 [US5] Create IDataValidationService interface in `backend/src/CaixaSeguradora.Core/Interfaces/IDataValidationService.cs`
- [ ] T197 [US5] Implement CsvDataLoader in `backend/src/CaixaSeguradora.Infrastructure/Services/CsvDataLoader.cs` using CsvHelper
- [ ] T198 [US5] Implement JsonDataLoader in `backend/src/CaixaSeguradora.Infrastructure/Services/JsonDataLoader.cs`
- [ ] T199 [US5] Implement DataValidationService in `backend/src/CaixaSeguradora.Infrastructure/Services/DataValidationService.cs` with foreign key checks
- [ ] T200 [US5] Implement SchemaInspectionService in `backend/src/CaixaSeguradora.Infrastructure/Services/SchemaInspectionService.cs`
- [ ] T201 [US5] Create MockDataController in `backend/src/CaixaSeguradora.Api/Controllers/MockDataController.cs` with load, validate, reset endpoints
- [ ] T202 [US5] Register mock data services in dependency injection in `backend/src/CaixaSeguradora.Api/Program.cs`
- [ ] T203 [US5] Create sample CSV files for all entities in `backend/tests/SampleData/` (premiums, policies, clients, etc.)
- [ ] T204 [US5] Test mock data loading via Swagger with sample CSV files, verify data appears in database

### Frontend Implementation for US5

- [ ] T205 [P] [US5] Create mockDataService.ts in `frontend/src/services/mockDataService.ts`
- [ ] T206 [P] [US5] Create FileUploadForm component in `frontend/src/components/data/FileUploadForm.tsx` with drag-and-drop
- [ ] T207 [P] [US5] Create SchemaViewer component in `frontend/src/components/data/SchemaViewer.tsx` showing table structures
- [ ] T208 [P] [US5] Create ValidationResultsPanel component in `frontend/src/components/data/ValidationResultsPanel.tsx`
- [ ] T209 [P] [US5] Create ComparisonReportViewer component in `frontend/src/components/data/ComparisonReportViewer.tsx` showing diffs
- [ ] T210 [US5] Create DataManagementPage in `frontend/src/pages/DataManagementPage.tsx` with upload, validate, reset, compare features
- [ ] T211 [US5] Add data management route `/data-management` to React Router in `frontend/src/App.tsx`
- [ ] T212 [US5] Test data management page: upload file, validate data, run comparison, export results

**Checkpoint**: All user stories (1-5) complete and independently testable.

---

## Phase 8: Polish & Cross-Cutting Concerns

**Purpose**: Improvements that affect multiple user stories and final validation

### Integration & Performance

- [ ] T213 [P] Create integration tests for complete workflows in `backend/tests/CaixaSeguradora.IntegrationTests/Workflows/`
- [ ] T214 [P] Create E2E tests using Playwright in `frontend/tests/e2e/` for critical user journeys
- [ ] T215 [P] Add performance benchmarks using BenchmarkDotNet in `backend/tests/CaixaSeguradora.PerformanceTests/` (research.md R8)
- [ ] T216 [P] Run performance comparison: .NET vs COBOL baseline, verify within 120% threshold (SC-015)
- [ ] T217 Test concurrent report generation with 10 simultaneous users, verify <20% degradation (performance goal)
- [ ] T218 Test large dataset processing (10,000+ records), verify <5 minutes completion (SC-003)

### Documentation & Deployment

- [ ] T219 [P] Update README.md in repository root with project overview and quick start links
- [ ] T220 [P] Create API documentation from OpenAPI spec using Redoc or Stoplight in `docs/api/`
- [ ] T221 [P] Add inline code documentation (XML comments) for all public APIs
- [ ] T222 [P] Create deployment guide in `docs/deployment.md` with Docker and Kubernetes instructions
- [ ] T223 [P] Create operations manual in `docs/operations.md` for monitoring, backup, troubleshooting
- [ ] T224 Validate quickstart.md by following all steps from clean environment
- [ ] T225 Create demo video or screenshots of all user stories for stakeholder presentation

### Code Quality & Security

- [ ] T226 [P] Run .NET code analysis (dotnet format, ReSharper inspections), fix all warnings
- [ ] T227 [P] Run frontend linting (eslint, prettier), fix all issues
- [ ] T228 [P] Add authentication/authorization middleware (JWT bearer tokens) per OpenAPI security scheme
- [ ] T229 [P] Add input validation for all API endpoints using FluentValidation
- [ ] T230 [P] Add rate limiting to prevent API abuse
- [ ] T231 [P] Configure HTTPS certificates for production
- [ ] T232 Review all error messages for Portuguese translation accuracy (FR-020)
- [ ] T233 Review Caixa Seguradora branding consistency across all pages (FR-021)

### Final Validation

- [ ] T234 Run full test suite (unit, integration, E2E, comparison) and verify all pass
- [ ] T235 Verify 90%+ code coverage for business logic services (constitution requirement III)
- [ ] T236 Verify byte-for-byte output matching with 100 COBOL samples (constitution requirement III)
- [ ] T237 Verify all 30 functional requirements (FR-001 through FR-030) are met
- [ ] T238 Verify all 19 success criteria (SC-001 through SC-019) are met
- [ ] T239 Conduct user acceptance testing with business stakeholders
- [ ] T240 Create migration sign-off document with validation results

---

## Dependencies & Execution Order

### Phase Dependencies

- **Setup (Phase 1)**: No dependencies - can start immediately
- **Foundational (Phase 2)**: Depends on Setup completion - BLOCKS all user stories
- **User Stories (Phase 3-7)**: All depend on Foundational phase completion
  - User stories can proceed in parallel (if team staffed accordingly)
  - Or sequentially in priority order (P1 → P2 → P3 → P4)
- **Polish (Phase 8)**: Depends on all desired user stories being complete

### User Story Dependencies

- **User Story 1 (P1)**: Can start after Foundational - No dependencies on other stories (Dashboard only)
- **User Story 2 (P2)**: Can start after Foundational - No dependencies on other stories (Report generation standalone)
- **User Story 3 (P3)**: Can start after Foundational - May query same data as US2 but independently testable
- **User Story 4 (P4)**: Can start after Foundational - Schedules reports from US2 but can be tested with mocks
- **User Story 5 (P4)**: Can start after Foundational - Loads data used by all stories but independently testable

### Within Each User Story

- Backend entities before repositories
- Repositories before services
- Services before controllers
- Controllers registered in DI before testing
- Frontend services before components
- Components before pages
- All implementation before independent testing

### Parallel Opportunities

All tasks marked **[P]** can run in parallel within their phase:

- **Setup (Phase 1)**: Tasks T002-T020 can run in parallel (different projects, different files)
- **Foundational (Phase 2)**:
  - Entities T028-T042 can run in parallel (different files)
  - Configurations T043-T057 can run in parallel (different files)
  - Frontend foundation T073-T076 can run in parallel
- **Within User Stories**:
  - DTOs can be created in parallel
  - Repository interfaces can be created in parallel
  - Repository implementations can be created in parallel
  - Frontend components can be created in parallel

Once Foundational phase completes, all 5 user stories can be worked on in parallel by different team members.

---

## Parallel Example: User Story 2

```bash
# Create all repository interfaces together:
Task T095: "Create IPremiumRepository interface in backend/src/CaixaSeguradora.Core/Interfaces/IPremiumRepository.cs"
Task T096: "Create IPolicyRepository interface in backend/src/CaixaSeguradora.Core/Interfaces/IPolicyRepository.cs"
Task T097: "Create IEndorsementRepository interface in backend/src/CaixaSeguradora.Core/Interfaces/IEndorsementRepository.cs"
# ... (all repository interfaces in parallel)

# Create all repository implementations together:
Task T104: "Implement PremiumRepository in backend/src/CaixaSeguradora.Infrastructure/Repositories/PremiumRepository.cs"
Task T105: "Implement PolicyRepository in backend/src/CaixaSeguradora.Infrastructure/Repositories/PolicyRepository.cs"
# ... (all repository implementations in parallel)

# Create all frontend components together:
Task T137: "Create reportService.ts in frontend/src/services/reportService.ts"
Task T138: "Create ReportParametersForm component in frontend/src/components/reports/ReportParametersForm.tsx"
Task T139: "Create ReportProgressIndicator component in frontend/src/components/reports/ReportProgressIndicator.tsx"
# ... (all components in parallel)
```

---

## Implementation Strategy

### MVP First (User Story 1 Only)

1. Complete Phase 1: Setup (T001-T020)
2. Complete Phase 2: Foundational (T021-T076) - CRITICAL, blocks all stories
3. Complete Phase 3: User Story 1 (T077-T094)
4. **STOP and VALIDATE**: Test dashboard independently, verify all metrics display
5. Deploy/demo MVP dashboard

**Timeline**: Estimated 2-3 weeks for skilled .NET/React team

### Incremental Delivery (Recommended)

1. **Week 1-2**: Setup + Foundational → Database schema ready, entities created
2. **Week 3**: User Story 1 → Dashboard complete → **Deploy MVP** 🎯
3. **Week 4-5**: User Story 2 → Report generation complete → **Deploy v1.1**
4. **Week 6**: User Story 3 → Query capability complete → **Deploy v1.2**
5. **Week 7**: User Story 4 → Batch jobs complete → **Deploy v1.3**
6. **Week 8**: User Story 5 → Data management complete → **Deploy v1.4**
7. **Week 9**: Polish & Validation → Final release

Each increment adds value without breaking previous functionality.

### Parallel Team Strategy

With team of 5 developers after Foundational phase complete:

- **Developer A**: User Story 1 (Dashboard) - 1 week
- **Developer B**: User Story 2 (Reports) - 2 weeks (most complex)
- **Developer C**: User Story 3 (Query) - 1.5 weeks
- **Developer D**: User Story 4 (Batch) - 1 week
- **Developer E**: User Story 5 (Data Management) - 1 week

Stories complete and integrate independently. **All 5 stories delivered in 2 weeks** (parallelized).

---

## Task Summary

- **Total Tasks**: 244
- **Setup Tasks**: 20 (Phase 1)
- **Foundational Tasks**: 56 (Phase 2)
- **User Story 1 Tasks**: 18 (Phase 3)
- **User Story 2 Tasks**: 72 (Phase 4)
- **User Story 3 Tasks**: 24 (Phase 5)
- **User Story 4 Tasks**: 24 (Phase 6)
- **User Story 5 Tasks**: 21 (Phase 7)
- **Polish Tasks**: 28 (Phase 8)

**Parallel Opportunities**: 120+ tasks marked [P] can run in parallel

**MVP Scope (Recommended)**: Phase 1 + Phase 2 + Phase 3 = 94 tasks (Weeks 1-3)

**Independent Test Criteria**:
- **US1**: Dashboard loads, all metrics display, charts render
- **US2**: Generate report, download file, byte-match COBOL output
- **US3**: Execute query, view results, export to CSV
- **US4**: Create scheduled job, monitor execution, receive notification
- **US5**: Load CSV data, validate schema, run comparison

---

## Notes

- **[P] tasks** = different files, no dependencies, safe to parallelize
- **[Story] label** maps task to specific user story for traceability
- Each user story is independently completable and testable
- Constitution requirement: 90%+ test coverage for business logic (T119, T120 in US2)
- Constitution requirement: 100% byte-match validation (T132-T136 in US2)
- All user-facing content must be in Portuguese (FR-020)
- Commit after each task or logical group of tasks
- Stop at any checkpoint to validate story independently
- Byte-level COBOL comparison is NON-NEGOTIABLE for regulatory compliance

---

**Generated**: October 22, 2025
**Status**: Ready for implementation
**Next Command**: `/speckit.implement T001` to start implementation



### RESEARCH.MD (Decisions & Constraints)

# Technical Research: COBOL RG1866B to .NET 9 Migration

**Date**: October 22, 2025
**Project**: SUSEP Circular 360 Premium Reporting System Migration
**Status**: Complete - All 8 Research Areas Documented

## Overview

This document captures technical research and decisions for migrating COBOL RG1866B to .NET 9 with React frontend. All research areas address critical requirements for regulatory compliance, particularly byte-for-byte output matching and decimal precision in financial calculations.

---

## R1: COBOL to C# Type Mapping Strategy

**Decision**: Comprehensive type mapping using C# `decimal` for all numeric fields with precision/scale matching COBOL PIC definitions, `string` with fixed-length awareness for alphanumeric, and custom `CobolDateTime` wrapper for date handling

**Rationale**:
- COBOL PIC 9(n)V9(m) represents packed decimal with exact precision - C# `decimal` type provides equivalent precision (up to 28-29 significant digits) required for financial calculations
- Regulatory compliance demands zero arithmetic deviation - `float`/`double` introduce rounding errors unacceptable for insurance premiums
- Fixed-length string handling critical for COBOL compatibility where `PIC X(10)` always occupies 10 bytes with space padding

**Type Mapping Table**:

| COBOL PIC Type | C# Type | Notes |
|----------------|---------|-------|
| PIC 9(n) | `int` or `long` | n ≤ 9: `int`, n > 9: `long` |
| PIC 9(n)V9(m) | `decimal` | Precision: n+m, Scale: m |
| PIC S9(n) | `int` or `long` | Signed integer, same size rules |
| PIC S9(n)V9(m) | `decimal` | Signed decimal with precision/scale |
| PIC S9(n) COMP-3 | `int` | Packed decimal, 2 digits per byte |
| PIC X(n) | `string` | Fixed length n, space-padded |
| PIC A(n) | `string` | Alphabetic only, space-padded |
| YYYYMMDD | `DateTime` | Parse with CultureInfo.InvariantCulture |
| DDMMYYYY | `DateTime` | Custom formatter required |

**Alternatives Considered**:
1. **Use `double` for decimals** - Rejected: Binary floating-point introduces rounding errors (e.g., 0.1 + 0.2 ≠ 0.3 exactly). Insurance calculations require exact decimal arithmetic.
2. **Use `BigDecimal` library** - Rejected: C# `decimal` is native, faster, and sufficient for precision requirements (28-29 digits covers all COBOL use cases in RG1866B)
3. **String-based arithmetic** - Rejected: Overly complex, slower performance, error-prone parsing

**Implementation Notes**:

```csharp
// Custom attribute for COBOL type metadata
[AttributeUsage(AttributeTargets.Property)]
public class CobolFieldAttribute : Attribute
{
    public string PicClause { get; set; }
    public int Length { get; set; }
    public int DecimalPlaces { get; set; }
    public CobolFieldType FieldType { get; set; }
}

// Example entity with COBOL mapping
public class Premium
{
    [CobolField(PicClause = "9(15)V99", Length = 17, DecimalPlaces = 2)]
    public decimal PremiumAmount { get; set; }  // Maps to PIC 9(15)V99

    [CobolField(PicClause = "X(10)", Length = 10)]
    public string PolicyNumber { get; set; }  // Maps to PIC X(10)

    [CobolField(PicClause = "9(8)", Length = 8)]
    public DateTime EffectiveDate { get; set; }  // YYYYMMDD format
}

// Rounding mode matching COBOL
public static class CobolMath
{
    // COBOL ROUND mode equivalent
    public static decimal RoundAwayFromZero(decimal value, int decimals)
    {
        return Math.Round(value, decimals, MidpointRounding.AwayFromZero);
    }

    // COBOL TRUNCATE equivalent
    public static decimal Truncate(decimal value, int decimals)
    {
        decimal multiplier = (decimal)Math.Pow(10, decimals);
        return Math.Truncate(value * multiplier) / multiplier;
    }
}
```

**References**:
- .NET `decimal` type documentation: https://learn.microsoft.com/en-us/dotnet/api/system.decimal
- COBOL PIC clause reference: https://www.ibm.com/docs/en/cobol-zos/6.4?topic=definitions-picture-clause
- Decimal precision in financial systems: https://stackoverflow.com/questions/3730019/why-not-use-double-or-float-to-represent-currency

---

## R2: Fixed-Width File Generation

**Decision**: Custom `FixedWidthFormatter` class using `StringBuilder` with explicit padding rules, validated via byte-level comparison against COBOL output samples

**Rationale**:
- COBOL WRITE statements generate fixed-width records with precise space/zero padding rules that standard .NET formatters don't replicate
- Regulatory requirement for byte-for-byte matching means even a single misplaced space causes compliance failure
- Performance critical for large files (10,000+ records) - `StringBuilder` approach is faster than string concatenation

**Padding Rules (COBOL Behavior)**:

| Data Type | Padding Rule | Example |
|-----------|--------------|---------|
| Numeric PIC 9(n) | Left-pad with zeros | 123 → "00123" for PIC 9(5) |
| Decimal PIC 9(n)V9(m) | Left-pad whole part with zeros, right-pad decimal with zeros | 12.3 → "00012.30" for PIC 9(5)V9(2) |
| Alpha PIC X(n) | Right-pad with spaces | "ABC" → "ABC       " for PIC X(10) |
| Signed PIC S9(n) | Leading sign, left-pad with zeros | -123 → "-00123" for PIC S9(5) |

**Alternatives Considered**:
1. **Use String.Format()** - Rejected: Doesn't support COBOL-specific padding rules (e.g., decimal with 'V' implied decimal point)
2. **TextFieldParser library** - Rejected: Designed for reading, not writing fixed-width files
3. **COBOL copybook parser libraries** - Rejected: Introduces unnecessary dependency, overkill for output generation

**Implementation Notes**:

```csharp
public class FixedWidthFormatter
{
    public string FormatNumeric(decimal value, int totalWidth, int decimalPlaces, bool includeDecimalPoint = false)
    {
        // COBOL PIC 9(n)V9(m) - V means implied decimal, not printed
        if (!includeDecimalPoint)
        {
            // Multiply by 10^decimalPlaces to get integer representation
            decimal multiplied = value * (decimal)Math.Pow(10, decimalPlaces);
            long intValue = (long)Math.Round(multiplied, MidpointRounding.AwayFromZero);
            return intValue.ToString().PadLeft(totalWidth, '0');
        }
        else
        {
            // Explicit decimal point (rare in COBOL output files)
            string formatted = value.ToString($"F{decimalPlaces}");
            return formatted.PadLeft(totalWidth, '0');
        }
    }

    public string FormatAlphanumeric(string value, int width)
    {
        // COBOL PIC X(n) - right-pad with spaces
        if (value == null) value = "";
        if (value.Length > width) value = value.Substring(0, width);  // Truncate if too long
        return value.PadRight(width, ' ');
    }

    public string FormatDate(DateTime date, string format = "yyyyMMdd")
    {
        // COBOL date formats: YYYYMMDD, DDMMYYYY, YYMMDD
        return date.ToString(format);
    }

    // Example usage for PREMIT.TXT record
    public string FormatPremitRecord(PremiumRecord record)
    {
        var sb = new StringBuilder();
        sb.Append(FormatAlphanumeric(record.PolicyNumber, 10));
        sb.Append(FormatNumeric(record.PremiumAmount, 15, 2));  // PIC 9(13)V99
        sb.Append(FormatDate(record.EffectiveDate));
        sb.Append(FormatAlphanumeric(record.ProductCode, 5));
        // ... continue for all 50+ fields in layout
        return sb.ToString();
    }
}

// Validation: Byte-level comparison
public class OutputValidator
{
    public ComparisonResult CompareFiles(string cobolFile, string dotnetFile)
    {
        byte[] cobolBytes = File.ReadAllBytes(cobolFile);
        byte[] dotnetBytes = File.ReadAllBytes(dotnetFile);

        if (cobolBytes.Length != dotnetBytes.Length)
        {
            return new ComparisonResult
            {
                Match = false,
                Error = $"File size mismatch: {cobolBytes.Length} vs {dotnetBytes.Length}"
            };
        }

        for (int i = 0; i < cobolBytes.Length; i++)
        {
            if (cobolBytes[i] != dotnetBytes[i])
            {
                return new ComparisonResult
                {
                    Match = false,
                    Error = $"Byte mismatch at position {i}: {cobolBytes[i]} vs {dotnetBytes[i]}",
                    Context = GetContext(dotnetBytes, i, 50)
                };
            }
        }

        return new ComparisonResult { Match = true };
    }
}
```

**References**:
- StringBuilder performance: https://learn.microsoft.com/en-us/dotnet/api/system.text.stringbuilder
- Fixed-width file patterns: https://www.codeproject.com/Articles/26176/Reading-and-Writing-Fixed-Width-Text-Files
- COBOL file handling: https://www.ibm.com/docs/en/cobol-zos/6.4?topic=division-file-section

---

## R3: Cursor-Based Processing Pattern

**Decision**: Use EF Core `AsNoTracking()` with `IAsyncEnumerable<T>` for streaming large datasets, implementing COBOL cursor semantics through async iteration

**Rationale**:
- COBOL cursors (DECLARE, OPEN, FETCH loop, CLOSE) enable processing millions of records without loading all into memory
- EF Core change tracking consumes significant memory - `AsNoTracking()` disables tracking for read-only operations (all report generation is read-only)
- `IAsyncEnumerable<T>` introduced in C# 8.0 provides native streaming support matching cursor behavior

**COBOL Cursor Example** (from RG1866B):
```cobol
EXEC SQL
    DECLARE C1 CURSOR FOR
        SELECT POLICY_NUM, PREMIUM_AMT, EFFECTIVE_DATE
        FROM V0PREMIOS
        WHERE EFFECTIVE_DATE BETWEEN :START-DATE AND :END-DATE
END-EXEC.

EXEC SQL OPEN C1 END-EXEC.

PERFORM UNTIL SQLCODE NOT = 0
    EXEC SQL FETCH C1 INTO :WS-POLICY-NUM, :WS-PREMIUM-AMT, :WS-EFFECTIVE-DATE END-EXEC
    IF SQLCODE = 0
        PERFORM PROCESS-RECORD
    END-IF
END-PERFORM.

EXEC SQL CLOSE C1 END-EXEC.
```

**C# Equivalent**:
```csharp
// Repository method with streaming
public async IAsyncEnumerable<PremiumRecord> GetPremiumsAsync(
    DateTime startDate,
    DateTime endDate,
    [EnumeratorCancellation] CancellationToken cancellationToken = default)
{
    var query = _context.Premiums
        .AsNoTracking()  // Disable change tracking (read-only)
        .Where(p => p.EffectiveDate >= startDate && p.EffectiveDate <= endDate)
        .OrderBy(p => p.PolicyNumber);  // Match COBOL cursor ordering

    await foreach (var record in query.AsAsyncEnumerable().WithCancellation(cancellationToken))
    {
        yield return record;
    }
}

// Service layer processing (matches COBOL PERFORM loop)
public async Task<ReportResult> GenerateReportAsync(DateTime startDate, DateTime endDate)
{
    int recordsProcessed = 0;
    var reportData = new List<ReportLine>();

    await foreach (var premium in _repository.GetPremiumsAsync(startDate, endDate))
    {
        // Process each record (equivalent to COBOL PERFORM PROCESS-RECORD)
        var reportLine = await ProcessPremiumRecord(premium);
        reportData.Add(reportLine);
        recordsProcessed++;

        // Optional: Report progress for long-running operations
        if (recordsProcessed % 1000 == 0)
        {
            _logger.LogInformation($"Processed {recordsProcessed} records");
        }
    }

    return new ReportResult { RecordsProcessed = recordsProcessed, Data = reportData };
}
```

**Alternatives Considered**:
1. **Load all records with .ToListAsync()** - Rejected: Out-of-memory exception for millions of records; COBOL handles via cursor specifically to avoid memory issues
2. **Manual pagination (Skip/Take)** - Rejected: More complex code, requires tracking page number, less performant than streaming
3. **SqlDataReader directly** - Rejected: Loses EF Core benefits (LINQ, entity mapping), introduces SQL injection risks

**Implementation Notes**:

- **Memory Management**: `AsNoTracking()` reduces memory per entity from ~2KB to ~200 bytes (10x improvement)
- **Batching for Writes**: When writing output files, batch writes every 1000 records to balance memory vs I/O

```csharp
// Batch writing pattern
public async Task WriteReportAsync(IAsyncEnumerable<ReportLine> lines, string filePath)
{
    using var writer = new StreamWriter(filePath, append: false, Encoding.UTF8);
    var batch = new List<string>(1000);

    await foreach (var line in lines)
    {
        batch.Add(_formatter.FormatLine(line));

        if (batch.Count >= 1000)
        {
            await writer.WriteAsync(string.Join(Environment.NewLine, batch));
            batch.Clear();
        }
    }

    // Write remaining records
    if (batch.Count > 0)
    {
        await writer.WriteAsync(string.Join(Environment.NewLine, batch));
    }
}
```

- **Cancellation Support**: Always accept `CancellationToken` for long-running operations to allow user cancellation
- **Transaction Boundaries**: Read-only cursors don't need transactions, but if cursor includes updates, wrap in `TransactionScope`

**References**:
- IAsyncEnumerable: https://learn.microsoft.com/en-us/dotnet/csharp/asynchronous-programming/
- EF Core streaming: https://learn.microsoft.com/en-us/ef/core/performance/efficient-querying#streaming-results
- AsNoTracking performance: https://learn.microsoft.com/en-us/ef/core/querying/tracking

---

## R4: External Module Integration

**Decision**: Create C# service interfaces (`IReinsuranceService`, `ICalculationService`) to abstract external modules, implement mock versions initially, design for future integration or replacement

**Rationale**:
- COBOL modules RE0001S (reinsurance), GE0009S, GE0010S have LINKAGE SECTION parameters that can be mapped to C# method signatures
- Mocking allows migration to proceed without COBOL module source code or runtime
- Service abstraction enables future replacement with modern APIs or third-party services
- Testing strategy: mock services for unit tests, stub services for integration tests

**COBOL Module Call Example** (from RG1866B):
```cobol
CALL 'RE0001S' USING LKRE-PARM-RE0001S.

* LINKAGE SECTION structure
01 LKRE-PARM-RE0001S.
   05 LKRE-INPUT-AREA.
      10 LKRE-POLICY-NUMBER        PIC X(10).
      10 LKRE-EFFECTIVE-DATE       PIC 9(8).
      10 LKRE-PREMIUM-AMOUNT       PIC 9(13)V99.
   05 LKRE-OUTPUT-AREA.
      10 LKRE-RETAINED-PREMIUM     PIC 9(13)V99.
      10 LKRE-CEDED-PREMIUM        PIC 9(13)V99.
      10 LKRE-RETURN-CODE          PIC 9(2).
```

**C# Service Interface**:
```csharp
// Service contract matching COBOL module signature
public interface IReinsuranceService
{
    Task<ReinsuranceResult> CalculateReinsuranceAsync(ReinsuranceRequest request);
}

// Request DTO (maps to LKRE-INPUT-AREA)
public class ReinsuranceRequest
{
    [CobolField(PicClause = "X(10)")]
    public string PolicyNumber { get; set; }

    [CobolField(PicClause = "9(8)")]
    public DateTime EffectiveDate { get; set; }

    [CobolField(PicClause = "9(13)V99")]
    public decimal PremiumAmount { get; set; }
}

// Response DTO (maps to LKRE-OUTPUT-AREA)
public class ReinsuranceResult
{
    [CobolField(PicClause = "9(13)V99")]
    public decimal RetainedPremium { get; set; }

    [CobolField(PicClause = "9(13)V99")]
    public decimal CededPremium { get; set; }

    [CobolField(PicClause = "9(2)")]
    public int ReturnCode { get; set; }

    public bool IsSuccess => ReturnCode == 0;
    public string ErrorMessage { get; set; }
}

// Mock implementation for testing
public class MockReinsuranceService : IReinsuranceService
{
    public Task<ReinsuranceResult> CalculateReinsuranceAsync(ReinsuranceRequest request)
    {
        // Mock logic based on assumed business rules from COBOL analysis
        // For production, would need actual module logic or API integration
        var result = new ReinsuranceResult
        {
            RetainedPremium = request.PremiumAmount * 0.80m,  // Assume 80% retention
            CededPremium = request.PremiumAmount * 0.20m,     // Assume 20% ceded
            ReturnCode = 0
        };

        return Task.FromResult(result);
    }
}

// Real implementation option 1: COBOL module interop (if COBOL runtime available)
public class CobolReinsuranceService : IReinsuranceService
{
    [DllImport("RE0001S.dll", CallingConvention = CallingConvention.Cdecl)]
    private static extern void RE0001S(ref CobolLinkageArea linkage);

    public Task<ReinsuranceResult> CalculateReinsuranceAsync(ReinsuranceRequest request)
    {
        // Marshal request to COBOL structure
        var linkage = MarshalToCobol(request);

        // Call COBOL module
        RE0001S(ref linkage);

        // Marshal response from COBOL structure
        var result = MarshalFromCobol(linkage);

        return Task.FromResult(result);
    }
}

// Real implementation option 2: REST API wrapper (if modules exposed as services)
public class ApiReinsuranceService : IReinsuranceService
{
    private readonly HttpClient _httpClient;

    public async Task<ReinsuranceResult> CalculateReinsuranceAsync(ReinsuranceRequest request)
    {
        var response = await _httpClient.PostAsJsonAsync("/api/reinsurance/calculate", request);
        response.EnsureSuccessStatusCode();
        return await response.Content.ReadFromJsonAsync<ReinsuranceResult>();
    }
}
```

**Alternatives Considered**:
1. **Direct P/Invoke to COBOL DLLs** - Rejected: Requires COBOL runtime on .NET server, marshalling complexity, not cross-platform
2. **Reverse-engineer and reimplement in C#** - Rejected: High risk of logic errors, time-consuming, requires deep business knowledge
3. **Keep COBOL modules in separate process** - Rejected: Adds deployment complexity, inter-process communication overhead

**Implementation Notes**:

- **Dependency Injection Setup**:
```csharp
// In Program.cs
builder.Services.AddScoped<IReinsuranceService, MockReinsuranceService>();  // For development
// builder.Services.AddScoped<IReinsuranceService, CobolReinsuranceService>();  // For production with COBOL runtime
// builder.Services.AddScoped<IReinsuranceService, ApiReinsuranceService>();  // For production with API gateway
```

- **Testing Strategy**:
  - Unit tests use `Mock<IReinsuranceService>` with Moq library
  - Integration tests use `MockReinsuranceService` with controlled test data
  - Validation tests compare mock outputs against documented COBOL module examples (if available)

- **Documentation Requirement**: Document assumptions for each mocked module in `docs/migration/external-modules.md`

**References**:
- P/Invoke fundamentals: https://learn.microsoft.com/en-us/dotnet/standard/native-interop/pinvoke
- Dependency injection: https://learn.microsoft.com/en-us/aspnet/core/fundamentals/dependency-injection
- Testing with Moq: https://github.com/moq/moq4/wiki/Quickstart

---

## R5: Transaction Boundary Replication

**Decision**: Use explicit `TransactionScope` with `TransactionScopeAsyncFlowOption.Enabled` for multi-operation transactions, matching COBOL COMMIT points exactly

**Rationale**:
- COBOL program has explicit COMMIT statements after completing logical units of work (e.g., after processing all records for a report)
- EF Core `SaveChanges()` auto-commits each time called - must wrap multiple saves in transaction to match COBOL semantics
- `TransactionScope` enables distributed transactions if future production requires multiple databases
- Async flow option required for async/await code paths

**COBOL Transaction Example**:
```cobol
* Process all premium records
PERFORM VARYING WS-IDX FROM 1 BY 1 UNTIL WS-IDX > WS-TOTAL-RECORDS
    PERFORM PROCESS-RECORD
    IF SQL-ERROR
        EXEC SQL ROLLBACK END-EXEC
        PERFORM ERROR-HANDLING
        STOP RUN
    END-IF
END-PERFORM.

* Commit all changes if successful
EXEC SQL COMMIT END-EXEC.
```

**C# Equivalent**:
```csharp
public async Task<ReportResult> GenerateReportAsync(DateTime startDate, DateTime endDate)
{
    using var scope = new TransactionScope(
        TransactionScopeOption.Required,
        new TransactionOptions { IsolationLevel = IsolationLevel.ReadCommitted },
        TransactionScopeAsyncFlowOption.Enabled);  // CRITICAL for async methods

    try
    {
        // Process all records (read-only in this case, but pattern shows transaction usage)
        int recordsProcessed = 0;
        await foreach (var premium in _repository.GetPremiumsAsync(startDate, endDate))
        {
            await ProcessPremiumRecord(premium);
            recordsProcessed++;
        }

        // Write report metadata to database (this DOES modify database)
        var reportMetadata = new ReportDefinition
        {
            ReportDate = DateTime.Now,
            StartDate = startDate,
            EndDate = endDate,
            RecordsProcessed = recordsProcessed,
            Status = ReportStatus.Completed
        };

        await _context.Reports.AddAsync(reportMetadata);
        await _context.SaveChangesAsync();  // Part of transaction

        // COMMIT equivalent
        scope.Complete();

        return new ReportResult { Success = true, RecordsProcessed = recordsProcessed };
    }
    catch (Exception ex)
    {
        // ROLLBACK automatic when scope disposes without Complete()
        _logger.LogError(ex, "Report generation failed, transaction rolled back");
        throw;
    }
}
```

**EF Core-Specific Pattern** (alternative to TransactionScope):
```csharp
public async Task<Result> MultiStepOperationAsync()
{
    using var transaction = await _context.Database.BeginTransactionAsync(IsolationLevel.ReadCommitted);

    try
    {
        // Step 1: Insert report header
        var report = new Report { /*...*/ };
        _context.Reports.Add(report);
        await _context.SaveChangesAsync();  // Writes to database but not committed yet

        // Step 2: Insert report details
        foreach (var detail in reportDetails)
        {
            _context.ReportDetails.Add(detail);
        }
        await _context.SaveChangesAsync();  // Still in same transaction

        // COMMIT
        await transaction.CommitAsync();

        return Result.Success();
    }
    catch (Exception ex)
    {
        // ROLLBACK
        await transaction.RollbackAsync();
        _logger.LogError(ex, "Transaction failed");
        return Result.Failure(ex.Message);
    }
}
```

**Alternatives Considered**:
1. **Auto-commit with SaveChanges()** - Rejected: Can't replicate COBOL multi-step transactions, risk of partial updates
2. **Manual SQL transactions** - Rejected: Loses EF Core benefits, harder to maintain
3. **Saga pattern** - Rejected: Overkill for single-database operations, adds complexity

**Implementation Notes**:

- **Isolation Levels**:
  - COBOL default: typically `ReadCommitted`
  - Match COBOL isolation level in C#: `IsolationLevel.ReadCommitted`
  - For COBOL `SELECT FOR UPDATE`: use `IsolationLevel.Serializable` or EF Core `.FromSqlRaw("SELECT ... FOR UPDATE")`

- **Deadlock Handling** (matches COBOL -911 SQLCODE):
```csharp
public async Task<Result> OperationWithDeadlockRetryAsync()
{
    int maxRetries = 3;
    int retryCount = 0;

    while (retryCount < maxRetries)
    {
        try
        {
            using var scope = new TransactionScope(/* ... */);
            // Perform operations
            scope.Complete();
            return Result.Success();
        }
        catch (DbUpdateException ex) when (IsDeadlock(ex))
        {
            retryCount++;
            if (retryCount >= maxRetries) throw;

            _logger.LogWarning($"Deadlock detected, retry {retryCount}/{maxRetries}");
            await Task.Delay(TimeSpan.FromMilliseconds(100 * retryCount));  // Exponential backoff
        }
    }
}

private bool IsDeadlock(DbUpdateException ex)
{
    // SQLite: SQLITE_BUSY (5), SQL Server: 1205, DB2: -911
    return ex.InnerException?.Message.Contains("deadlock") == true;
}
```

- **Read-Only Operations**: Don't need transactions unless multiple reads must be consistent snapshot

**References**:
- TransactionScope: https://learn.microsoft.com/en-us/dotnet/api/system.transactions.transactionscope
- EF Core transactions: https://learn.microsoft.com/en-us/ef/core/saving/transactions
- Isolation levels: https://learn.microsoft.com/en-us/sql/t-sql/statements/set-transaction-isolation-level-transact-sql

---

## R6: Caixa Seguradora Branding Implementation

**Decision**: Extract color palette and typography from website, implement with TailwindCSS custom theme configuration, use shadcn/ui component library as foundation with Caixa Seguradora customization

**Rationale**:
- TailwindCSS provides utility-first CSS matching modern React best practices, easy to customize with brand colors
- shadcn/ui offers accessible, unstyled components (headless UI) that can be themed to match Caixa Seguradora branding exactly
- Extracting colors directly from website ensures brand consistency
- Component library approach ensures UI consistency across all pages

**Brand Analysis** (from https://www.caixaseguradora.com.br/):

**Color Palette**:
```css
/* Primary Colors */
--caixa-blue: #0047BB;          /* Primary brand color (header, buttons) */
--caixa-blue-dark: #003380;     /* Darker blue for hover states */
--caixa-blue-light: #E6F0FF;    /* Light blue for backgrounds */

/* Secondary Colors */
--caixa-yellow: #FFB81C;        /* Accent color (CTA buttons, highlights) */
--caixa-yellow-dark: #E6A519;   /* Darker yellow for hover */

/* Neutral Colors */
--caixa-gray-900: #1A1A1A;      /* Headings */
--caixa-gray-700: #4A4A4A;      /* Body text */
--caixa-gray-400: #BDBDBD;      /* Borders */
--caixa-gray-100: #F5F5F5;      /* Light backgrounds */
--caixa-white: #FFFFFF;         /* White */

/* Semantic Colors */
--caixa-success: #28A745;       /* Success messages */
--caixa-error: #DC3545;         /* Error messages */
--caixa-warning: #FFC107;       /* Warning messages */
--caixa-info: #17A2B8;          /* Info messages */
```

**Typography Stack**:
```css
/* Font Families */
--font-primary: 'Segoe UI', 'Helvetica Neue', Arial, sans-serif;  /* Body text */
--font-headings: 'Segoe UI', 'Helvetica Neue', Arial, sans-serif;  /* Headings */

/* Font Sizes (Tailwind scale) */
--text-xs: 0.75rem;     /* 12px */
--text-sm: 0.875rem;    /* 14px */
--text-base: 1rem;      /* 16px */
--text-lg: 1.125rem;    /* 18px */
--text-xl: 1.25rem;     /* 20px */
--text-2xl: 1.5rem;     /* 24px */
--text-3xl: 1.875rem;   /* 30px */
--text-4xl: 2.25rem;    /* 36px */

/* Font Weights */
--font-normal: 400;
--font-medium: 500;
--font-semibold: 600;
--font-bold: 700;
```

**Implementation**:

**1. Tailwind Configuration** (`tailwind.config.js`):
```javascript
/** @type {import('tailwindcss').Config} */
export default {
  content: [
    "./index.html",
    "./src/**/*.{js,ts,jsx,tsx}",
  ],
  theme: {
    extend: {
      colors: {
        caixa: {
          blue: {
            DEFAULT: '#0047BB',
            dark: '#003380',
            light: '#E6F0FF',
          },
          yellow: {
            DEFAULT: '#FFB81C',
            dark: '#E6A519',
          },
          gray: {
            900: '#1A1A1A',
            700: '#4A4A4A',
            400: '#BDBDBD',
            100: '#F5F5F5',
          },
        },
        success: '#28A745',
        error: '#DC3545',
        warning: '#FFC107',
        info: '#17A2B8',
      },
      fontFamily: {
        sans: ['Segoe UI', 'Helvetica Neue', 'Arial', 'sans-serif'],
      },
    },
  },
  plugins: [],
}
```

**2. Global Styles** (`src/styles/globals.css`):
```css
@tailwind base;
@tailwind components;
@tailwind utilities;

@layer base {
  body {
    @apply font-sans text-base text-caixa-gray-700 bg-white;
  }

  h1 {
    @apply text-4xl font-bold text-caixa-gray-900;
  }

  h2 {
    @apply text-3xl font-semibold text-caixa-gray-900;
  }

  h3 {
    @apply text-2xl font-semibold text-caixa-gray-900;
  }
}

@layer components {
  .btn-primary {
    @apply bg-caixa-blue hover:bg-caixa-blue-dark text-white font-medium px-4 py-2 rounded transition-colors;
  }

  .btn-secondary {
    @apply bg-caixa-yellow hover:bg-caixa-yellow-dark text-caixa-gray-900 font-medium px-4 py-2 rounded transition-colors;
  }

  .card {
    @apply bg-white border border-caixa-gray-400 rounded-lg shadow-sm p-6;
  }
}
```

**3. Component Example** (Header with branding):
```tsx
export function Header() {
  return (
    <header className="bg-caixa-blue text-white shadow-md">
      <div className="container mx-auto px-4 py-4 flex items-center justify-between">
        <div className="flex items-center space-x-4">
          <img
            src="/assets/logo-caixa.png"
            alt="Caixa Seguradora"
            className="h-10"
          />
          <h1 className="text-2xl font-bold text-white">
            Sistema de Relatórios SUSEP
          </h1>
        </div>

        <nav className="flex space-x-6">
          <a href="/dashboard" className="hover:text-caixa-yellow transition-colors">
            Dashboard
          </a>
          <a href="/reports" className="hover:text-caixa-yellow transition-colors">
            Relatórios
          </a>
          <a href="/query" className="hover:text-caixa-yellow transition-colors">
            Consultas
          </a>
        </nav>
      </div>
    </header>
  );
}
```

**Alternatives Considered**:
1. **Material-UI with theme override** - Rejected: Harder to match exact branding, larger bundle size, opinionated styling
2. **Bootstrap with SASS customization** - Rejected: Less modern than Tailwind, more opinionated class names
3. **Pure CSS** - Rejected: Harder to maintain consistency, no utility classes, slower development

**Implementation Notes**:

- **Logo Usage**: Verify licensing for Caixa Seguradora logo - may need written permission for internal application usage
- **Accessibility**: Ensure color contrast ratios meet WCAG AA standards (blue #0047BB on white passes at 8.59:1)
- **Responsive Design**: Use Tailwind responsive prefixes (`sm:`, `md:`, `lg:`, `xl:`) for mobile-first design
- **Dark Mode**: Not required per spec, but Tailwind supports if needed future

**References**:
- TailwindCSS customization: https://tailwindcss.com/docs/theme
- shadcn/ui components: https://ui.shadcn.com/
- WCAG contrast checker: https://webaim.org/resources/contrastchecker/

---

## R7: SQLite to DB2 Compatibility Layer

**Decision**: Document SQL dialect differences, create abstract repository layer to isolate database-specific queries, use EF Core query translation with custom SQLite functions for DB2-specific operations

**Rationale**:
- SQLite chosen for development to avoid mainframe access requirement, but must be production-ready for DB2 migration
- Repository pattern abstracts database access - switching from SQLite to DB2 only requires changing connection string and minor query adjustments
- EF Core LINQ queries translate to both SQLite and DB2 SQL, minimizing dialect-specific code
- Known limitations can be worked around with documented patterns

**Key Differences & Solutions**:

| Feature | COBOL/DB2 | SQLite | Solution |
|---------|-----------|--------|----------|
| **Date Functions** | `DAYS(date1) - DAYS(date2)` | `julianday(date1) - julianday(date2)` | Abstract in repository method `GetDaysBetween()` |
| **String Functions** | `SUBSTR(str, pos, len)` (1-indexed) | `substr(str, pos, len)` (1-indexed, compatible!) | No change needed |
| **Decimal Precision** | `DECIMAL(p, s)` explicit | SQLite stores as TEXT or REAL | EF Core maps `decimal` correctly, validate precision in tests |
| **Stored Procedures** | Supported | Not supported | Move logic to C# service layer |
| **Cursors** | Native DECLARE CURSOR | Not needed | Use IAsyncEnumerable as shown in R3 |
| **Isolation Levels** | Full ACID with READ COMMITTED default | Serialized by default (single writer) | Use `PRAGMA read_uncommitted=1` for testing concurrency |
| **Sequences** | `CREATE SEQUENCE`, `NEXTVAL` | `AUTOINCREMENT` on INTEGER PRIMARY KEY | Use EF Core value generation, abstracts both |

**Repository Abstraction Example**:
```csharp
public interface IPremiumRepository
{
    Task<IEnumerable<PremiumRecord>> GetPremiumsByDateRangeAsync(DateTime startDate, DateTime endDate);
    Task<int> GetDaysBetweenDatesAsync(DateTime date1, DateTime date2);
}

// SQLite implementation
public class SqlitePremiumRepository : IPremiumRepository
{
    private readonly ApplicationDbContext _context;

    public async Task<int> GetDaysBetweenDatesAsync(DateTime date1, DateTime date2)
    {
        // SQLite-specific function
        var sql = "SELECT CAST(julianday(@date1) - julianday(@date2) AS INTEGER)";
        return await _context.Database.ExecuteSqlRawAsync(sql,
            new SqliteParameter("@date1", date1),
            new SqliteParameter("@date2", date2));
    }
}

// DB2 implementation (for future production)
public class Db2PremiumRepository : IPremiumRepository
{
    private readonly ApplicationDbContext _context;

    public async Task<int> GetDaysBetweenDatesAsync(DateTime date1, DateTime date2)
    {
        // DB2-specific function
        var sql = "SELECT DAYS(@date1) - DAYS(@date2) FROM SYSIBM.SYSDUMMY1";
        return await _context.Database.ExecuteSqlRawAsync(sql,
            new Db2Parameter("@date1", date1),
            new Db2Parameter("@date2", date2));
    }
}
```

**EF Core Configuration**:
```csharp
// Startup configuration
services.AddDbContext<ApplicationDbContext>(options =>
{
    if (isDevelopment)
    {
        options.UseSqlite(connectionString, sqliteOptions =>
        {
            sqliteOptions.UseQuerySplittingBehavior(QuerySplittingBehavior.SplitQuery);
        });
    }
    else
    {
        options.UseDb2(connectionString, db2Options =>
        {
            db2Options.SetServerInfo(new DB2ServerInfo { ServerType = DB2ServerType.LUW });
        });
    }
});
```

**Alternatives Considered**:
1. **Use DB2 Express-C for development** - Rejected: Complex setup, licensing questions, doesn't run well on macOS/Linux dev machines
2. **PostgreSQL as dev database** - Rejected: Still requires server setup, SQLite simpler for POC
3. **In-memory database** - Rejected: Loses data between runs, harder to inspect data for debugging

**Implementation Notes**:

- **Schema Generation**: Create SQLite schema matching DB2 exactly (table names, column names, data types)
```sql
-- Example matching V0PREMIOS view structure
CREATE TABLE V0PREMIOS (
    POLICY_NUMBER VARCHAR(10) NOT NULL,
    PREMIUM_AMOUNT DECIMAL(15, 2) NOT NULL,
    EFFECTIVE_DATE DATE NOT NULL,
    PRODUCT_CODE VARCHAR(5),
    /* ... 50+ columns matching DB2 view */
    PRIMARY KEY (POLICY_NUMBER, EFFECTIVE_DATE)
);

CREATE INDEX IDX_V0PREMIOS_DATE ON V0PREMIOS(EFFECTIVE_DATE);
```

- **Mock Data Loading**: Create CSV files matching DB2 export format, load with SQLite `.import` command or bulk insert via EF Core

- **Type Mapping Validation**: Write unit tests confirming decimal precision maintained:
```csharp
[Fact]
public void DecimalPrecision_MaintainedInSqlite()
{
    var value = 123456789012345.67m;  // 15 digits + 2 decimal places

    _context.TestDecimals.Add(new TestDecimal { Value = value });
    _context.SaveChanges();

    var retrieved = _context.TestDecimals.First().Value;

    Assert.Equal(value, retrieved);  // Must be exact match
}
```

**References**:
- SQLite vs DB2 comparison: https://db-engines.com/en/system/DB2%3BSQLite
- EF Core SQLite provider: https://learn.microsoft.com/en-us/ef/core/providers/sqlite/
- IBM Db2 .NET provider: https://www.ibm.com/docs/en/db2/11.5?topic=apis-db2-net

---

## R8: Performance Baseline Establishment

**Decision**: Use BenchmarkDotNet for micro-benchmarks, Application Insights or Serilog + Seq for production profiling, custom comparison framework to validate .NET performance vs COBOL baseline

**Rationale**:
- Need quantitative evidence that .NET migration meets success criteria (within 120% of COBOL execution time)
- BenchmarkDotNet industry standard for .NET performance testing, provides statistical analysis and warmup handling
- Continuous profiling during development catches regressions early
- Success criteria includes specific metrics (10,000 records in 5 minutes, dashboard load in 2 seconds)

**Benchmark Framework**:
```csharp
using BenchmarkDotNet.Attributes;
using BenchmarkDotNet.Running;

[MemoryDiagnoser]
[SimpleJob(iterationCount: 10, warmupCount: 5)]
public class ReportGenerationBenchmark
{
    private IReportService _reportService;
    private DateTime _startDate;
    private DateTime _endDate;

    [GlobalSetup]
    public void Setup()
    {
        // Initialize service with test database
        _reportService = new ReportService(/* dependencies */);
        _startDate = new DateTime(2025, 1, 1);
        _endDate = new DateTime(2025, 1, 31);
    }

    [Benchmark]
    public async Task GenerateReport_10000Records()
    {
        await _reportService.GenerateReportAsync(_startDate, _endDate);
    }

    [Benchmark]
    public async Task ProcessSingleRecord()
    {
        var premium = new PremiumRecord { /* test data */ };
        await _reportService.ProcessPremiumRecordAsync(premium);
    }
}

// Run benchmarks
class Program
{
    static void Main(string[] args)
    {
        var summary = BenchmarkRunner.Run<ReportGenerationBenchmark>();

        // Compare against COBOL baseline
        var cobolBaseline = TimeSpan.FromMinutes(4.5);  // Example: COBOL takes 4.5 min
        var dotnetActual = summary.Reports.First().ResultStatistics.Mean;
        var tolerance = 1.2;  // 120% per success criteria

        if (dotnetActual <= cobolBaseline.TotalSeconds * tolerance)
        {
            Console.WriteLine($"✓ Performance OK: {dotnetActual}s vs {cobolBaseline.TotalSeconds}s baseline (limit: {cobolBaseline.TotalSeconds * tolerance}s)");
        }
        else
        {
            Console.WriteLine($"✗ Performance FAILED: {dotnetActual}s exceeds {tolerance}x baseline");
        }
    }
}
```

**Profiling Setup** (Development):
```csharp
// Program.cs
builder.Services.AddSerilog(config =>
{
    config
        .Enrich.FromLogContext()
        .Enrich.WithProperty("Application", "CaixaSeguradora.Api")
        .WriteTo.Console()
        .WriteTo.Seq("http://localhost:5341")  // Seq for log aggregation
        .WriteTo.File("logs/app-.txt", rollingInterval: RollingInterval.Day);
});

// Middleware for request timing
public class PerformanceLoggingMiddleware
{
    private readonly RequestDelegate _next;
    private readonly ILogger<PerformanceLoggingMiddleware> _logger;

    public async Task InvokeAsync(HttpContext context)
    {
        var stopwatch = Stopwatch.StartNew();

        await _next(context);

        stopwatch.Stop();

        if (stopwatch.ElapsedMilliseconds > 500)  // Log slow requests
        {
            _logger.LogWarning(
                "Slow request: {Method} {Path} took {ElapsedMs}ms",
                context.Request.Method,
                context.Request.Path,
                stopwatch.ElapsedMilliseconds);
        }

        // Metrics for dashboard
        context.Response.Headers.Add("X-Response-Time-ms", stopwatch.ElapsedMilliseconds.ToString());
    }
}
```

**Comparison Test Framework**:
```csharp
public class PerformanceComparisonTests
{
    [Fact]
    public async Task ReportGeneration_MeetsPerformanceGoal()
    {
        // Arrange
        var startDate = new DateTime(2025, 1, 1);
        var endDate = new DateTime(2025, 1, 31);
        int expectedRecordCount = 10000;
        TimeSpan maxExecutionTime = TimeSpan.FromMinutes(5);  // Success criteria

        // Act
        var stopwatch = Stopwatch.StartNew();
        var result = await _reportService.GenerateReportAsync(startDate, endDate);
        stopwatch.Stop();

        // Assert
        Assert.Equal(expectedRecordCount, result.RecordsProcessed);
        Assert.True(stopwatch.Elapsed < maxExecutionTime,
            $"Report generation took {stopwatch.Elapsed.TotalMinutes:F2} minutes, exceeds {maxExecutionTime.TotalMinutes} minute limit");
    }

    [Fact]
    public async Task DashboardLoad_MeetsResponseTimeGoal()
    {
        // Arrange
        TimeSpan maxResponseTime = TimeSpan.FromSeconds(2);  // Success criteria

        // Act
        var stopwatch = Stopwatch.StartNew();
        var metrics = await _dashboardService.GetMetricsAsync();
        stopwatch.Stop();

        // Assert
        Assert.NotNull(metrics);
        Assert.True(stopwatch.Elapsed < maxResponseTime,
            $"Dashboard load took {stopwatch.Elapsed.TotalSeconds:F2}s, exceeds {maxResponseTime.TotalSeconds}s limit");
    }
}
```

**Metrics Collection**:
```csharp
public class PerformanceMetrics
{
    public string OperationName { get; set; }
    public TimeSpan ExecutionTime { get; set; }
    public long MemoryUsedBytes { get; set; }
    public int RecordsProcessed { get; set; }
    public DateTime Timestamp { get; set; }

    // Comparison with COBOL baseline
    public TimeSpan? CobolBaseline { get; set; }
    public double PerformanceRatio => CobolBaseline.HasValue
        ? ExecutionTime.TotalSeconds / CobolBaseline.Value.TotalSeconds
        : 0;

    public bool MeetsSuccessCriteria => PerformanceRatio <= 1.2;  // Within 120%
}

// Metrics storage
public class MetricsRepository
{
    public async Task SaveMetricsAsync(PerformanceMetrics metrics)
    {
        await _context.PerformanceMetrics.AddAsync(metrics);
        await _context.SaveChangesAsync();
    }

    public async Task<PerformanceReport> GetPerformanceReportAsync(string operationName)
    {
        var recent = await _context.PerformanceMetrics
            .Where(m => m.OperationName == operationName)
            .OrderByDescending(m => m.Timestamp)
            .Take(100)
            .ToListAsync();

        return new PerformanceReport
        {
            OperationName = operationName,
            AverageExecutionTime = TimeSpan.FromSeconds(recent.Average(m => m.ExecutionTime.TotalSeconds)),
            MinExecutionTime = recent.Min(m => m.ExecutionTime),
            MaxExecutionTime = recent.Max(m => m.ExecutionTime),
            AveragePerformanceRatio = recent.Where(m => m.CobolBaseline.HasValue).Average(m => m.PerformanceRatio),
            MeetsSuccessCriteria = recent.All(m => m.MeetsSuccessCriteria)
        };
    }
}
```

**Alternatives Considered**:
1. **Manual timing with Stopwatch** - Rejected: No statistical analysis, no warmup handling, harder to compare runs
2. **Application Insights only** - Rejected: Overkill for development, requires Azure subscription
3. **Custom benchmark framework** - Rejected: Reinventing wheel, BenchmarkDotNet battle-tested

**Implementation Notes**:

- **COBOL Baseline Acquisition**: If possible, run COBOL system with instrumentation to get actual timings; otherwise estimate from user reports or job logs
- **Environment Consistency**: Run benchmarks on equivalent hardware (COBOL on mainframe vs .NET on x86 server isn't apples-to-apples, but document differences)
- **Continuous Monitoring**: Integrate benchmark runs into CI/CD pipeline to catch regressions
- **Visualization**: Build dashboard showing performance trends over time (part of User Story 1)

**References**:
- BenchmarkDotNet: https://benchmarkdotnet.org/
- Serilog: https://serilog.net/
- Seq log server: https://datalust.co/seq
- Application Insights: https://learn.microsoft.com/en-us/azure/azure-monitor/app/app-insights-overview

---

## Summary

All 8 research areas have been thoroughly investigated with concrete technical decisions documented. Key takeaways:

**Critical Decisions for Regulatory Compliance**:
1. **R1**: C# `decimal` type mandatory for all financial calculations
2. **R2**: Custom fixed-width formatter with byte-level validation
3. **R3**: Streaming with `IAsyncEnumerable` for memory efficiency
4. **R5**: Explicit transaction boundaries matching COBOL COMMIT points

**Pragmatic Development Decisions**:
1. **R4**: Mock external modules initially, design for future integration
2. **R6**: TailwindCSS + shadcn/ui for rapid, branded UI development
3. **R7**: SQLite for development with repository abstraction for DB2 migration
4. **R8**: BenchmarkDotNet for continuous performance validation

**Risk Mitigation**:
- All decisions include fallback alternatives
- Performance testing integrated from start
- Regulatory compliance validated through byte comparison
- Abstraction layers enable future production migration (SQLite → DB2)

**Next Steps**: Proceed to Phase 1 (Data Model Design, API Contracts, Quickstart Guide)

---

**Research Complete**: October 22, 2025
**Approved For**: Phase 1 Design



**BMAD EXECUTION CONTEXT:**
## research.md
```
// Custom attribute for COBOL type metadata
[AttributeUsage(AttributeTargets.Property)]
public class CobolFieldAttribute : Attribute
{
    public string PicClause { get; set; }
    public int Length { get; set; }
    public int DecimalPlaces { get; set; }
    public CobolFieldType FieldType { get; set; }
}

// Example entity with COBOL mapping
public class Premium
{
    [CobolField(PicClause = "9(15)V99", Length = 17, DecimalPlaces = 2)]
    public decimal PremiumAmount { get; set; }  // Maps to PIC 9(15)V99

    [CobolField(PicClause = "X(10)", Length = 10)]
    public string PolicyNumber { get; set; }  // Maps to PIC X(10)

    [CobolField(PicClause = "9(8)", Length = 8)]
    public DateTime EffectiveDate { get; set; }  // YYYYMMDD format
}

// Rounding mode matching COBOL
public static class CobolMath
{
    // COBOL ROUND mode equivalent
    public static decimal RoundAwayFromZero(decimal value, int decimals)
    {
        return Math.Round(value, decimals, MidpointRounding.AwayFromZero);
    }

    // COBOL TRUNCATE equivalent
    public static decimal Truncate(decimal value, int decimals)
    {
        decimal multiplier = (decimal)Math.Pow(10, decimals);
        return Math.Truncate(value * multiplier) / multiplier;
    }
}

```
```
public class FixedWidthFormatter
{
    public string FormatNumeric(decimal value, int totalWidth, int decimalPlaces, bool includeDecimalPoint = false)
    {
        // COBOL PIC 9(n)V9(m) - V means implied decimal, not printed
        if (!includeDecimalPoint)
        {
            // Multiply by 10^decimalPlaces to get integer representation
            decimal multiplied = value * (decimal)Math.Pow(10, decimalPlaces);
            long intValue = (long)Math.Round(multiplied, MidpointRounding.AwayFromZero);
            return intValue.ToString().PadLeft(totalWidth, '0');
        }
        else
        {
            // Explicit decimal point (rare in COBOL output files)
            string formatted = value.ToString($"F{decimalPlaces}");
            return formatted.PadLeft(totalWidth, '0');
        }
    }

    public string FormatAlphanumeric(string value, int width)
    {
        // COBOL PIC X(n) - right-pad with spaces
        if (value == null) value = "";
        if (value.Length > width) value = value.Substring(0, width);  // Truncate if too long
        return value.PadRight(width, ' ');
    }

    public string FormatDate(DateTime date, string format = "yyyyMMdd")
    {
        // COBOL date formats: YYYYMMDD, DDMMYYYY, YYMMDD
        return date.ToString(format);
    }

    // Example usage for PREMIT.TXT record
    public string FormatPremitRecord(PremiumRecord record)
    {
        var sb = new StringBuilder();
        sb.Append(FormatAlphanumeric(record.PolicyNumber, 10));
        sb.Append(FormatNumeric(record.PremiumAmount, 15, 2));  // PIC 9(13)V99
        sb.Append(FormatDate(record.EffectiveDate));
        sb.Append(FormatAlphanumeric(record.ProductCode, 5));
        // ... continue for all 50+ fields in layout
        return sb.ToString();
    }
}

// Validation: Byte-level comparison
public class OutputValidator
{
    public ComparisonResult CompareFiles(string cobolFile, string dotnetFile)
    {
        byte[] cobolBytes = File.ReadAllBytes(cobolFile);
        byte[] dotnetBytes = File.ReadAllBytes(dotnetFile);

        if (cobolBytes.Length != dotnetBytes.Length)
        {
            return new ComparisonResult
            {
                Match = false,
                Error = $"File size mismatch: {cobolBytes.Length} vs {dotnetBytes.Length}"
            };
        }

        for (int i = 0; i < cobolBytes.Length; i++)
        {
            if (cobolBytes[i] != dotnetBytes[i])
            {
                return new ComparisonResult
                {
                    Match = false,
                    Error = $"Byte mismatch at position {i}: {cobolBytes[i]} vs {dotnetBytes[i]}",
                    Context = GetContext(dotnetBytes, i, 50)
                };
            }
        }

        return new ComparisonResult { Match = true };
    }
}

```
```
EXEC SQL
    DECLARE C1 CURSOR FOR
        SELECT POLICY_NUM, PREMIUM_AMT, EFFECTIVE_DATE
        FROM V0PREMIOS
        WHERE EFFECTIVE_DATE BETWEEN :START-DATE AND :END-DATE
END-EXEC.

EXEC SQL OPEN C1 END-EXEC.

PERFORM UNTIL SQLCODE NOT = 0
    EXEC SQL FETCH C1 INTO :WS-POLICY-NUM, :WS-PREMIUM-AMT, :WS-EFFECTIVE-DATE END-EXEC
    IF SQLCODE = 0
        PERFORM PROCESS-RECORD
    END-IF
END-PERFORM.

EXEC SQL CLOSE C1 END-EXEC.

```
```
// Repository method with streaming
public async IAsyncEnumerable<PremiumRecord> GetPremiumsAsync(
    DateTime startDate,
    DateTime endDate,
    [EnumeratorCancellation] CancellationToken cancellationToken = default)
{
    var query = _context.Premiums
        .AsNoTracking()  // Disable change tracking (read-only)
        .Where(p => p.EffectiveDate >= startDate && p.EffectiveDate <= endDate)
        .OrderBy(p => p.PolicyNumber);  // Match COBOL cursor ordering

    await foreach (var record in query.AsAsyncEnumerable().WithCancellation(cancellationToken))
    {
        yield return record;
    }
}

// Service layer processing (matches COBOL PERFORM loop)
public async Task<ReportResult> GenerateReportAsync(DateTime startDate, DateTime endDate)
{
    int recordsProcessed = 0;
    var reportData = new List<ReportLine>();

    await foreach (var premium in _repository.GetPremiumsAsync(startDate, endDate))
    {
        // Process each record (equivalent to COBOL PERFORM PROCESS-RECORD)
        var reportLine = await ProcessPremiumRecord(premium);
        reportData.Add(reportLine);
        recordsProcessed++;

        // Optional: Report progress for long-running operations
        if (recordsProcessed % 1000 == 0)
        {
            _logger.LogInformation($"Processed {recordsProcessed} records");
        }
    }

    return new ReportResult { RecordsProcessed = recordsProcessed, Data = reportData };
}

```
```
// Batch writing pattern
public async Task WriteReportAsync(IAsyncEnumerable<ReportLine> lines, string filePath)
{
    using var writer = new StreamWriter(filePath, append: false, Encoding.UTF8);
    var batch = new List<string>(1000);

    await foreach (var line in lines)
    {
        batch.Add(_formatter.FormatLine(line));

        if (batch.Count >= 1000)
        {
            await writer.WriteAsync(string.Join(Environment.NewLine, batch));
            batch.Clear();
        }
    }

    // Write remaining records
    if (batch.Count > 0)
    {
        await writer.WriteAsync(string.Join(Environment.NewLine, batch));
    }
}

```
```
CALL 'RE0001S' USING LKRE-PARM-RE0001S.

* LINKAGE SECTION structure
01 LKRE-PARM-RE0001S.
   05 LKRE-INPUT-AREA.
      10 LKRE-POLICY-NUMBER        PIC X(10).
      10 LKRE-EFFECTIVE-DATE       PIC 9(8).
      10 LKRE-PREMIUM-AMOUNT       PIC 9(13)V99.
   05 LKRE-OUTPUT-AREA.
      10 LKRE-RETAINED-PREMIUM     PIC 9(13)V99.
      10 LKRE-CEDED-PREMIUM        PIC 9(13)V99.
      10 LKRE-RETURN-CODE          PIC 9(2).

```
```
// Service contract matching COBOL module signature
public interface IReinsuranceService
{
    Task<ReinsuranceResult> CalculateReinsuranceAsync(ReinsuranceRequest request);
}

// Request DTO (maps to LKRE-INPUT-AREA)
public class ReinsuranceRequest
{
    [CobolField(PicClause = "X(10)")]
    public string PolicyNumber { get; set; }

    [CobolField(PicClause = "9(8)")]
    public DateTime EffectiveDate { get; set; }

    [CobolField(PicClause = "9(13)V99")]
    public decimal PremiumAmount { get; set; }
}

// Response DTO (maps to LKRE-OUTPUT-AREA)
public class ReinsuranceResult
{
    [CobolField(PicClause = "9(13)V99")]
    public decimal RetainedPremium { get; set; }

    [CobolField(PicClause = "9(13)V99")]
    public decimal CededPremium { get; set; }

    [CobolField(PicClause = "9(2)")]
    public int ReturnCode { get; set; }

    public bool IsSuccess => ReturnCode == 0;
    public string ErrorMessage { get; set; }
}

// Mock implementation for testing
public class MockReinsuranceService : IReinsuranceService
{
    public Task<ReinsuranceResult> CalculateReinsuranceAsync(ReinsuranceRequest request)
    {
        // Mock logic based on assumed business rules from COBOL analysis
        // For production, would need actual module logic or API integration
        var result = new ReinsuranceResult
        {
            RetainedPremium = request.PremiumAmount * 0.80m,  // Assume 80% retention
            CededPremium = request.PremiumAmount * 0.20m,     // Assume 20% ceded
            ReturnCode = 0
        };

        return Task.FromResult(result);
    }
}

// Real implementation option 1: COBOL module interop (if COBOL runtime available)
public class CobolReinsuranceService : IReinsuranceService
{
    [DllImport("RE0001S.dll", CallingConvention = CallingConvention.Cdecl)]
    private static extern void RE0001S(ref CobolLinkageArea linkage);

    public Task<ReinsuranceResult> CalculateReinsuranceAsync(ReinsuranceRequest request)
    {
        // Marshal request to COBOL structure
        var linkage = MarshalToCobol(request);

        // Call COBOL module
        RE0001S(ref linkage);

        // Marshal response from COBOL structure
        var result = MarshalFromCobol(linkage);

        return Task.FromResult(result);
    }
}

// Real implementation option 2: REST API wrapper (if modules exposed as services)
public class ApiReinsuranceService : IReinsuranceService
{
    private readonly HttpClient _httpClient;

    public async Task<ReinsuranceResult> CalculateReinsuranceAsync(ReinsuranceRequest request)
    {
        var response = await _httpClient.PostAsJsonAsync("/api/reinsurance/calculate", request);
        response.EnsureSuccessStatusCode();
        return await response.Content.ReadFromJsonAsync<ReinsuranceResult>();
    }
}

```
```
// In Program.cs
builder.Services.AddScoped<IReinsuranceService, MockReinsuranceService>();  // For development
// builder.Services.AddScoped<IReinsuranceService, CobolReinsuranceService>();  // For production with COBOL runtime
// builder.Services.AddScoped<IReinsuranceService, ApiReinsuranceService>();  // For production with API gateway

```
```
* Process all premium records
PERFORM VARYING WS-IDX FROM 1 BY 1 UNTIL WS-IDX > WS-TOTAL-RECORDS
    PERFORM PROCESS-RECORD
    IF SQL-ERROR
        EXEC SQL ROLLBACK END-EXEC
        PERFORM ERROR-HANDLING
        STOP RUN
    END-IF
END-PERFORM.

* Commit all changes if successful
EXEC SQL COMMIT END-EXEC.

```
```
public async Task<ReportResult> GenerateReportAsync(DateTime startDate, DateTime endDate)
{
    using var scope = new TransactionScope(
        TransactionScopeOption.Required,
        new TransactionOptions { IsolationLevel = IsolationLevel.ReadCommitted },
        TransactionScopeAsyncFlowOption.Enabled);  // CRITICAL for async methods

    try
    {
        // Process all records (read-only in this case, but pattern shows transaction usage)
        int recordsProcessed = 0;
        await foreach (var premium in _repository.GetPremiumsAsync(startDate, endDate))
        {
            await ProcessPremiumRecord(premium);
            recordsProcessed++;
        }

        // Write report metadata to database (this DOES modify database)
        var reportMetadata = new ReportDefinition
        {
            ReportDate = DateTime.Now,
            StartDate = startDate,
            EndDate = endDate,
            RecordsProcessed = recordsProcessed,
            Status = ReportStatus.Completed
        };

        await _context.Reports.AddAsync(reportMetadata);
        await _context.SaveChangesAsync();  // Part of transaction

        // COMMIT equivalent
        scope.Complete();

        return new ReportResult { Success = true, RecordsProcessed = recordsProcessed };
    }
    catch (Exception ex)
    {
        // ROLLBACK automatic when scope disposes without Complete()
        _logger.LogError(ex, "Report generation failed, transaction rolled back");
        throw;
    }
}

```
```
public async Task<Result> MultiStepOperationAsync()
{
    using var transaction = await _context.Database.BeginTransactionAsync(IsolationLevel.ReadCommitted);

    try
    {
        // Step 1: Insert report header
        var report = new Report { /*...*/ };
        _context.Reports.Add(report);
        await _context.SaveChangesAsync();  // Writes to database but not committed yet

        // Step 2: Insert report details
        foreach (var detail in reportDetails)
        {
            _context.ReportDetails.Add(detail);
        }
        await _context.SaveChangesAsync();  // Still in same transaction

        // COMMIT
        await transaction.CommitAsync();

        return Result.Success();
    }
    catch (Exception ex)
    {
        // ROLLBACK
        await transaction.RollbackAsync();
        _logger.LogError(ex, "Transaction failed");
        return Result.Failure(ex.Message);
    }
}

```
```
public async Task<Result> OperationWithDeadlockRetryAsync()
{
    int maxRetries = 3;
    int retryCount = 0;

    while (retryCount < maxRetries)
    {
        try
        {
            using var scope = new TransactionScope(/* ... */);
            // Perform operations
            scope.Complete();
            return Result.Success();
        }
        catch (DbUpdateException ex) when (IsDeadlock(ex))
        {
            retryCount++;
            if (retryCount >= maxRetries) throw;

            _logger.LogWarning($"Deadlock detected, retry {retryCount}/{maxRetries}");
            await Task.Delay(TimeSpan.FromMilliseconds(100 * retryCount));  // Exponential backoff
        }
    }
}

private bool IsDeadlock(DbUpdateException ex)
{
    // SQLite: SQLITE_BUSY (5), SQL Server: 1205, DB2: -911
    return ex.InnerException?.Message.Contains("deadlock") == true;
}

```
```
/* Primary Colors */
--caixa-blue: #0047BB;          /* Primary brand color (header, buttons) */
--caixa-blue-dark: #003380;     /* Darker blue for hover states */
--caixa-blue-light: #E6F0FF;    /* Light blue for backgrounds */

/* Secondary Colors */
--caixa-yellow: #FFB81C;        /* Accent color (CTA buttons, highlights) */
--caixa-yellow-dark: #E6A519;   /* Darker yellow for hover */

/* Neutral Colors */
--caixa-gray-900: #1A1A1A;      /* Headings */
--caixa-gray-700: #4A4A4A;      /* Body text */
--caixa-gray-400: #BDBDBD;      /* Borders */
--caixa-gray-100: #F5F5F5;      /* Light backgrounds */
--caixa-white: #FFFFFF;         /* White */

/* Semantic Colors */
--caixa-success: #28A745;       /* Success messages */
--caixa-error: #DC3545;         /* Error messages */
--caixa-warning: #FFC107;       /* Warning messages */
--caixa-info: #17A2B8;          /* Info messages */

```
```
/* Font Families */
--font-primary: 'Segoe UI', 'Helvetica Neue', Arial, sans-serif;  /* Body text */
--font-headings: 'Segoe UI', 'Helvetica Neue', Arial, sans-serif;  /* Headings */

/* Font Sizes (Tailwind scale) */
--text-xs: 0.75rem;     /* 12px */
--text-sm: 0.875rem;    /* 14px */
--text-base: 1rem;      /* 16px */
--text-lg: 1.125rem;    /* 18px */
--text-xl: 1.25rem;     /* 20px */
--text-2xl: 1.5rem;     /* 24px */
--text-3xl: 1.875rem;   /* 30px */
--text-4xl: 2.25rem;    /* 36px */

/* Font Weights */
--font-normal: 400;
--font-medium: 500;
--font-semibold: 600;
--font-bold: 700;

```
```
/** @type {import('tailwindcss').Config} */
export default {
  content: [
    "./index.html",
    "./src/**/*.{js,ts,jsx,tsx}",
  ],
  theme: {
    extend: {
      colors: {
        caixa: {
          blue: {
            DEFAULT: '#0047BB',
            dark: '#003380',
            light: '#E6F0FF',
          },
          yellow: {
            DEFAULT: '#FFB81C',
            dark: '#E6A519',
          },
          gray: {
            900: '#1A1A1A',
            700: '#4A4A4A',
            400: '#BDBDBD',
            100: '#F5F5F5',
          },
        },
        success: '#28A745',
        error: '#DC3545',
        warning: '#FFC107',
        info: '#17A2B8',
      },
      fontFamily: {
        sans: ['Segoe UI', 'Helvetica Neue', 'Arial', 'sans-serif'],
      },
    },
  },
  plugins: [],
}

```
```
@tailwind base;
@tailwind components;
@tailwind utilities;

@layer base {
  body {
    @apply font-sans text-base text-caixa-gray-700 bg-white;
  }

  h1 {
    @apply text-4xl font-bold text-caixa-gray-900;
  }

  h2 {
    @apply text-3xl font-semibold text-caixa-gray-900;
  }

  h3 {
    @apply text-2xl font-semibold text-caixa-gray-900;
  }
}

@layer components {
  .btn-primary {
    @apply bg-caixa-blue hover:bg-caixa-blue-dark text-white font-medium px-4 py-2 rounded transition-colors;
  }

  .btn-secondary {
    @apply bg-caixa-yellow hover:bg-caixa-yellow-dark text-caixa-gray-900 font-medium px-4 py-2 rounded transition-colors;
  }

  .card {
    @apply bg-white border border-caixa-gray-400 rounded-lg shadow-sm p-6;
  }
}

```
```
export function Header() {
  return (
    <header className="bg-caixa-blue text-white shadow-md">
      <div className="container mx-auto px-4 py-4 flex items-center justify-between">
        <div className="flex items-center space-x-4">
          <img
            src="/assets/logo-caixa.png"
            alt="Caixa Seguradora"
            className="h-10"
          />
          <h1 className="text-2xl font-bold text-white">
            Sistema de Relatórios SUSEP
          </h1>
        </div>

        <nav className="flex space-x-6">
          <a href="/dashboard" className="hover:text-caixa-yellow transition-colors">
            Dashboard
          </a>
          <a href="/reports" className="hover:text-caixa-yellow transition-colors">
            Relatórios
          </a>
          <a href="/query" className="hover:text-caixa-yellow transition-colors">
            Consultas
          </a>
        </nav>
      </div>
    </header>
  );
}

```
```
public interface IPremiumRepository
{
    Task<IEnumerable<PremiumRecord>> GetPremiumsByDateRangeAsync(DateTime startDate, DateTime endDate);
    Task<int> GetDaysBetweenDatesAsync(DateTime date1, DateTime date2);
}

// SQLite implementation
public class SqlitePremiumRepository : IPremiumRepository
{
    private readonly ApplicationDbContext _context;

    public async Task<int> GetDaysBetweenDatesAsync(DateTime date1, DateTime date2)
    {
        // SQLite-specific function
        var sql = "SELECT CAST(julianday(@date1) - julianday(@date2) AS INTEGER)";
        return await _context.Database.ExecuteSqlRawAsync(sql,
            new SqliteParameter("@date1", date1),
            new SqliteParameter("@date2", date2));
    }
}

// DB2 implementation (for future production)
public class Db2PremiumRepository : IPremiumRepository
{
    private readonly ApplicationDbContext _context;

    public async Task<int> GetDaysBetweenDatesAsync(DateTime date1, DateTime date2)
    {
        // DB2-specific function
        var sql = "SELECT DAYS(@date1) - DAYS(@date2) FROM SYSIBM.SYSDUMMY1";
        return await _context.Database.ExecuteSqlRawAsync(sql,
            new Db2Parameter("@date1", date1),
            new Db2Parameter("@date2", date2));
    }
}

```
```
// Startup configuration
services.AddDbContext<ApplicationDbContext>(options =>
{
    if (isDevelopment)
    {
        options.UseSqlite(connectionString, sqliteOptions =>
        {
            sqliteOptions.UseQuerySplittingBehavior(QuerySplittingBehavior.SplitQuery);
        });
    }
    else
    {
        options.UseDb2(connectionString, db2Options =>
        {
            db2Options.SetServerInfo(new DB2ServerInfo { ServerType = DB2ServerType.LUW });
        });
    }
});

```
```
-- Example matching V0PREMIOS view structure
CREATE TABLE V0PREMIOS (
    POLICY_NUMBER VARCHAR(10) NOT NULL,
    PREMIUM_AMOUNT DECIMAL(15, 2) NOT NULL,
    EFFECTIVE_DATE DATE NOT NULL,
    PRODUCT_CODE VARCHAR(5),
    /* ... 50+ columns matching DB2 view */
    PRIMARY KEY (POLICY_NUMBER, EFFECTIVE_DATE)
);

CREATE INDEX IDX_V0PREMIOS_DATE ON V0PREMIOS(EFFECTIVE_DATE);

```
```
[Fact]
public void DecimalPrecision_MaintainedInSqlite()
{
    var value = 123456789012345.67m;  // 15 digits + 2 decimal places

    _context.TestDecimals.Add(new TestDecimal { Value = value });
    _context.SaveChanges();

    var retrieved = _context.TestDecimals.First().Value;

    Assert.Equal(value, retrieved);  // Must be exact match
}

```
```
using BenchmarkDotNet.Attributes;
using BenchmarkDotNet.Running;

[MemoryDiagnoser]
[SimpleJob(iterationCount: 10, warmupCount: 5)]
public class ReportGenerationBenchmark
{
    private IReportService _reportService;
    private DateTime _startDate;
    private DateTime _endDate;

    [GlobalSetup]
    public void Setup()
    {
        // Initialize service with test database
        _reportService = new ReportService(/* dependencies */);
        _startDate = new DateTime(2025, 1, 1);
        _endDate = new DateTime(2025, 1, 31);
    }

    [Benchmark]
    public async Task GenerateReport_10000Records()
    {
        await _reportService.GenerateReportAsync(_startDate, _endDate);
    }

    [Benchmark]
    public async Task ProcessSingleRecord()
    {
        var premium = new PremiumRecord { /* test data */ };
        await _reportService.ProcessPremiumRecordAsync(premium);
    }
}

// Run benchmarks
class Program
{
    static void Main(string[] args)
    {
        var summary = BenchmarkRunner.Run<ReportGenerationBenchmark>();

        // Compare against COBOL baseline
        var cobolBaseline = TimeSpan.FromMinutes(4.5);  // Example: COBOL takes 4.5 min
        var dotnetActual = summary.Reports.First().ResultStatistics.Mean;
        var tolerance = 1.2;  // 120% per success criteria

        if (dotnetActual <= cobolBaseline.TotalSeconds * tolerance)
        {
            Console.WriteLine($"✓ Performance OK: {dotnetActual}s vs {cobolBaseline.TotalSeconds}s baseline (limit: {cobolBaseline.TotalSeconds * tolerance}s)");
        }
        else
        {
            Console.WriteLine($"✗ Performance FAILED: {dotnetActual}s exceeds {tolerance}x baseline");
        }
    }
}

```
```
// Program.cs
builder.Services.AddSerilog(config =>
{
    config
        .Enrich.FromLogContext()
        .Enrich.WithProperty("Application", "CaixaSeguradora.Api")
        .WriteTo.Console()
        .WriteTo.Seq("http://localhost:5341")  // Seq for log aggregation
        .WriteTo.File("logs/app-.txt", rollingInterval: RollingInterval.Day);
});

// Middleware for request timing
public class PerformanceLoggingMiddleware
{
    private readonly RequestDelegate _next;
    private readonly ILogger<PerformanceLoggingMiddleware> _logger;

    public async Task InvokeAsync(HttpContext context)
    {
        var stopwatch = Stopwatch.StartNew();

        await _next(context);

        stopwatch.Stop();

        if (stopwatch.ElapsedMilliseconds > 500)  // Log slow requests
        {
            _logger.LogWarning(
                "Slow request: {Method} {Path} took {ElapsedMs}ms",
                context.Request.Method,
                context.Request.Path,
                stopwatch.ElapsedMilliseconds);
        }

        // Metrics for dashboard
        context.Response.Headers.Add("X-Response-Time-ms", stopwatch.ElapsedMilliseconds.ToString());
    }
}

```
```
public class PerformanceComparisonTests
{
    [Fact]
    public async Task ReportGeneration_MeetsPerformanceGoal()
    {
        // Arrange
        var startDate = new DateTime(2025, 1, 1);
        var endDate = new DateTime(2025, 1, 31);
        int expectedRecordCount = 10000;
        TimeSpan maxExecutionTime = TimeSpan.FromMinutes(5);  // Success criteria

        // Act
        var stopwatch = Stopwatch.StartNew();
        var result = await _reportService.GenerateReportAsync(startDate, endDate);
        stopwatch.Stop();

        // Assert
        Assert.Equal(expectedRecordCount, result.RecordsProcessed);
        Assert.True(stopwatch.Elapsed < maxExecutionTime,
            $"Report generation took {stopwatch.Elapsed.TotalMinutes:F2} minutes, exceeds {maxExecutionTime.TotalMinutes} minute limit");
    }

    [Fact]
    public async Task DashboardLoad_MeetsResponseTimeGoal()
    {
        // Arrange
        TimeSpan maxResponseTime = TimeSpan.FromSeconds(2);  // Success criteria

        // Act
        var stopwatch = Stopwatch.StartNew();
        var metrics = await _dashboardService.GetMetricsAsync();
        stopwatch.Stop();

        // Assert
        Assert.NotNull(metrics);
        Assert.True(stopwatch.Elapsed < maxResponseTime,
            $"Dashboard load took {stopwatch.Elapsed.TotalSeconds:F2}s, exceeds {maxResponseTime.TotalSeconds}s limit");
    }
}

```
```
public class PerformanceMetrics
{
    public string OperationName { get; set; }
    public TimeSpan ExecutionTime { get; set; }
    public long MemoryUsedBytes { get; set; }
    public int RecordsProcessed { get; set; }
    public DateTime Timestamp { get; set; }

    // Comparison with COBOL baseline
    public TimeSpan? CobolBaseline { get; set; }
    public double PerformanceRatio => CobolBaseline.HasValue
        ? ExecutionTime.TotalSeconds / CobolBaseline.Value.TotalSeconds
        : 0;

    public bool MeetsSuccessCriteria => PerformanceRatio <= 1.2;  // Within 120%
}

// Metrics storage
public class MetricsRepository
{
    public async Task SaveMetricsAsync(PerformanceMetrics metrics)
    {
        await _context.PerformanceMetrics.AddAsync(metrics);
        await _context.SaveChangesAsync();
    }

    public async Task<PerformanceReport> GetPerformanceReportAsync(string operationName)
    {
        var recent = await _context.PerformanceMetrics
            .Where(m => m.OperationName == operationName)
            .OrderByDescending(m => m.Timestamp)
            .Take(100)
            .ToListAsync();

        return new PerformanceReport
        {
            OperationName = operationName,
            AverageExecutionTime = TimeSpan.FromSeconds(recent.Average(m => m.ExecutionTime.TotalSeconds)),
            MinExecutionTime = recent.Min(m => m.ExecutionTime),
            MaxExecutionTime = recent.Max(m => m.ExecutionTime),
            AveragePerformanceRatio = recent.Where(m => m.CobolBaseline.HasValue).Average(m => m.PerformanceRatio),
            MeetsSuccessCriteria = recent.All(m => m.MeetsSuccessCriteria)
        };
    }
}

```












**CURRENT TASK:**
- ID: T010
- Name: Add NuGet packages to Infrastructure project (EF Core 9.0, SQLite provider, System.Text.Json)
- Files: 
- Description: Add NuGet packages to Infrastructure project (EF Core 9.0, SQLite provider, System.Text.Json)
- Dependencies: None

**PROJECT PATHS:**
- Feature directory: /Users/brunosouza/Development/Caixa Seguradora/POC Cobol/specs/001-vamos-migrar-sistema
- Tasks file: /Users/brunosouza/Development/Caixa Seguradora/POC Cobol/specs/001-vamos-migrar-sistema/tasks.md
- Plan file: /Users/brunosouza/Development/Caixa Seguradora/POC Cobol/specs/001-vamos-migrar-sistema/plan.md
- **Consolidated Task Plan**: /Users/brunosouza/Development/Caixa Seguradora/POC Cobol/specs/001-vamos-migrar-sistema/.task-plans/task-T010.md

**PRE-EXECUTION CHECKS (from /speckit.implement):**

STEP 1: Check checklists status (if /Users/brunosouza/Development/Caixa Seguradora/POC Cobol/specs/001-vamos-migrar-sistema/checklists/ exists):
- Scan all checklist files in checklists/ directory
- For each checklist, count:
  * Total items: All lines matching `- [ ]` or `- [X]` or `- [x]`
  * Completed: Lines matching `- [X]` or `- [x]`
  * Incomplete: Lines matching `- [ ]`
- Create status table showing checklist completion
- If any checklist is incomplete:
  * Display table with incomplete counts
  * STOP and ask: "Some checklists are incomplete. Do you want to proceed with implementation anyway? (yes/no)"
  * Wait for user response before continuing
  * If "no" or "stop": Halt execution and report status
  * If "yes" or "proceed": Continue to Step 2
- If all checklists complete: Proceed to Step 2

STEP 2: Project Setup Verification:
- Detect project technology and create/verify ignore files:
  * Check if git repo → create/verify .gitignore
  * Check if Dockerfile exists → create/verify .dockerignore
  * Check if .eslintrc* exists → create/verify .eslintignore
  * Check if .prettierrc* exists → create/verify .prettierignore
  * Check if package.json exists → create/verify .npmignore (if publishing)
- Use technology-specific patterns from plan.md:
  * Node.js/JS: node_modules/, dist/, build/, *.log, .env*
  * Python: __pycache__/, *.pyc, .venv/, venv/, dist/, *.egg-info/
  * Java: target/, *.class, *.jar, .gradle/, build/
  * Universal: .DS_Store, Thumbs.db, *.tmp, *.swp, .vscode/, .idea/
- If ignore file exists: Verify essential patterns, append missing critical ones
- If ignore file missing: Create with full pattern set for detected tech
- Report created/verified files before proceeding

**EXECUTION RULES (from /implement template):**

1. **Load Consolidated Task Plan**: Read /Users/brunosouza/Development/Caixa Seguradora/POC Cobol/specs/001-vamos-migrar-sistema/.task-plans/task-T010.md (YOUR PRIMARY GUIDE)
2. **Follow Implementation Steps**: Execute ONLY task T010 following the steps from the consolidated task file
3. **Respect Dependencies**: Check if prerequisite tasks are complete (listed in consolidated file)
4. **Follow TDD**: Write tests first if specified in consolidated plan (tests before code)
5. **Use Patterns**: Follow code patterns from consolidated task file (extracted from plan.md/research.md)
6. **Handle Edge Cases**: Address all scenarios mentioned in the consolidated task file
7. **Verify Criteria**: Ensure ALL verification criteria are met (in SUCCESS CRITERIA section)
8. **Mark Subtasks**: If task has subtasks, mark each `- [x]` as completed, then mark main task [x] in tasks.md
9. **Progress Tracking**: Report what you've done step by step

**IMPLEMENTATION REQUIREMENTS:**
- Follow consolidated task file implementation steps (don't skip steps)
- Create/modify files using absolute paths from the consolidated task file
- Use architectural patterns from "Code Patterns to Follow" section
- Apply technical decisions from "Technical Approach" section
- Implement according to "Artifact Analysis" guidance
- Write clean, well-documented code
- Ensure all verification criteria pass (use "Verification Checklist")
- Mark task as [x] completed in tasks.md when finished (after all subtasks if applicable)

**CRITICAL RULES:**
- DO: Implement ONLY task T010
- DO: Follow every step in the consolidated task file (/Users/brunosouza/Development/Caixa Seguradora/POC Cobol/specs/001-vamos-migrar-sistema/.task-plans/task-T010.md)
- DO: Use code patterns from consolidated task file
- DO: Mark subtasks [x] individually, then main task [x] when ALL subtasks complete
- DON'T: Implement other tasks
- DON'T: Skip steps from the consolidated task file
- DON'T: Ignore patterns/approaches from consolidated task file
- DON'T: Leave task or subtasks unmarked

**PHASE-BY-PHASE EXECUTION (from /implement):**
- Setup first: Initialize structure, dependencies, configuration
- Tests before code (TDD APPROACH):
  * Write test files FIRST based on test_specifications from plan
  * Run tests to verify they FAIL (red phase)
  * Generate test metadata: test_commands, test_file_locations
- Core development: Implement models, services, endpoints to make tests pass
- Integration work: Database, middleware, logging, external services
- Polish and validation: Unit tests, performance, documentation

**ERROR HANDLING & EXECUTION CONTROL (from /speckit.implement):**
- **Sequential tasks (default)**:
  * HALT execution immediately if task fails
  * Do not proceed to next task
  * Report error with full context for debugging
  * Suggest corrective actions if possible
- **Parallel tasks (marked [P])**:
  * Continue with other successful tasks if one fails
  * Report failed parallel tasks separately
  * Aggregate failures at end of parallel batch
  * Only halt if ALL parallel tasks in batch fail
- **Dependency violations**:
  * HALT if required dependency task not completed
  * Display clear dependency chain
  * Suggest running prerequisite tasks first
- **Critical failures** (cannot recover):
  * Missing required files from plan.md
  * Unresolvable conflicts in codebase
  * Environmental issues (missing tools, permissions)
  * Report failure mode and suggest user intervention

**TEST METADATA GENERATION (REQUIRED):**
When generating tests, you MUST provide:
- test_commands: List of exact commands to run tests (e.g., "pytest tests/test_validation.py -q")
  * Use pytest native options: -q (quiet), -v (verbose), --tb=short (short traceback)
  * NEVER use grep to filter pytest output (adds 30-40% overhead)
- test_file_locations: Absolute paths to all test files created
- test_data_setup: Any setup instructions needed before running tests

**CRITICAL OUTPUT FORMAT REQUIREMENTS:**

At the end of your implementation, you MUST include:

## Files Modified
- /absolute/path/to/file1.ts (created, 450 lines) - Brief description
- /absolute/path/to/file2.json (modified, 1200 lines) - What changed
- /absolute/path/to/file3.spec.ts (created, 300 lines) - Test file

## Verification Commands Executed
- npm test -- path/to/test.spec.ts (PASSED - 15 tests)
- npx prettier --check file.ts (PASSED)
- npm run lint (PASSED)

## Criteria Verified
- ✅ Criterion 1: Evidence description
- ✅ Criterion 2: Evidence description

This structured output is REQUIRED for validation to work properly.

### Execution Guidance JSON
```json
{
  "task_id": "T010",
  "implementation_summary": "Concise description of what changed and why",
  "files_modified": [
    {"path": "/absolute/path/to/file.ts", "change_type": "created|modified|deleted", "description": "Short note"}
  ],
  "key_changes": ["Highlight the most important code adjustments"],
  "tests_executed": [
    {"command": "pytest tests/... -q", "status": "PASSED", "evidence": "Number of tests / coverage"}
  ],
  "validation_focus": [
    {"area": "Function or module to double-check", "expectation": "Exact behaviour to validate"}
  ],
  "risks": ["Known limitations or follow-up actions"]
}
```
- The JSON block MUST be valid, appear exactly once, and match the structure above.
- Do not add narrative before or after the JSON block; keep it machine-readable.

Implement task T010 now, following the plan exactly.


================================================================================
# SpecKit Command: speckit.implement
================================================================================

description = "Execute the implementation plan by processing and executing all tasks defined in tasks.md"

prompt = """
---
description: Execute the implementation plan by processing and executing all tasks defined in tasks.md
---

## User Input

```text
$ARGUMENTS
```

You **MUST** consider the user input before proceeding (if not empty).

## Outline

1. Run `.specify/scripts/bash/check-prerequisites.sh --json --require-tasks --include-tasks` from repo root and parse FEATURE_DIR and AVAILABLE_DOCS list. All paths must be absolute. For single quotes in args like "I'm Groot", use escape syntax: e.g 'I'\\''m Groot' (or double-quote if possible: "I'm Groot").

2. **Check checklists status** (if FEATURE_DIR/checklists/ exists):
   - Scan all checklist files in the checklists/ directory
   - For each checklist, count:
     - Total items: All lines matching `- [ ]` or `- [X]` or `- [x]`
     - Completed items: Lines matching `- [X]` or `- [x]`
     - Incomplete items: Lines matching `- [ ]`
   - Create a status table:

     ```text
     | Checklist | Total | Completed | Incomplete | Status |
     |-----------|-------|-----------|------------|--------|
     | ux.md     | 12    | 12        | 0          | ✓ PASS |
     | test.md   | 8     | 5         | 3          | ✗ FAIL |
     | security.md | 6   | 6         | 0          | ✓ PASS |
     ```

   - Calculate overall status:
     - **PASS**: All checklists have 0 incomplete items
     - **FAIL**: One or more checklists have incomplete items

   - **If any checklist is incomplete**:
     - Display the table with incomplete item counts
     - **STOP** and ask: "Some checklists are incomplete. Do you want to proceed with implementation anyway? (yes/no)"
     - Wait for user response before continuing
     - If user says "no" or "wait" or "stop", halt execution
     - If user says "yes" or "proceed" or "continue", proceed to step 3

   - **If all checklists are complete**:
     - Display the table showing all checklists passed
     - Automatically proceed to step 3

3. Load and analyze the implementation context:
   - **REQUIRED**: Read tasks.md for the complete task list and execution plan
   - **REQUIRED**: Read plan.md for tech stack, architecture, and file structure
   - **IF EXISTS**: Read data-model.md for entities and relationships
   - **IF EXISTS**: Read contracts/ for API specifications and test requirements
   - **IF EXISTS**: Read research.md for technical decisions and constraints
   - **IF EXISTS**: Read quickstart.md for integration scenarios

4. **Project Setup Verification**:
   - **REQUIRED**: Create/verify ignore files based on actual project setup:

   **Detection & Creation Logic**:
   - Check if the following command succeeds to determine if the repository is a git repo (create/verify .gitignore if so):

     ```sh
     git rev-parse --git-dir 2>/dev/null
     ```

   - Check if Dockerfile* exists or Docker in plan.md → create/verify .dockerignore
   - Check if .eslintrc*or eslint.config.* exists → create/verify .eslintignore
   - Check if .prettierrc* exists → create/verify .prettierignore
   - Check if .npmrc or package.json exists → create/verify .npmignore (if publishing)
   - Check if terraform files (*.tf) exist → create/verify .terraformignore
   - Check if .helmignore needed (helm charts present) → create/verify .helmignore

   **If ignore file already exists**: Verify it contains essential patterns, append missing critical patterns only
   **If ignore file missing**: Create with full pattern set for detected technology

   **Common Patterns by Technology** (from plan.md tech stack):
   - **Node.js/JavaScript/TypeScript**: `node_modules/`, `dist/`, `build/`, `*.log`, `.env*`
   - **Python**: `__pycache__/`, `*.pyc`, `.venv/`, `venv/`, `dist/`, `*.egg-info/`
   - **Java**: `target/`, `*.class`, `*.jar`, `.gradle/`, `build/`
   - **C#/.NET**: `bin/`, `obj/`, `*.user`, `*.suo`, `packages/`
   - **Go**: `*.exe`, `*.test`, `vendor/`, `*.out`
   - **Ruby**: `.bundle/`, `log/`, `tmp/`, `*.gem`, `vendor/bundle/`
   - **PHP**: `vendor/`, `*.log`, `*.cache`, `*.env`
   - **Rust**: `target/`, `debug/`, `release/`, `*.rs.bk`, `*.rlib`, `*.prof*`, `.idea/`, `*.log`, `.env*`
   - **Kotlin**: `build/`, `out/`, `.gradle/`, `.idea/`, `*.class`, `*.jar`, `*.iml`, `*.log`, `.env*`
   - **C++**: `build/`, `bin/`, `obj/`, `out/`, `*.o`, `*.so`, `*.a`, `*.exe`, `*.dll`, `.idea/`, `*.log`, `.env*`
   - **C**: `build/`, `bin/`, `obj/`, `out/`, `*.o`, `*.a`, `*.so`, `*.exe`, `Makefile`, `config.log`, `.idea/`, `*.log`, `.env*`
   - **Swift**: `.build/`, `DerivedData/`, `*.swiftpm/`, `Packages/`
   - **R**: `.Rproj.user/`, `.Rhistory`, `.RData`, `.Ruserdata`, `*.Rproj`, `packrat/`, `renv/`
   - **Universal**: `.DS_Store`, `Thumbs.db`, `*.tmp`, `*.swp`, `.vscode/`, `.idea/`

   **Tool-Specific Patterns**:
   - **Docker**: `node_modules/`, `.git/`, `Dockerfile*`, `.dockerignore`, `*.log*`, `.env*`, `coverage/`
   - **ESLint**: `node_modules/`, `dist/`, `build/`, `coverage/`, `*.min.js`
   - **Prettier**: `node_modules/`, `dist/`, `build/`, `coverage/`, `package-lock.json`, `yarn.lock`, `pnpm-lock.yaml`
   - **Terraform**: `.terraform/`, `*.tfstate*`, `*.tfvars`, `.terraform.lock.hcl`
   - **Kubernetes/k8s**: `*.secret.yaml`, `secrets/`, `.kube/`, `kubeconfig*`, `*.key`, `*.crt`

5. Parse tasks.md structure and extract:
   - **Task phases**: Setup, Tests, Core, Integration, Polish
   - **Task dependencies**: Sequential vs parallel execution rules
   - **Task details**: ID, description, file paths, parallel markers [P]
   - **Execution flow**: Order and dependency requirements

6. Execute implementation following the task plan:
   - **Phase-by-phase execution**: Complete each phase before moving to the next
   - **Respect dependencies**: Run sequential tasks in order, parallel tasks [P] can run together  
   - **Follow TDD approach**: Execute test tasks before their corresponding implementation tasks
   - **File-based coordination**: Tasks affecting the same files must run sequentially
   - **Validation checkpoints**: Verify each phase completion before proceeding

7. Implementation execution rules:
   - **Setup first**: Initialize project structure, dependencies, configuration
   - **Tests before code**: If you need to write tests for contracts, entities, and integration scenarios
   - **Core development**: Implement models, services, CLI commands, endpoints
   - **Integration work**: Database connections, middleware, logging, external services
   - **Polish and validation**: Unit tests, performance optimization, documentation

8. Progress tracking and error handling:
   - Report progress after each completed task
   - Halt execution if any non-parallel task fails
   - For parallel tasks [P], continue with successful tasks, report failed ones
   - Provide clear error messages with context for debugging
   - Suggest next steps if implementation cannot proceed
   - **IMPORTANT** For completed tasks, make sure to mark the task off as [X] in the tasks file.

9. Completion validation:
   - Verify all required tasks are completed
   - Check that implemented features match the original specification
   - Validate that tests pass and coverage meets requirements
   - Confirm the implementation follows the technical plan
   - Report final status with summary of completed work

Note: This command assumes a complete task breakdown exists in tasks.md. If tasks are incomplete or missing, suggest running `/speckit.tasks` first to regenerate the task list.
"""



================================================================================
# SpecKit Command: speckit.tasks
================================================================================

description = "Generate an actionable, dependency-ordered tasks.md for the feature based on available design artifacts."

prompt = """
---
description: Generate an actionable, dependency-ordered tasks.md for the feature based on available design artifacts.
---

## User Input

```text
$ARGUMENTS
```

You **MUST** consider the user input before proceeding (if not empty).

## Outline

1. **Setup**: Run `.specify/scripts/bash/check-prerequisites.sh --json` from repo root and parse FEATURE_DIR and AVAILABLE_DOCS list. All paths must be absolute. For single quotes in args like "I'm Groot", use escape syntax: e.g 'I'\\''m Groot' (or double-quote if possible: "I'm Groot").

2. **Load design documents**: Read from FEATURE_DIR:
   - **Required**: plan.md (tech stack, libraries, structure), spec.md (user stories with priorities)
   - **Optional**: data-model.md (entities), contracts/ (API endpoints), research.md (decisions), quickstart.md (test scenarios)
   - Note: Not all projects have all documents. Generate tasks based on what's available.

3. **Execute task generation workflow**:
   - Load plan.md and extract tech stack, libraries, project structure
   - Load spec.md and extract user stories with their priorities (P1, P2, P3, etc.)
   - If data-model.md exists: Extract entities and map to user stories
   - If contracts/ exists: Map endpoints to user stories
   - If research.md exists: Extract decisions for setup tasks
   - Generate tasks organized by user story (see Task Generation Rules below)
   - Generate dependency graph showing user story completion order
   - Create parallel execution examples per user story
   - Validate task completeness (each user story has all needed tasks, independently testable)

4. **Generate tasks.md**: Use `.specify.specify/templates/tasks-template.md` as structure, fill with:
   - Correct feature name from plan.md
   - Phase 1: Setup tasks (project initialization)
   - Phase 2: Foundational tasks (blocking prerequisites for all user stories)
   - Phase 3+: One phase per user story (in priority order from spec.md)
   - Each phase includes: story goal, independent test criteria, tests (if requested), implementation tasks
   - Final Phase: Polish & cross-cutting concerns
   - All tasks must follow the strict checklist format (see Task Generation Rules below)
   - Clear file paths for each task
   - Dependencies section showing story completion order
   - Parallel execution examples per story
   - Implementation strategy section (MVP first, incremental delivery)

5. **Report**: Output path to generated tasks.md and summary:
   - Total task count
   - Task count per user story
   - Parallel opportunities identified
   - Independent test criteria for each story
   - Suggested MVP scope (typically just User Story 1)
   - Format validation: Confirm ALL tasks follow the checklist format (checkbox, ID, labels, file paths)

Context for task generation: {{args}}

The tasks.md should be immediately executable - each task must be specific enough that an LLM can complete it without additional context.

## Task Generation Rules

**CRITICAL**: Tasks MUST be organized by user story to enable independent implementation and testing.

**Tests are OPTIONAL**: Only generate test tasks if explicitly requested in the feature specification or if user requests TDD approach.

### Checklist Format (REQUIRED)

Every task MUST strictly follow this format:

```text
- [ ] [TaskID] [P?] [Story?] Description with file path
```

**Format Components**:

1. **Checkbox**: ALWAYS start with `- [ ]` (markdown checkbox)
2. **Task ID**: Sequential number (T001, T002, T003...) in execution order
3. **[P] marker**: Include ONLY if task is parallelizable (different files, no dependencies on incomplete tasks)
4. **[Story] label**: REQUIRED for user story phase tasks only
   - Format: [US1], [US2], [US3], etc. (maps to user stories from spec.md)
   - Setup phase: NO story label
   - Foundational phase: NO story label  
   - User Story phases: MUST have story label
   - Polish phase: NO story label
5. **Description**: Clear action with exact file path

**Examples**:

- ✅ CORRECT: `- [ ] T001 Create project structure per implementation plan`
- ✅ CORRECT: `- [ ] T005 [P] Implement authentication middleware in src/middleware/auth.py`
- ✅ CORRECT: `- [ ] T012 [P] [US1] Create User model in src/models/user.py`
- ✅ CORRECT: `- [ ] T014 [US1] Implement UserService in src/services/user_service.py`
- ❌ WRONG: `- [ ] Create User model` (missing ID and Story label)
- ❌ WRONG: `T001 [US1] Create model` (missing checkbox)
- ❌ WRONG: `- [ ] [US1] Create User model` (missing Task ID)
- ❌ WRONG: `- [ ] T001 [US1] Create model` (missing file path)

### Task Organization

1. **From User Stories (spec.md)** - PRIMARY ORGANIZATION:
   - Each user story (P1, P2, P3...) gets its own phase
   - Map all related components to their story:
     - Models needed for that story
     - Services needed for that story
     - Endpoints/UI needed for that story
     - If tests requested: Tests specific to that story
   - Mark story dependencies (most stories should be independent)

2. **From Contracts**:
   - Map each contract/endpoint → to the user story it serves
   - If tests requested: Each contract → contract test task [P] before implementation in that story's phase

3. **From Data Model**:
   - Map each entity to the user story(ies) that need it
   - If entity serves multiple stories: Put in earliest story or Setup phase
   - Relationships → service layer tasks in appropriate story phase

4. **From Setup/Infrastructure**:
   - Shared infrastructure → Setup phase (Phase 1)
   - Foundational/blocking tasks → Foundational phase (Phase 2)
   - Story-specific setup → within that story's phase

### Phase Structure

- **Phase 1**: Setup (project initialization)
- **Phase 2**: Foundational (blocking prerequisites - MUST complete before user stories)
- **Phase 3+**: User Stories in priority order (P1, P2, P3...)
  - Within each story: Tests (if requested) → Models → Services → Endpoints → Integration
  - Each phase should be a complete, independently testable increment
- **Final Phase**: Polish & Cross-Cutting Concerns
"""

